#!/usr/bin/env python3
"""
æµ‹è¯•å®Œæ•´çš„NanoDetPlusæ¨¡å‹
ä¸¥æ ¼å¯¹ç…§PyTorchç‰ˆæœ¬è¿›è¡Œæµ‹è¯•
"""

import os
import sys
import logging
import jittor as jt
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def test_full_model():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•å®Œæ•´NanoDetPlusæ¨¡å‹")
    logger.info("=" * 50)
    
    try:
        from nanodet.model import build_model
        
        # ä¸¥æ ¼æŒ‰ç…§é…ç½®æ–‡ä»¶çš„æ¨¡å‹é…ç½®
        model_cfg = {
            'name': 'NanoDetPlus',
            'backbone': {
                'name': 'ShuffleNetV2',
                'model_size': '1.0x',
                'out_stages': [2, 3, 4],
                'activation': 'LeakyReLU',
                'pretrain': True
            },
            'fpn': {
                'name': 'GhostPAN',
                'in_channels': [116, 232, 464],
                'out_channels': 96,
                'kernel_size': 5,
                'num_extra_level': 1,
                'use_depthwise': True,
                'activation': 'LeakyReLU'
            },
            'head': {
                'name': 'NanoDetPlusHead',
                'num_classes': 20,
                'input_channel': 96,
                'feat_channels': 96,
                'stacked_convs': 2,
                'kernel_size': 5,
                'strides': [8, 16, 32, 64],
                'activation': 'LeakyReLU',
                'reg_max': 7,
                'norm_cfg': {'type': 'BN'},
                'loss': {
                    'loss_qfl': {
                        'name': 'QualityFocalLoss',
                        'use_sigmoid': True,
                        'beta': 2.0,
                        'loss_weight': 1.0
                    },
                    'loss_dfl': {
                        'name': 'DistributionFocalLoss',
                        'loss_weight': 0.25
                    },
                    'loss_bbox': {
                        'name': 'GIoULoss',
                        'loss_weight': 2.0
                    }
                }
            },
            'aux_head': {
                'name': 'SimpleConvHead',
                'num_classes': 20,
                'input_channel': 192,  # 96 * 2 (concatenated features)
                'feat_channels': 192,
                'stacked_convs': 4,
                'strides': [8, 16, 32, 64],
                'activation': 'LeakyReLU',
                'norm_cfg': {'type': 'BN'}
            },
            'detach_epoch': 10
        }
        
        logger.info("æ„å»ºå®Œæ•´NanoDetPlusæ¨¡å‹...")
        model = build_model(model_cfg)
        logger.info("âœ… å®Œæ•´æ¨¡å‹æ„å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        x = jt.randn(1, 3, 320, 320)
        logger.info(f"è¾“å…¥å¼ é‡: {x.shape}")
        
        # æµ‹è¯•æ¨ç†æ¨¡å¼
        logger.info("æµ‹è¯•æ¨ç†æ¨¡å¼...")
        model.eval()
        with jt.no_grad():
            output = model(x)
        
        logger.info(f"æ¨ç†è¾“å‡º: {output.shape}")
        
        # æµ‹è¯•è®­ç»ƒæ¨¡å¼
        logger.info("æµ‹è¯•è®­ç»ƒæ¨¡å¼...")
        model.train()
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒæ•°æ®
        gt_meta = {
            'img': x,
            'gt_bboxes': [jt.randn(5, 4)],  # 5ä¸ªbbox
            'gt_labels': [jt.randint(0, 20, (5,))],  # 5ä¸ªæ ‡ç­¾
            'img_info': {
                'height': 320,
                'width': 320,
                'id': 0
            }
        }
        
        try:
            # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½ä¼šå› ä¸ºç¼ºå°‘æŸäº›è®­ç»ƒç›¸å…³çš„ç»„ä»¶è€Œå¤±è´¥
            # ä½†è‡³å°‘å¯ä»¥æµ‹è¯•æ¨¡å‹çš„åŸºæœ¬ç»“æ„
            head_out, loss, loss_states = model.forward_train(gt_meta)
            logger.info("âœ… è®­ç»ƒå‰å‘ä¼ æ’­æˆåŠŸ")
            logger.info(f"æŸå¤±å€¼: {loss}")
        except Exception as train_e:
            logger.warning(f"è®­ç»ƒæ¨¡å¼æµ‹è¯•å¤±è´¥ï¼ˆè¿™æ˜¯é¢„æœŸçš„ï¼‰: {train_e}")
            logger.info("âœ… æ¨¡å‹ç»“æ„æ­£ç¡®ï¼Œè®­ç»ƒç›¸å…³ç»„ä»¶å¯èƒ½éœ€è¦è¿›ä¸€æ­¥å®ç°")
        
        logger.info("âœ… å®Œæ•´æ¨¡å‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_model_with_config_file():
    """ä½¿ç”¨é…ç½®æ–‡ä»¶æµ‹è¯•æ¨¡å‹"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("ä½¿ç”¨é…ç½®æ–‡ä»¶æµ‹è¯•æ¨¡å‹")
    logger.info("=" * 50)
    
    try:
        from nanodet.util import load_config
        from nanodet.model import build_model
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = project_root / "config" / "nanodet-plus-m_320_voc.yml"
        cfg = load_config(str(config_path))
        
        logger.info(f"ä»é…ç½®æ–‡ä»¶åŠ è½½: {config_path}")
        
        # æ„å»ºæ¨¡å‹
        model = build_model(cfg.model)
        logger.info("âœ… ä»é…ç½®æ–‡ä»¶æ„å»ºæ¨¡å‹æˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = jt.randn(1, 3, 320, 320)
        logger.info(f"è¾“å…¥å¼ é‡: {x.shape}")
        
        model.eval()
        with jt.no_grad():
            output = model(x)
        
        logger.info(f"æ¨ç†è¾“å‡º: {output.shape}")
        logger.info("âœ… é…ç½®æ–‡ä»¶æ¨¡å‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    # å¼ºåˆ¶ä½¿ç”¨CPU
    jt.flags.use_cuda = 0
    
    logger = setup_logging()
    logger.info("å¼€å§‹å®Œæ•´æ¨¡å‹æµ‹è¯•...")
    logger.info(f"Jittor CUDA available: {jt.has_cuda}")
    logger.info(f"Jittor using CUDA: {jt.flags.use_cuda}")
    
    # æµ‹è¯•å®Œæ•´æ¨¡å‹
    full_model_success = test_full_model()
    if not full_model_success:
        logger.error("âŒ å®Œæ•´æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶æ¨¡å‹
    config_model_success = test_model_with_config_file()
    if not config_model_success:
        logger.error("âŒ é…ç½®æ–‡ä»¶æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False
    
    logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
