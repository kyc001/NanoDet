#!/usr/bin/env python3
"""
ç®€å•çš„CPUæ¨¡å¼æµ‹è¯•è„šæœ¬
éªŒè¯Jittoråœ¨CPUæ¨¡å¼ä¸‹çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
import logging
import jittor as jt
from pathlib import Path

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def test_basic_cpu_operations():
    """æµ‹è¯•åŸºæœ¬çš„CPUæ“ä½œ"""
    logger = setup_logging()
    
    # å¼ºåˆ¶ä½¿ç”¨CPU
    jt.flags.use_cuda = 0
    logger.info("å¼ºåˆ¶è®¾ç½®ä¸ºCPUæ¨¡å¼")
    logger.info(f"Jittor CUDA available: {jt.has_cuda}")
    logger.info(f"Jittor using CUDA: {jt.flags.use_cuda}")
    
    try:
        # æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ
        logger.info("æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ...")
        
        # åˆ›å»ºå¼ é‡
        x = jt.randn(4, 3, 32, 32)
        y = jt.randn(4, 10)
        logger.info(f"åˆ›å»ºå¼ é‡ x: {x.shape}, y: {y.shape}")
        
        # æµ‹è¯•å·ç§¯æ“ä½œ
        logger.info("æµ‹è¯•å·ç§¯æ“ä½œ...")
        conv = jt.nn.Conv2d(3, 16, 3, padding=1)
        conv_out = conv(x)
        logger.info(f"å·ç§¯è¾“å‡º: {conv_out.shape}")
        
        # æµ‹è¯•æ± åŒ–æ“ä½œ
        logger.info("æµ‹è¯•æ± åŒ–æ“ä½œ...")
        pool = jt.nn.AdaptiveAvgPool2d((1, 1))
        pool_out = pool(conv_out)
        logger.info(f"æ± åŒ–è¾“å‡º: {pool_out.shape}")
        
        # æµ‹è¯•å…¨è¿æ¥å±‚
        logger.info("æµ‹è¯•å…¨è¿æ¥å±‚...")
        fc = jt.nn.Linear(16, 10)
        pool_flat = pool_out.view(pool_out.shape[0], -1)
        fc_out = fc(pool_flat)
        logger.info(f"å…¨è¿æ¥è¾“å‡º: {fc_out.shape}")
        
        # æµ‹è¯•æŸå¤±è®¡ç®—
        logger.info("æµ‹è¯•æŸå¤±è®¡ç®—...")
        loss_fn = jt.nn.MSELoss()
        loss = loss_fn(fc_out, y)
        logger.info(f"æŸå¤±å€¼: {loss.item():.4f}")
        
        # æµ‹è¯•åå‘ä¼ æ’­
        logger.info("æµ‹è¯•åå‘ä¼ æ’­...")
        optimizer = jt.optim.SGD([conv.weight, conv.bias, fc.weight, fc.bias], lr=0.01)
        optimizer.zero_grad()
        optimizer.backward(loss)
        optimizer.step()
        logger.info("åå‘ä¼ æ’­å®Œæˆ")
        
        # æµ‹è¯•ç®€å•çš„è®­ç»ƒå¾ªç¯
        logger.info("æµ‹è¯•ç®€å•è®­ç»ƒå¾ªç¯...")
        for i in range(3):
            # å‰å‘ä¼ æ’­
            conv_out = conv(x)
            pool_out = pool(conv_out)
            pool_flat = pool_out.view(pool_out.shape[0], -1)
            fc_out = fc(pool_flat)
            
            # è®¡ç®—æŸå¤±
            loss = loss_fn(fc_out, y)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            optimizer.backward(loss)
            optimizer.step()
            
            logger.info(f"Epoch {i+1}: loss = {loss.item():.4f}")
        
        logger.info("âœ… CPUæ¨¡å¼åŸºæœ¬æ“ä½œæµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ CPUæ¨¡å¼æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("æµ‹è¯•ç®€å•æ¨¡å‹åˆ›å»º...")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„CNNæ¨¡å‹
        class SimpleCNN(jt.nn.Module):
            def __init__(self):
                super(SimpleCNN, self).__init__()
                self.conv1 = jt.nn.Conv2d(3, 16, 3, padding=1)
                self.conv2 = jt.nn.Conv2d(16, 32, 3, padding=1)
                self.pool = jt.nn.AdaptiveAvgPool2d((1, 1))
                self.fc = jt.nn.Linear(32, 10)
                self.relu = jt.nn.ReLU()
            
            def execute(self, x):
                x = self.relu(self.conv1(x))
                x = self.relu(self.conv2(x))
                x = self.pool(x)
                x = x.view(x.shape[0], -1)
                x = self.fc(x)
                return x
        
        model = SimpleCNN()
        logger.info("æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        x = jt.randn(2, 3, 32, 32)
        output = model(x)
        logger.info(f"æ¨¡å‹è¾“å‡º: {output.shape}")
        
        # æµ‹è¯•æ¨¡å‹è®­ç»ƒ
        target = jt.randn(2, 10)
        loss_fn = jt.nn.MSELoss()
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01)
        
        for i in range(3):
            output = model(x)
            loss = loss_fn(output, target)
            
            optimizer.zero_grad()
            optimizer.backward(loss)
            optimizer.step()
            
            logger.info(f"è®­ç»ƒæ­¥éª¤ {i+1}: loss = {loss.item():.4f}")
        
        logger.info("âœ… æ¨¡å‹åˆ›å»ºå’Œè®­ç»ƒæµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logging()
    
    logger.info("å¼€å§‹CPUæ¨¡å¼ç»¼åˆæµ‹è¯•...")
    
    # æµ‹è¯•åŸºæœ¬æ“ä½œ
    basic_success = test_basic_cpu_operations()
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    model_success = test_model_creation()
    
    if basic_success and model_success:
        logger.info("ğŸ‰ æ‰€æœ‰CPUæ¨¡å¼æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… CPUæ¨¡å¼éªŒè¯æˆåŠŸï¼Jittorå¯ä»¥åœ¨CPUæ¨¡å¼ä¸‹æ­£å¸¸å·¥ä½œã€‚")
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("âŒ CPUæ¨¡å¼éªŒè¯å¤±è´¥ï¼")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
