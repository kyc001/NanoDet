#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ·±åº¦åˆ†ææƒé‡åŠ è½½å¤±è´¥çš„åŸå› 
æ‰¾å‡ºæ¯ä¸ªå¤±è´¥å‚æ•°çš„å…·ä½“é—®é¢˜
"""

import os
import sys
import torch
import jittor as jt
from collections import defaultdict

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def create_nanodet_model():
    """åˆ›å»ºNanoDetæ¨¡å‹"""
    print("åˆ›å»ºNanoDetæ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®å­—å…¸
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    # åˆ›å»ºaux_headé…ç½® - ä½¿ç”¨æ­£ç¡®çš„SimpleConvHead
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    return model


def analyze_parameter_mismatch():
    """æ·±åº¦åˆ†æå‚æ•°ä¸åŒ¹é…çš„åŸå› """
    print("ğŸ” æ·±åº¦åˆ†æå‚æ•°ä¸åŒ¹é…åŸå› ")
    print("=" * 80)
    
    # åŠ è½½PyTorch checkpoint
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    pytorch_state_dict = checkpoint.get('state_dict', checkpoint)
    
    print(f"âœ“ PyTorch checkpointåŒ…å« {len(pytorch_state_dict)} ä¸ªå‚æ•°")
    
    # åˆ›å»ºJittoræ¨¡å‹
    jittor_model = create_nanodet_model()
    
    # è·å–Jittoræ¨¡å‹çš„å‚æ•°å­—å…¸
    jittor_state_dict = {}
    for name, param in jittor_model.named_parameters():
        jittor_state_dict[name] = param
    
    print(f"âœ“ Jittoræ¨¡å‹åŒ…å« {len(jittor_state_dict)} ä¸ªå‚æ•°")
    
    # åˆ†ç±»åˆ†æå¤±è´¥åŸå› 
    analysis_result = {
        "æˆåŠŸåŠ è½½": [],
        "è·³è¿‡_BatchNormç»Ÿè®¡": [],
        "è·³è¿‡_æƒé‡å¹³å‡": [],
        "è·³è¿‡_aux_head": [],
        "å½¢çŠ¶ä¸åŒ¹é…": [],
        "å‚æ•°åä¸å­˜åœ¨": [],
        "å…¶ä»–é”™è¯¯": []
    }
    
    for pytorch_name, pytorch_param in pytorch_state_dict.items():
        # ç§»é™¤PyTorchç‰¹æœ‰çš„å‰ç¼€
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]  # ç§»é™¤"model."å‰ç¼€
        
        # åˆ†ç±»å¤„ç†
        if "num_batches_tracked" in jittor_name:
            analysis_result["è·³è¿‡_BatchNormç»Ÿè®¡"].append({
                "pytorch_name": pytorch_name,
                "jittor_name": jittor_name,
                "shape": list(pytorch_param.shape)
            })
            continue
        
        if jittor_name.startswith("avg_"):
            analysis_result["è·³è¿‡_æƒé‡å¹³å‡"].append({
                "pytorch_name": pytorch_name,
                "jittor_name": jittor_name,
                "shape": list(pytorch_param.shape)
            })
            continue
        
        # ä¸å†è·³è¿‡aux_headï¼Œç°åœ¨åº”è¯¥èƒ½æ­£ç¡®åŒ¹é…
        # if "aux_head" in jittor_name:
        #     analysis_result["è·³è¿‡_aux_head"].append({
        #         "pytorch_name": pytorch_name,
        #         "jittor_name": jittor_name,
        #         "shape": list(pytorch_param.shape)
        #     })
        #     continue
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            # æ£€æŸ¥å½¢çŠ¶åŒ¹é…
            if list(pytorch_param.shape) == list(jittor_param.shape):
                analysis_result["æˆåŠŸåŠ è½½"].append({
                    "pytorch_name": pytorch_name,
                    "jittor_name": jittor_name,
                    "shape": list(pytorch_param.shape)
                })
            else:
                analysis_result["å½¢çŠ¶ä¸åŒ¹é…"].append({
                    "pytorch_name": pytorch_name,
                    "jittor_name": jittor_name,
                    "pytorch_shape": list(pytorch_param.shape),
                    "jittor_shape": list(jittor_param.shape)
                })
        else:
            analysis_result["å‚æ•°åä¸å­˜åœ¨"].append({
                "pytorch_name": pytorch_name,
                "jittor_name": jittor_name,
                "shape": list(pytorch_param.shape)
            })
    
    # æ‰“å°è¯¦ç»†åˆ†æç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š è¯¦ç»†åˆ†æç»“æœ")
    print("=" * 80)
    
    for category, items in analysis_result.items():
        print(f"\nğŸ”¹ {category}: {len(items)} ä¸ª")
        
        if len(items) > 0:
            print(f"   å‰5ä¸ªç¤ºä¾‹:")
            for i, item in enumerate(items[:5]):
                if category == "å½¢çŠ¶ä¸åŒ¹é…":
                    print(f"   {i+1}. {item['jittor_name']}")
                    print(f"      PyTorch: {item['pytorch_shape']}")
                    print(f"      Jittor: {item['jittor_shape']}")
                else:
                    print(f"   {i+1}. {item['jittor_name']} -> {item['shape']}")
            
            if len(items) > 5:
                print(f"   ... è¿˜æœ‰ {len(items) - 5} ä¸ª")
    
    # é‡ç‚¹åˆ†æï¼šå‚æ•°åä¸å­˜åœ¨çš„é—®é¢˜
    print("\n" + "=" * 80)
    print("ğŸš¨ é‡ç‚¹åˆ†æï¼šå‚æ•°åä¸å­˜åœ¨çš„é—®é¢˜")
    print("=" * 80)
    
    missing_params = analysis_result["å‚æ•°åä¸å­˜åœ¨"]
    if len(missing_params) > 0:
        # æŒ‰æ¨¡å—åˆ†ç»„
        module_groups = defaultdict(list)
        for param in missing_params:
            module_name = param['jittor_name'].split('.')[0]
            module_groups[module_name].append(param)
        
        for module_name, params in module_groups.items():
            print(f"\nğŸ”¸ {module_name} æ¨¡å—ç¼ºå¤±: {len(params)} ä¸ªå‚æ•°")
            for param in params[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   - {param['jittor_name']}")
            if len(params) > 3:
                print(f"   ... è¿˜æœ‰ {len(params) - 3} ä¸ª")
    
    # é‡ç‚¹åˆ†æï¼šå½¢çŠ¶ä¸åŒ¹é…çš„é—®é¢˜
    print("\n" + "=" * 80)
    print("ğŸš¨ é‡ç‚¹åˆ†æï¼šå½¢çŠ¶ä¸åŒ¹é…çš„é—®é¢˜")
    print("=" * 80)
    
    shape_mismatch = analysis_result["å½¢çŠ¶ä¸åŒ¹é…"]
    if len(shape_mismatch) > 0:
        for item in shape_mismatch:
            print(f"\nâŒ {item['jittor_name']}")
            print(f"   PyTorch: {item['pytorch_shape']}")
            print(f"   Jittor: {item['jittor_shape']}")
            print(f"   å·®å¼‚: {[p-j for p, j in zip(item['pytorch_shape'], item['jittor_shape']) if len(item['pytorch_shape']) == len(item['jittor_shape'])]}")
    
    return analysis_result


def compare_jittor_pytorch_parameters():
    """å¯¹æ¯”Jittorå’ŒPyTorchçš„å‚æ•°å"""
    print("\n" + "=" * 80)
    print("ğŸ” å¯¹æ¯”Jittorå’ŒPyTorchçš„å‚æ•°å")
    print("=" * 80)
    
    # åŠ è½½PyTorch checkpoint
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    pytorch_state_dict = checkpoint.get('state_dict', checkpoint)
    
    # åˆ›å»ºJittoræ¨¡å‹
    jittor_model = create_nanodet_model()
    
    # è·å–å‚æ•°ååˆ—è¡¨
    pytorch_names = set()
    for name in pytorch_state_dict.keys():
        clean_name = name
        if clean_name.startswith("model."):
            clean_name = clean_name[6:]
        if not clean_name.startswith("avg_") and "num_batches_tracked" not in clean_name:
            pytorch_names.add(clean_name)
    
    jittor_names = set()
    for name, param in jittor_model.named_parameters():
        jittor_names.add(name)
    
    print(f"PyTorchæœ‰æ•ˆå‚æ•°å: {len(pytorch_names)} ä¸ª")
    print(f"Jittorå‚æ•°å: {len(jittor_names)} ä¸ª")
    
    # æ‰¾å‡ºå·®å¼‚
    only_in_pytorch = pytorch_names - jittor_names
    only_in_jittor = jittor_names - pytorch_names
    common = pytorch_names & jittor_names
    
    print(f"\nâœ… å…±åŒå‚æ•°: {len(common)} ä¸ª")
    print(f"âŒ åªåœ¨PyTorchä¸­: {len(only_in_pytorch)} ä¸ª")
    print(f"âŒ åªåœ¨Jittorä¸­: {len(only_in_jittor)} ä¸ª")
    
    if len(only_in_pytorch) > 0:
        print(f"\nğŸ”¸ åªåœ¨PyTorchä¸­çš„å‚æ•° (å‰10ä¸ª):")
        for i, name in enumerate(sorted(only_in_pytorch)[:10]):
            print(f"   {i+1}. {name}")
    
    if len(only_in_jittor) > 0:
        print(f"\nğŸ”¸ åªåœ¨Jittorä¸­çš„å‚æ•° (å‰10ä¸ª):")
        for i, name in enumerate(sorted(only_in_jittor)[:10]):
            print(f"   {i+1}. {name}")
    
    return {
        "common": common,
        "only_pytorch": only_in_pytorch,
        "only_jittor": only_in_jittor
    }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ·±åº¦åˆ†æå‚æ•°åŠ è½½å¤±è´¥åŸå› ")
    
    # è¯¦ç»†åˆ†æå‚æ•°ä¸åŒ¹é…
    analysis_result = analyze_parameter_mismatch()
    
    # å¯¹æ¯”å‚æ•°åå·®å¼‚
    name_comparison = compare_jittor_pytorch_parameters()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“‹ é—®é¢˜æ€»ç»“")
    print("=" * 80)
    
    total_failed = (len(analysis_result["è·³è¿‡_BatchNormç»Ÿè®¡"]) + 
                   len(analysis_result["è·³è¿‡_æƒé‡å¹³å‡"]) + 
                   len(analysis_result["è·³è¿‡_aux_head"]) + 
                   len(analysis_result["å½¢çŠ¶ä¸åŒ¹é…"]) + 
                   len(analysis_result["å‚æ•°åä¸å­˜åœ¨"]))
    
    print(f"âœ… æˆåŠŸåŠ è½½: {len(analysis_result['æˆåŠŸåŠ è½½'])} ä¸ª")
    print(f"âŒ æ€»å¤±è´¥æ•°: {total_failed} ä¸ª")
    print(f"   - BatchNormç»Ÿè®¡: {len(analysis_result['è·³è¿‡_BatchNormç»Ÿè®¡'])} ä¸ª (å¯å¿½ç•¥)")
    print(f"   - æƒé‡å¹³å‡: {len(analysis_result['è·³è¿‡_æƒé‡å¹³å‡'])} ä¸ª (å¯å¿½ç•¥)")
    print(f"   - aux_head: {len(analysis_result['è·³è¿‡_aux_head'])} ä¸ª (éœ€ä¿®å¤)")
    print(f"   - å½¢çŠ¶ä¸åŒ¹é…: {len(analysis_result['å½¢çŠ¶ä¸åŒ¹é…'])} ä¸ª (éœ€ä¿®å¤)")
    print(f"   - å‚æ•°åä¸å­˜åœ¨: {len(analysis_result['å‚æ•°åä¸å­˜åœ¨'])} ä¸ª (éœ€ä¿®å¤)")
    
    critical_failures = (len(analysis_result["å½¢çŠ¶ä¸åŒ¹é…"]) + 
                        len(analysis_result["å‚æ•°åä¸å­˜åœ¨"]))
    
    print(f"\nğŸš¨ å…³é”®å¤±è´¥æ•°: {critical_failures} ä¸ª (å¿…é¡»ä¿®å¤)")
    
    if critical_failures > 0:
        print("âŒ æƒé‡åŠ è½½å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¿®å¤ï¼")
        return False
    else:
        print("âœ… æƒé‡åŠ è½½åŸºæœ¬æ­£å¸¸")
        return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
