#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é€æ­¥è°ƒè¯•åå¤„ç†ç®—æ³•
æ‰¾å‡ºä¸ºä»€ä¹ˆæ¨¡å‹è¾“å‡ºé«˜ç½®ä¿¡åº¦ä½†åå¤„ç†åæ²¡æœ‰æ£€æµ‹ç»“æœ
"""

import os
import sys
import cv2
import torch
import jittor as jt
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus
from nanodet.util.postprocess_pytorch_aligned import nanodet_postprocess


def create_nanodet_model():
    """åˆ›å»ºNanoDetæ¨¡å‹"""
    print("åˆ›å»ºNanoDetæ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®å­—å…¸
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    # åˆ›å»ºaux_headé…ç½®
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    return model


def load_pytorch_weights_100_percent(model, checkpoint_path):
    """100%ä¿®å¤çš„æƒé‡åŠ è½½å‡½æ•°"""
    print(f"åŠ è½½PyTorch checkpoint: {checkpoint_path}")
    
    # ä½¿ç”¨PyTorchåŠ è½½checkpoint
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    # è·å–Jittoræ¨¡å‹çš„å‚æ•°å­—å…¸
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    # 100%ä¿®å¤çš„æƒé‡åŠ è½½
    loaded_count = 0
    skipped_count = 0
    scale_fixed_count = 0
    
    for pytorch_name, pytorch_param in state_dict.items():
        # ç§»é™¤PyTorchç‰¹æœ‰çš„å‰ç¼€
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]  # ç§»é™¤"model."å‰ç¼€
        
        # è·³è¿‡Jittorä¸­ä¸å­˜åœ¨çš„BatchNormç»Ÿè®¡å‚æ•°
        if "num_batches_tracked" in jittor_name:
            skipped_count += 1
            continue
        
        # è·³è¿‡avg_modelå‚æ•°ï¼ˆæƒé‡å¹³å‡ç›¸å…³ï¼‰
        if jittor_name.startswith("avg_"):
            skipped_count += 1
            continue
        
        # ç‰¹æ®Šå¤„ç†ï¼šdistribution_project.projectå‚æ•°åœ¨Jittorä¸­ä¸å­˜åœ¨ï¼ˆå·²æ”¹ä¸ºéå‚æ•°ï¼‰
        if "distribution_project.project" in jittor_name:
            skipped_count += 1
            continue
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            # æ£€æŸ¥å½¢çŠ¶åŒ¹é…
            if list(pytorch_param.shape) == list(jittor_param.shape):
                # è½¬æ¢å¹¶åŠ è½½å‚æ•°
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                # ç‰¹æ®Šå¤„ç†Scaleå‚æ•°ï¼šPyTorchæ ‡é‡ -> Jittor 1ç»´å¼ é‡
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
                loaded_count += 1
                scale_fixed_count += 1
    
    print(f"âœ… æˆåŠŸåŠ è½½: {loaded_count} ä¸ªå‚æ•°")
    print(f"âœ… Scaleå‚æ•°ä¿®å¤: {scale_fixed_count} ä¸ª")
    print(f"â­ï¸ è·³è¿‡æ— å…³: {skipped_count} ä¸ªå‚æ•°")
    
    return True


def debug_postprocess_step_by_step():
    """é€æ­¥è°ƒè¯•åå¤„ç†ç®—æ³•"""
    print("ğŸ” å¼€å§‹é€æ­¥è°ƒè¯•åå¤„ç†ç®—æ³•")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_nanodet_model()
    
    # åŠ è½½æƒé‡
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    load_pytorch_weights_100_percent(model, checkpoint_path)
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img_path = "data/VOCdevkit/VOC2007/JPEGImages/000001.jpg"
    
    if not os.path.exists(test_img_path):
        print(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_img_path}")
        # åˆ›å»ºä¸€ä¸ªéšæœºå›¾åƒè¿›è¡Œæµ‹è¯•
        test_img = np.random.randint(0, 255, (320, 320, 3), dtype=np.uint8)
        print("âœ“ ä½¿ç”¨éšæœºå›¾åƒè¿›è¡Œæµ‹è¯•")
    else:
        test_img = cv2.imread(test_img_path)
        test_img = cv2.resize(test_img, (320, 320))
        print(f"âœ“ ä½¿ç”¨çœŸå®å›¾åƒè¿›è¡Œæµ‹è¯•: {test_img_path}")
    
    # é¢„å¤„ç†
    img_tensor = jt.array(test_img.transpose(2, 0, 1)).unsqueeze(0).float()
    
    # ä½¿ç”¨ImageNetå½’ä¸€åŒ–ï¼ˆä¹‹å‰æµ‹è¯•æ˜¾ç¤ºè¿™æ˜¯æœ€ä½³æ–¹å¼ï¼‰
    mean = jt.array([123.675, 116.28, 103.53]).reshape(1, 3, 1, 1)
    std = jt.array([58.395, 57.12, 57.375]).reshape(1, 3, 1, 1)
    img_normalized = (img_tensor - mean) / std
    
    print(f"\nğŸ“Š è¾“å…¥åˆ†æ:")
    print(f"   è¾“å…¥å½¢çŠ¶: {img_normalized.shape}")
    print(f"   è¾“å…¥æ•°å€¼èŒƒå›´: [{img_normalized.min():.6f}, {img_normalized.max():.6f}]")
    
    # æ¨¡å‹æ¨ç†
    with jt.no_grad():
        output = model(img_normalized)
    
    print(f"\nğŸ“Š æ¨¡å‹è¾“å‡ºåˆ†æ:")
    print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   è¾“å‡ºæ•°å€¼èŒƒå›´: [{output.min():.6f}, {output.max():.6f}]")
    
    # åˆ†ç¦»åˆ†ç±»å’Œå›å½’é¢„æµ‹
    cls_preds = output[:, :, :20]  # [B, N, 20]
    reg_preds = output[:, :, 20:]  # [B, N, 32]
    
    print(f"\nğŸ“Š åˆ†ç¦»åçš„é¢„æµ‹:")
    print(f"   åˆ†ç±»é¢„æµ‹å½¢çŠ¶: {cls_preds.shape}")
    print(f"   åˆ†ç±»é¢„æµ‹èŒƒå›´: [{cls_preds.min():.6f}, {cls_preds.max():.6f}]")
    print(f"   å›å½’é¢„æµ‹å½¢çŠ¶: {reg_preds.shape}")
    print(f"   å›å½’é¢„æµ‹èŒƒå›´: [{reg_preds.min():.6f}, {reg_preds.max():.6f}]")
    
    # è®¡ç®—sigmoidåçš„åˆ†ç±»åˆ†æ•°
    cls_scores = jt.sigmoid(cls_preds)
    print(f"   Sigmoidååˆ†ç±»åˆ†æ•°èŒƒå›´: [{cls_scores.min():.6f}, {cls_scores.max():.6f}]")
    print(f"   æœ€é«˜åˆ†ç±»åˆ†æ•°: {cls_scores.max():.6f}")
    
    # ç»Ÿè®¡é«˜ç½®ä¿¡åº¦é¢„æµ‹
    high_conf_mask = cls_scores > 0.5
    high_conf_count = high_conf_mask.sum()
    print(f"   ç½®ä¿¡åº¦>0.5çš„é¢„æµ‹æ•°: {high_conf_count}")
    
    if high_conf_count > 0:
        high_conf_indices = jt.where(high_conf_mask)
        print(f"   é«˜ç½®ä¿¡åº¦é¢„æµ‹ä½ç½®: æ‰¹æ¬¡{high_conf_indices[0][:5]}, é”šç‚¹{high_conf_indices[1][:5]}, ç±»åˆ«{high_conf_indices[2][:5]}")
    
    # é€æ­¥è°ƒè¯•åå¤„ç†
    print(f"\nğŸ” é€æ­¥è°ƒè¯•åå¤„ç†:")
    
    # æ­¥éª¤1: è°ƒç”¨åå¤„ç†å‡½æ•°
    print(f"\n1ï¸âƒ£ è°ƒç”¨nanodet_postprocesså‡½æ•°:")
    try:
        # æµ‹è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
        test_thresholds = [0.001, 0.01, 0.05, 0.1]

        for threshold in test_thresholds:
            print(f"\n   æµ‹è¯•é˜ˆå€¼ {threshold}:")
            results = nanodet_postprocess(cls_preds, reg_preds, (320, 320), score_thr=threshold)
            print(f"     âœ“ åå¤„ç†å‡½æ•°è°ƒç”¨æˆåŠŸ")
            print(f"     ç»“æœæ•°é‡: {len(results)}")

            for i, (dets, labels) in enumerate(results):
                print(f"     æ‰¹æ¬¡{i}: {len(dets)}ä¸ªæ£€æµ‹, {len(labels)}ä¸ªæ ‡ç­¾")
                if len(dets) > 0:
                    print(f"       æ£€æµ‹æ¡†å½¢çŠ¶: {dets.shape}")
                    print(f"       æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
                    print(f"       ç½®ä¿¡åº¦èŒƒå›´: [{dets[:, 4].min():.6f}, {dets[:, 4].max():.6f}]")
                    # æ˜¾ç¤ºå‰å‡ ä¸ªæ£€æµ‹ç»“æœ
                    for j in range(min(3, len(dets))):
                        bbox = dets[j][:4]
                        score = dets[j][4]
                        label = labels[j]
                        print(f"       æ£€æµ‹{j+1}: bbox=[{bbox[0]:.1f},{bbox[1]:.1f},{bbox[2]:.1f},{bbox[3]:.1f}], score={score:.4f}, label={label}")
                else:
                    print(f"       âŒ æ²¡æœ‰æ£€æµ‹ç»“æœ")

    except Exception as e:
        print(f"   âŒ åå¤„ç†å‡½æ•°è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æ­¥éª¤2: æµ‹è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
    print(f"\n2ï¸âƒ£ æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼:")
    thresholds = [0.001, 0.01, 0.05, 0.1, 0.3, 0.5]
    
    for threshold in thresholds:
        # ç®€å•çš„é˜ˆå€¼è¿‡æ»¤
        valid_mask = cls_scores.max(dim=-1)[0] > threshold
        valid_count = valid_mask.sum()
        print(f"   é˜ˆå€¼{threshold:5.3f}: {valid_count}ä¸ªæœ‰æ•ˆé¢„æµ‹")
    
    # æ­¥éª¤3: æ‰‹åŠ¨æ£€æŸ¥anchorç”Ÿæˆ
    print(f"\n3ï¸âƒ£ æ£€æŸ¥anchorç”Ÿæˆ:")
    
    # è¿™é‡Œéœ€è¦å®ç°anchorç”Ÿæˆçš„æ£€æŸ¥
    # æš‚æ—¶è·³è¿‡ï¼Œä¸“æ³¨äºåå¤„ç†é€»è¾‘
    
    print(f"\nâœ… åå¤„ç†è°ƒè¯•å®Œæˆ")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é€æ­¥è°ƒè¯•åå¤„ç†ç®—æ³•")
    
    success = debug_postprocess_step_by_step()
    
    if success:
        print("\nâœ… åå¤„ç†è°ƒè¯•å®Œæˆ")
    else:
        print("\nâŒ åå¤„ç†è°ƒè¯•å¤±è´¥")
    
    return success


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
