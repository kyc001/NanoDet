#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éªŒè¯æƒé‡è½¬æ¢è¿‡ç¨‹
æ£€æŸ¥PyTorchåˆ°Jittorçš„æƒé‡è½¬æ¢æ˜¯å¦æ­£ç¡®
"""

import torch
import jittor as jt
import numpy as np


def test_basic_conversion():
    """æµ‹è¯•åŸºç¡€çš„PyTorchåˆ°Jittorè½¬æ¢"""
    print("ğŸ” æµ‹è¯•åŸºç¡€PyTorchåˆ°Jittorè½¬æ¢")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_cases = [
        ("æ ‡é‡", torch.tensor(3.14159)),
        ("1Då¼ é‡", torch.randn(10)),
        ("2Då¼ é‡", torch.randn(3, 4)),
        ("3Då¼ é‡", torch.randn(2, 3, 4)),
        ("4Då¼ é‡", torch.randn(1, 3, 32, 32)),
    ]
    
    for name, pytorch_tensor in test_cases:
        print(f"\næµ‹è¯• {name}:")
        print(f"  PyTorch: {pytorch_tensor.shape}, dtype={pytorch_tensor.dtype}")
        
        # æ–¹æ³•1: ç›´æ¥è½¬æ¢
        jittor_array1 = jt.array(pytorch_tensor.detach().numpy())
        print(f"  Jittoræ–¹æ³•1: {jittor_array1.shape}, dtype={jittor_array1.dtype}")
        
        # æ–¹æ³•2: æ˜¾å¼numpyè½¬æ¢
        numpy_array = pytorch_tensor.detach().numpy()
        jittor_array2 = jt.array(numpy_array)
        print(f"  Jittoræ–¹æ³•2: {jittor_array2.shape}, dtype={jittor_array2.dtype}")
        
        # æ£€æŸ¥æ•°å€¼ä¸€è‡´æ€§
        diff1 = np.abs(pytorch_tensor.detach().numpy() - jittor_array1.numpy()).max()
        diff2 = np.abs(pytorch_tensor.detach().numpy() - jittor_array2.numpy()).max()
        
        print(f"  å·®å¼‚æ–¹æ³•1: {diff1:.10f}")
        print(f"  å·®å¼‚æ–¹æ³•2: {diff2:.10f}")
        
        if diff1 < 1e-6 and diff2 < 1e-6:
            print(f"  âœ… è½¬æ¢æ­£ç¡®")
        else:
            print(f"  âŒ è½¬æ¢æœ‰è¯¯")


def test_parameter_assignment():
    """æµ‹è¯•å‚æ•°èµ‹å€¼è¿‡ç¨‹"""
    print("\nğŸ” æµ‹è¯•å‚æ•°èµ‹å€¼è¿‡ç¨‹")
    print("=" * 50)
    
    # åˆ›å»ºç®€å•çš„Jittoræ¨¡å‹
    class SimpleModel(jt.nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = jt.nn.Conv2d(3, 16, 3)
            self.bn = jt.nn.BatchNorm2d(16)
    
    model = SimpleModel()
    
    # åˆ›å»ºPyTorchæƒé‡
    pytorch_conv_weight = torch.randn(16, 3, 3, 3)
    pytorch_conv_bias = torch.randn(16)
    pytorch_bn_weight = torch.randn(16)
    pytorch_bn_bias = torch.randn(16)
    pytorch_bn_mean = torch.randn(16)
    pytorch_bn_var = torch.randn(16)
    
    print("åŸå§‹Jittorå‚æ•°:")
    for name, param in model.named_parameters():
        print(f"  {name}: {param.shape}, èŒƒå›´[{param.min():.6f}, {param.max():.6f}]")
    
    # æµ‹è¯•ä¸åŒçš„èµ‹å€¼æ–¹æ³•
    print("\næµ‹è¯•èµ‹å€¼æ–¹æ³•:")
    
    # æ–¹æ³•1: ç›´æ¥assign
    print("æ–¹æ³•1: ç›´æ¥assign")
    try:
        model.conv.weight.assign(jt.array(pytorch_conv_weight.detach().numpy()))
        model.conv.bias.assign(jt.array(pytorch_conv_bias.detach().numpy()))
        model.bn.weight.assign(jt.array(pytorch_bn_weight.detach().numpy()))
        model.bn.bias.assign(jt.array(pytorch_bn_bias.detach().numpy()))
        model.bn.running_mean.assign(jt.array(pytorch_bn_mean.detach().numpy()))
        model.bn.running_var.assign(jt.array(pytorch_bn_var.detach().numpy()))
        
        print("  âœ… assignæˆåŠŸ")
        
        # éªŒè¯èµ‹å€¼ç»“æœ
        conv_weight_diff = np.abs(pytorch_conv_weight.detach().numpy() - model.conv.weight.numpy()).max()
        conv_bias_diff = np.abs(pytorch_conv_bias.detach().numpy() - model.conv.bias.numpy()).max()
        bn_weight_diff = np.abs(pytorch_bn_weight.detach().numpy() - model.bn.weight.numpy()).max()
        bn_bias_diff = np.abs(pytorch_bn_bias.detach().numpy() - model.bn.bias.numpy()).max()
        bn_mean_diff = np.abs(pytorch_bn_mean.detach().numpy() - model.bn.running_mean.numpy()).max()
        bn_var_diff = np.abs(pytorch_bn_var.detach().numpy() - model.bn.running_var.numpy()).max()
        
        print(f"  conv.weightå·®å¼‚: {conv_weight_diff:.10f}")
        print(f"  conv.biaså·®å¼‚: {conv_bias_diff:.10f}")
        print(f"  bn.weightå·®å¼‚: {bn_weight_diff:.10f}")
        print(f"  bn.biaså·®å¼‚: {bn_bias_diff:.10f}")
        print(f"  bn.running_meanå·®å¼‚: {bn_mean_diff:.10f}")
        print(f"  bn.running_varå·®å¼‚: {bn_var_diff:.10f}")
        
        max_diff = max(conv_weight_diff, conv_bias_diff, bn_weight_diff, bn_bias_diff, bn_mean_diff, bn_var_diff)
        if max_diff < 1e-6:
            print(f"  âœ… èµ‹å€¼æ•°å€¼æ­£ç¡®")
        else:
            print(f"  âŒ èµ‹å€¼æ•°å€¼æœ‰è¯¯ï¼Œæœ€å¤§å·®å¼‚: {max_diff:.10f}")
            
    except Exception as e:
        print(f"  âŒ assignå¤±è´¥: {e}")


def test_real_weight_loading():
    """æµ‹è¯•çœŸå®æƒé‡åŠ è½½è¿‡ç¨‹"""
    print("\nğŸ” æµ‹è¯•çœŸå®æƒé‡åŠ è½½è¿‡ç¨‹")
    print("=" * 50)
    
    # åŠ è½½çœŸå®çš„PyTorchæƒé‡
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    
    try:
        ckpt = torch.load(checkpoint_path, map_location='cpu')
        state_dict = ckpt.get('state_dict', ckpt)
        
        print(f"âœ“ æˆåŠŸåŠ è½½PyTorchæƒé‡ï¼ŒåŒ…å« {len(state_dict)} ä¸ªå‚æ•°")
        
        # é€‰æ‹©å‡ ä¸ªå…¸å‹å‚æ•°è¿›è¡Œæµ‹è¯•
        test_params = [
            "model.backbone.conv1.0.weight",
            "model.backbone.conv1.1.weight", 
            "model.backbone.conv1.1.bias",
            "model.backbone.conv1.1.running_mean",
            "model.backbone.conv1.1.running_var",
        ]
        
        for param_name in test_params:
            if param_name in state_dict:
                pytorch_param = state_dict[param_name]
                print(f"\næµ‹è¯•å‚æ•°: {param_name}")
                print(f"  PyTorch: {pytorch_param.shape}, dtype={pytorch_param.dtype}")
                print(f"  èŒƒå›´: [{pytorch_param.min():.6f}, {pytorch_param.max():.6f}]")
                
                # è½¬æ¢åˆ°Jittor
                jittor_param = jt.array(pytorch_param.detach().numpy())
                print(f"  Jittor: {jittor_param.shape}, dtype={jittor_param.dtype}")
                print(f"  èŒƒå›´: [{jittor_param.min():.6f}, {jittor_param.max():.6f}]")
                
                # æ£€æŸ¥å·®å¼‚
                diff = np.abs(pytorch_param.detach().numpy() - jittor_param.numpy()).max()
                print(f"  è½¬æ¢å·®å¼‚: {diff:.10f}")
                
                if diff < 1e-6:
                    print(f"  âœ… è½¬æ¢æ­£ç¡®")
                else:
                    print(f"  âŒ è½¬æ¢æœ‰è¯¯")
                    
                    # è¯¦ç»†åˆ†æå·®å¼‚
                    pytorch_np = pytorch_param.detach().numpy()
                    jittor_np = jittor_param.numpy()
                    
                    print(f"    PyTorchç»Ÿè®¡: å‡å€¼={pytorch_np.mean():.6f}, æ ‡å‡†å·®={pytorch_np.std():.6f}")
                    print(f"    Jittorç»Ÿè®¡: å‡å€¼={jittor_np.mean():.6f}, æ ‡å‡†å·®={jittor_np.std():.6f}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®ç±»å‹é—®é¢˜
                    print(f"    PyTorch numpy dtype: {pytorch_np.dtype}")
                    print(f"    Jittor numpy dtype: {jittor_np.dtype}")
            else:
                print(f"âš ï¸ å‚æ•° {param_name} ä¸å­˜åœ¨")
                
    except Exception as e:
        print(f"âŒ åŠ è½½PyTorchæƒé‡å¤±è´¥: {e}")


def test_scale_parameter_issue():
    """æµ‹è¯•Scaleå‚æ•°é—®é¢˜"""
    print("\nğŸ” æµ‹è¯•Scaleå‚æ•°é—®é¢˜")
    print("=" * 50)
    
    # æ¨¡æ‹ŸPyTorchçš„æ ‡é‡å‚æ•°
    pytorch_scale = torch.tensor(1.0)  # æ ‡é‡
    print(f"PyTorch scale: {pytorch_scale.shape}, å€¼={pytorch_scale.item()}")
    
    # æ¨¡æ‹ŸJittorçš„Scaleå‚æ•°
    jittor_scale = jt.array([1.0])  # 1ç»´æ•°ç»„
    print(f"Jittor scale: {jittor_scale.shape}, å€¼={jittor_scale.numpy()}")
    
    # æµ‹è¯•è½¬æ¢
    print("\nè½¬æ¢æµ‹è¯•:")
    
    # æ–¹æ³•1: ç›´æ¥è½¬æ¢ï¼ˆä¼šå¤±è´¥ï¼‰
    try:
        converted1 = jt.array(pytorch_scale.detach().numpy())
        print(f"æ–¹æ³•1æˆåŠŸ: {converted1.shape}, å€¼={converted1.numpy()}")
    except Exception as e:
        print(f"æ–¹æ³•1å¤±è´¥: {e}")
    
    # æ–¹æ³•2: åŒ…è£…æˆæ•°ç»„
    try:
        if len(pytorch_scale.shape) == 0:  # æ ‡é‡
            converted2 = jt.array([pytorch_scale.detach().numpy()])
        else:
            converted2 = jt.array(pytorch_scale.detach().numpy())
        print(f"æ–¹æ³•2æˆåŠŸ: {converted2.shape}, å€¼={converted2.numpy()}")
        
        # èµ‹å€¼æµ‹è¯•
        jittor_scale.assign(converted2)
        print(f"èµ‹å€¼å: {jittor_scale.shape}, å€¼={jittor_scale.numpy()}")
        
    except Exception as e:
        print(f"æ–¹æ³•2å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹éªŒè¯æƒé‡è½¬æ¢è¿‡ç¨‹")
    
    # åŸºç¡€è½¬æ¢æµ‹è¯•
    test_basic_conversion()
    
    # å‚æ•°èµ‹å€¼æµ‹è¯•
    test_parameter_assignment()
    
    # çœŸå®æƒé‡åŠ è½½æµ‹è¯•
    test_real_weight_loading()
    
    # Scaleå‚æ•°é—®é¢˜æµ‹è¯•
    test_scale_parameter_issue()
    
    print(f"\nâœ… éªŒè¯å®Œæˆ")


if __name__ == '__main__':
    main()
