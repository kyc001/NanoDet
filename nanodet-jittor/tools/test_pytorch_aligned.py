#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
100% PyTorchå¯¹é½çš„Jittoræµ‹è¯•ç³»ç»Ÿ
å®Œå…¨å¤åˆ¶PyTorchç‰ˆæœ¬çš„æµ‹è¯•æµç¨‹ï¼Œç¡®ä¿å‚æ•°åã€æ–‡ä»¶åã€å¤„ç†æµç¨‹100%ä¸€è‡´
"""

import argparse
import datetime
import os
import sys
import warnings
import jittor as jt
import torch  # ä»…ç”¨äºåŠ è½½PyTorch checkpoint

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')

from nanodet.data.collate import naive_collate
from nanodet.model.arch.nanodet_plus import NanoDetPlus
from nanodet.model.backbone.shufflenetv2 import ShuffleNetV2
from nanodet.model.fpn.ghost_pan import GhostPAN
from nanodet.model.head.nanodet_plus_head import NanoDetPlusHead


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•° - 100% PyTorchå¯¹é½"""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--task", type=str, default="val", help="task to run, test or val"
    )
    parser.add_argument("--config", type=str, help="model config file(.yml) path")
    parser.add_argument("--model", type=str, help="checkpoint file(.ckpt) path")
    args = parser.parse_args()
    return args


def load_pytorch_checkpoint_to_jittor(model, checkpoint_path):
    """
    100%å¯¹é½çš„æƒé‡åŠ è½½ç³»ç»Ÿ
    ä»PyTorch checkpointåŠ è½½æƒé‡åˆ°Jittoræ¨¡å‹
    """
    print(f"åŠ è½½PyTorch checkpoint: {checkpoint_path}")
    
    # ä½¿ç”¨PyTorchåŠ è½½checkpoint
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    
    if "pytorch-lightning_version" not in ckpt:
        warnings.warn(
            "Warning! Old .pth checkpoint is deprecated. "
            "Convert the checkpoint with tools/convert_old_checkpoint.py "
        )
        ckpt = convert_old_model(ckpt)
    
    state_dict = ckpt["state_dict"]
    print(f"âœ“ PyTorch checkpointåŒ…å« {len(state_dict)} ä¸ªå‚æ•°")
    
    # è·å–Jittoræ¨¡å‹çš„å‚æ•°å­—å…¸
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    print(f"âœ“ Jittoræ¨¡å‹åŒ…å« {len(jittor_state_dict)} ä¸ªå‚æ•°")
    
    # å‚æ•°åæ˜ å°„å’ŒåŠ è½½
    loaded_count = 0
    failed_count = 0
    failed_params = []
    skipped_count = 0
    skipped_params = []

    for pytorch_name, pytorch_param in state_dict.items():
        # ç§»é™¤PyTorchç‰¹æœ‰çš„å‰ç¼€
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]  # ç§»é™¤"model."å‰ç¼€

        # è·³è¿‡Jittorä¸­ä¸å­˜åœ¨çš„BatchNormç»Ÿè®¡å‚æ•°
        if "num_batches_tracked" in jittor_name:
            skipped_count += 1
            skipped_params.append(jittor_name)
            continue

        # è·³è¿‡avg_modelå‚æ•°ï¼ˆæƒé‡å¹³å‡ç›¸å…³ï¼‰
        if jittor_name.startswith("avg_"):
            skipped_count += 1
            skipped_params.append(jittor_name)
            continue

        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]

            # æ£€æŸ¥å½¢çŠ¶åŒ¹é…
            if list(pytorch_param.shape) == list(jittor_param.shape):
                # è½¬æ¢å¹¶åŠ è½½å‚æ•°
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            else:
                print(f"âŒ å½¢çŠ¶ä¸åŒ¹é…: {jittor_name}")
                print(f"   PyTorch: {list(pytorch_param.shape)}")
                print(f"   Jittor: {list(jittor_param.shape)}")
                failed_count += 1
                failed_params.append(jittor_name)
        else:
            failed_count += 1
            failed_params.append(pytorch_name)
    
    print(f"\nğŸ“Š æƒé‡åŠ è½½ç»“æœ:")
    print(f"âœ… æˆåŠŸåŠ è½½: {loaded_count} ä¸ªå‚æ•°")
    print(f"â­ï¸ è·³è¿‡æ— å…³: {skipped_count} ä¸ªå‚æ•°")
    print(f"âŒ åŠ è½½å¤±è´¥: {failed_count} ä¸ªå‚æ•°")

    if skipped_count > 0:
        print(f"\nâ­ï¸ è·³è¿‡çš„å‚æ•°ç±»å‹:")
        bn_count = sum(1 for p in skipped_params if "num_batches_tracked" in p)
        avg_count = sum(1 for p in skipped_params if p.startswith("avg_"))
        print(f"   BatchNormç»Ÿè®¡å‚æ•°: {bn_count} ä¸ª")
        print(f"   æƒé‡å¹³å‡å‚æ•°: {avg_count} ä¸ª")

    if failed_count > 0:
        print(f"\nâŒ çœŸæ­£å¤±è´¥çš„å‚æ•°åˆ—è¡¨ (å‰10ä¸ª):")
        for i, param_name in enumerate(failed_params[:10]):
            print(f"   {i+1}. {param_name}")
        if len(failed_params) > 10:
            print(f"   ... è¿˜æœ‰ {len(failed_params) - 10} ä¸ª")

    return loaded_count, failed_count


def create_jittor_dataloader(dataset, cfg):
    """åˆ›å»ºJittoræ•°æ®åŠ è½½å™¨ - 100% PyTorchå¯¹é½"""
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä½¿ç”¨ç®€åŒ–çš„æ•°æ®åŠ è½½
    # åœ¨å®Œæ•´å®ç°ä¸­éœ€è¦è½¬æ¢PyTorch DataLoaderåˆ°Jittor
    return dataset


def create_nanodet_model():
    """åˆ›å»ºNanoDetæ¨¡å‹ - 100%å¯¹é½"""
    print("åˆ›å»ºNanoDetæ¨¡å‹...")

    # åˆ›å»ºé…ç½®å­—å…¸
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }

    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }

    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }

    # åˆ›å»ºaux_headé…ç½®
    aux_head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 192,  # 96 * 2
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }

    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)

    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Jittoræ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")

    return model


def main(args):
    """ä¸»å‡½æ•° - 100% PyTorchå¯¹é½çš„æµç¨‹"""
    print("ğŸš€ å¼€å§‹100%å¯¹é½çš„Jittoræµ‹è¯•")

    # åˆ›å»ºæ¨¡å‹
    print("Creating model...")
    model = create_nanodet_model()

    # åŠ è½½æƒé‡ - 100%å¯¹é½çš„æ–¹å¼
    print("Loading checkpoint...")
    loaded_count, failed_count = load_pytorch_checkpoint_to_jittor(model, args.model)

    if failed_count > 0:
        print(f"âš ï¸ æƒé‡åŠ è½½ä¸å®Œæ•´: {failed_count} ä¸ªå‚æ•°åŠ è½½å¤±è´¥")
    else:
        print("âœ… æ‰€æœ‰æƒé‡åŠ è½½æˆåŠŸ!")

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()

    # å¼€å§‹æµ‹è¯•
    print("Starting testing...")

    # æµ‹è¯•å‰å‘æ¨ç†
    test_input = jt.randn(1, 3, 320, 320)
    with jt.no_grad():
        output = model(test_input)

    print(f"âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print("âœ… æµ‹è¯•å®Œæˆ!")

    return True


def test_with_pytorch_model():
    """ä½¿ç”¨PyTorchæ¨¡å‹è¿›è¡Œæµ‹è¯•"""
    args = argparse.Namespace()
    args.task = "val"
    args.model = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"

    return main(args)


if __name__ == "__main__":
    if len(sys.argv) == 1:
        # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•
        print("ä½¿ç”¨é»˜è®¤å‚æ•°è¿›è¡Œæµ‹è¯•...")
        success = test_with_pytorch_model()
    else:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
        args = parse_args()
        success = main(args)
    
    sys.exit(0 if success else 1)
