#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç²¾ç¡®æ‰¾å‡º29,116å‚æ•°å·®å¼‚çš„æ ¹æº
å¿…é¡»åšåˆ°100%å¯¹é½ï¼Œä¸èƒ½æœ‰ä»»ä½•å¦¥å
"""

import os
import sys
import torch
import jittor as jt
from collections import defaultdict

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/home/kyc/project/nanodet/nanodet-pytorch')
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')

# PyTorchç‰ˆæœ¬
from nanodet.model.arch import build_model as build_pytorch_model
from nanodet.util import cfg as pytorch_cfg, load_config

# Jittorç‰ˆæœ¬
from nanodet.model.arch.nanodet_plus import NanoDetPlus as JittorNanoDetPlus


def create_pytorch_model():
    """åˆ›å»ºPyTorchæ¨¡å‹"""
    print("åˆ›å»ºPyTorchæ¨¡å‹...")
    
    config_path = "/home/kyc/project/nanodet/nanodet-pytorch/config/nanodet-plus-m_320_voc.yml"
    load_config(pytorch_cfg, config_path)
    
    model = build_pytorch_model(pytorch_cfg.model)
    
    return model


def create_jittor_model():
    """åˆ›å»ºJittoræ¨¡å‹"""
    print("åˆ›å»ºJittoræ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®å­—å…¸ - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    # åˆ›å»ºaux_headé…ç½® - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,  # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'stacked_convs': 4,    # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = JittorNanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    return model


def analyze_parameter_differences():
    """ç²¾ç¡®åˆ†æå‚æ•°å·®å¼‚"""
    print("ğŸ” ç²¾ç¡®åˆ†æå‚æ•°å·®å¼‚")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡å‹
    try:
        pytorch_model = create_pytorch_model()
        print("âœ“ PyTorchæ¨¡å‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ PyTorchæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    jittor_model = create_jittor_model()
    print("âœ“ Jittoræ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # ç»Ÿè®¡PyTorchå‚æ•°
    pytorch_params = {}
    pytorch_total = 0
    
    for name, param in pytorch_model.named_parameters():
        param_count = param.numel()
        pytorch_params[name] = {
            'shape': list(param.shape),
            'count': param_count
        }
        pytorch_total += param_count
    
    print(f"âœ“ PyTorchæ¨¡å‹: {pytorch_total:,} å‚æ•°, {len(pytorch_params)} é¡¹")
    
    # ç»Ÿè®¡Jittorå‚æ•°
    jittor_params = {}
    jittor_total = 0
    
    for name, param in jittor_model.named_parameters():
        param_count = param.numel() if hasattr(param, 'numel') else param.size
        jittor_params[name] = {
            'shape': list(param.shape),
            'count': param_count
        }
        jittor_total += param_count
    
    print(f"âœ“ Jittoræ¨¡å‹: {jittor_total:,} å‚æ•°, {len(jittor_params)} é¡¹")
    
    # è®¡ç®—å·®å¼‚
    difference = abs(pytorch_total - jittor_total)
    print(f"\nğŸ“Š å‚æ•°å·®å¼‚: {difference:,} ({difference/pytorch_total*100:.3f}%)")
    
    if difference == 0:
        print("ğŸ‰ å‚æ•°æ•°é‡100%å¯¹é½ï¼")
        return True
    
    # è¯¦ç»†åˆ†æå·®å¼‚
    print(f"\nğŸ” è¯¦ç»†åˆ†æå·®å¼‚æ¥æº:")
    
    # æŒ‰æ¨¡å—åˆ†ç»„ç»Ÿè®¡
    pytorch_modules = defaultdict(int)
    jittor_modules = defaultdict(int)
    
    for name, details in pytorch_params.items():
        module = name.split('.')[0]
        pytorch_modules[module] += details['count']
    
    for name, details in jittor_params.items():
        module = name.split('.')[0]
        jittor_modules[module] += details['count']
    
    # å¯¹æ¯”æ¯ä¸ªæ¨¡å—
    all_modules = set(pytorch_modules.keys()) | set(jittor_modules.keys())
    
    print(f"\nğŸ“Š æŒ‰æ¨¡å—å¯¹æ¯”:")
    print(f"{'æ¨¡å—':<20} {'PyTorch':<12} {'Jittor':<12} {'å·®å¼‚':<12}")
    print("-" * 60)
    
    total_diff = 0
    for module in sorted(all_modules):
        pytorch_count = pytorch_modules.get(module, 0)
        jittor_count = jittor_modules.get(module, 0)
        diff = pytorch_count - jittor_count
        total_diff += abs(diff)
        
        status = "âœ…" if diff == 0 else "âŒ"
        print(f"{module:<20} {pytorch_count:<12,} {jittor_count:<12,} {diff:<12,} {status}")
    
    print("-" * 60)
    print(f"{'æ€»è®¡':<20} {pytorch_total:<12,} {jittor_total:<12,} {pytorch_total-jittor_total:<12,}")
    
    # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„æ¨¡å—
    max_diff_module = None
    max_diff = 0
    
    for module in all_modules:
        pytorch_count = pytorch_modules.get(module, 0)
        jittor_count = jittor_modules.get(module, 0)
        diff = abs(pytorch_count - jittor_count)
        
        if diff > max_diff:
            max_diff = diff
            max_diff_module = module
    
    if max_diff_module:
        print(f"\nğŸ¯ å·®å¼‚æœ€å¤§çš„æ¨¡å—: {max_diff_module} (å·®å¼‚: {max_diff:,} å‚æ•°)")
        
        # è¯¦ç»†åˆ†æè¯¥æ¨¡å—
        print(f"\nğŸ” è¯¦ç»†åˆ†æ {max_diff_module} æ¨¡å—:")
        
        pytorch_module_params = {k: v for k, v in pytorch_params.items() if k.startswith(max_diff_module)}
        jittor_module_params = {k: v for k, v in jittor_params.items() if k.startswith(max_diff_module)}
        
        print(f"  PyTorch {max_diff_module} å‚æ•°é¡¹: {len(pytorch_module_params)}")
        print(f"  Jittor {max_diff_module} å‚æ•°é¡¹: {len(jittor_module_params)}")
        
        # æ‰¾å‡ºåªåœ¨ä¸€è¾¹å­˜åœ¨çš„å‚æ•°
        pytorch_names = set(pytorch_module_params.keys())
        jittor_names = set(jittor_module_params.keys())
        
        only_pytorch = pytorch_names - jittor_names
        only_jittor = jittor_names - pytorch_names
        common = pytorch_names & jittor_names
        
        print(f"  å…±åŒå‚æ•°: {len(common)}")
        print(f"  åªåœ¨PyTorchä¸­: {len(only_pytorch)}")
        print(f"  åªåœ¨Jittorä¸­: {len(only_jittor)}")
        
        if only_pytorch:
            print(f"\n  åªåœ¨PyTorchä¸­çš„å‚æ•°:")
            for name in sorted(only_pytorch)[:10]:
                details = pytorch_module_params[name]
                print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
            if len(only_pytorch) > 10:
                print(f"    ... è¿˜æœ‰ {len(only_pytorch) - 10} ä¸ª")
        
        if only_jittor:
            print(f"\n  åªåœ¨Jittorä¸­çš„å‚æ•°:")
            for name in sorted(only_jittor)[:10]:
                details = jittor_module_params[name]
                print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
            if len(only_jittor) > 10:
                print(f"    ... è¿˜æœ‰ {len(only_jittor) - 10} ä¸ª")
        
        # æ£€æŸ¥å½¢çŠ¶ä¸åŒ¹é…çš„å‚æ•°
        shape_mismatches = []
        for name in common:
            pytorch_shape = pytorch_module_params[name]['shape']
            jittor_shape = jittor_module_params[name]['shape']
            if pytorch_shape != jittor_shape:
                shape_mismatches.append({
                    'name': name,
                    'pytorch_shape': pytorch_shape,
                    'jittor_shape': jittor_shape,
                    'pytorch_count': pytorch_module_params[name]['count'],
                    'jittor_count': jittor_module_params[name]['count']
                })
        
        if shape_mismatches:
            print(f"\n  å½¢çŠ¶ä¸åŒ¹é…çš„å‚æ•°:")
            for mismatch in shape_mismatches[:10]:
                print(f"    {mismatch['name']}:")
                print(f"      PyTorch: {mismatch['pytorch_shape']} ({mismatch['pytorch_count']} å‚æ•°)")
                print(f"      Jittor: {mismatch['jittor_shape']} ({mismatch['jittor_count']} å‚æ•°)")
    
    return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç²¾ç¡®æŸ¥æ‰¾29,116å‚æ•°å·®å¼‚")
    print("ç›®æ ‡: 100%å‚æ•°å¯¹é½ï¼Œä¸å…è®¸ä»»ä½•å·®å¼‚")
    
    success = analyze_parameter_differences()
    
    if success:
        print("\nâœ… å‚æ•°100%å¯¹é½æˆåŠŸï¼")
    else:
        print("\nâŒ ä»æœ‰å‚æ•°å·®å¼‚ï¼Œéœ€è¦ç»§ç»­ä¿®å¤")
    
    return success


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
