#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ§åˆ¶å˜é‡æ³•äº¤å‰éªŒè¯
é€ä¸ªç»„ä»¶æ›¿æ¢ï¼Œç²¾ç¡®å®šä½æ€§èƒ½å·®å¼‚çš„æ ¹æº
"""

import os
import sys
import cv2
import torch
import jittor as jt
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
sys.path.append('/home/kyc/project/nanodet/nanodet-pytorch')

# å¯¼å…¥Jittorç‰ˆæœ¬
import nanodet.model.arch.nanodet_plus as jittor_nanodet
import nanodet.model.backbone.shufflenetv2 as jittor_backbone
import nanodet.model.fpn.ghost_pan as jittor_fpn
import nanodet.model.head.nanodet_plus_head as jittor_head

# å°è¯•å¯¼å…¥PyTorchç‰ˆæœ¬
try:
    sys.path.insert(0, '/home/kyc/project/nanodet/nanodet-pytorch')
    import nanodet.model.arch.nanodet_plus as pytorch_nanodet
    import nanodet.model.backbone.shufflenetv2 as pytorch_backbone
    import nanodet.model.fpn.ghost_pan as pytorch_fpn
    import nanodet.model.head.nanodet_plus_head as pytorch_head
    PYTORCH_AVAILABLE = True
    print("âœ… PyTorchç‰ˆæœ¬æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ PyTorchç‰ˆæœ¬æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    PYTORCH_AVAILABLE = False


def load_pytorch_weights():
    """åŠ è½½PyTorchæƒé‡"""
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    return state_dict


def create_pure_jittor_model():
    """åˆ›å»ºçº¯Jittoræ¨¡å‹"""
    print("ğŸ” åˆ›å»ºçº¯Jittoræ¨¡å‹...")
    
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': False
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    model = jittor_nanodet.NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    # åŠ è½½æƒé‡
    state_dict = load_pytorch_weights()
    
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    loaded_count = 0
    total_count = 0
    
    for pytorch_name, pytorch_param in state_dict.items():
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]
        
        if "num_batches_tracked" in jittor_name or jittor_name.startswith("avg_"):
            continue
        
        if "distribution_project.project" in jittor_name:
            continue
        
        total_count += 1
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            if list(pytorch_param.shape) == list(jittor_param.shape):
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
                loaded_count += 1
    
    print(f"âœ… çº¯Jittoræ¨¡å‹æƒé‡åŠ è½½: {loaded_count}/{total_count}")
    model.eval()
    return model


def create_pure_pytorch_model():
    """åˆ›å»ºçº¯PyTorchæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    if not PYTORCH_AVAILABLE:
        print("âŒ PyTorchç‰ˆæœ¬ä¸å¯ç”¨")
        return None
    
    print("ğŸ” åˆ›å»ºçº¯PyTorchæ¨¡å‹...")
    
    # è¿™é‡Œéœ€è¦æ ¹æ®PyTorchç‰ˆæœ¬çš„å®é™…APIæ¥å®ç°
    # ç”±äºæˆ‘ä»¬æ²¡æœ‰PyTorchç‰ˆæœ¬çš„å®Œæ•´ä»£ç ï¼Œè¿™é‡Œåªæ˜¯ç¤ºä¾‹
    print("âš ï¸ PyTorchæ¨¡å‹åˆ›å»ºéœ€è¦æ ¹æ®å®é™…APIå®ç°")
    return None


def test_model_inference(model, model_name):
    """æµ‹è¯•æ¨¡å‹æ¨ç†"""
    print(f"ğŸ” æµ‹è¯• {model_name} æ¨ç†...")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    np.random.seed(42)
    input_data = np.random.randn(1, 3, 320, 320).astype(np.float32)
    
    if 'jittor' in model_name.lower():
        jittor_input = jt.array(input_data)
        with jt.no_grad():
            output = model(jittor_input)
            
            # åˆ†æè¾“å‡º
            cls_preds = output[:, :, :20]
            cls_scores = jt.sigmoid(cls_preds)
            
            max_conf = float(cls_scores.max().numpy())
            mean_conf = float(cls_scores.mean().numpy())
            
            # ç»Ÿè®¡æ£€æµ‹æ•°é‡
            detection_counts = {}
            for threshold in [0.01, 0.05, 0.1]:
                max_scores = jt.max(cls_scores, dim=2)[0]
                valid_detections = int((max_scores > threshold).sum().numpy())
                detection_counts[threshold] = valid_detections
    
    elif 'pytorch' in model_name.lower() and model is not None:
        # PyTorchæ¨¡å‹æ¨ç†
        torch_input = torch.tensor(input_data)
        with torch.no_grad():
            output = model(torch_input)
            # ç±»ä¼¼çš„åˆ†æ...
            max_conf = 0.0  # å ä½ç¬¦
            mean_conf = 0.0
            detection_counts = {0.01: 0, 0.05: 0, 0.1: 0}
    
    else:
        print(f"âš ï¸ æ— æ³•æµ‹è¯• {model_name}")
        return None
    
    result = {
        'model_name': model_name,
        'max_confidence': max_conf,
        'mean_confidence': mean_conf,
        'detection_counts': detection_counts
    }
    
    print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.6f}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {mean_conf:.6f}")
    for threshold, count in detection_counts.items():
        print(f"  é˜ˆå€¼{threshold}: {count}ä¸ªæ£€æµ‹")
    
    return result


def create_hybrid_model_backbone_pytorch():
    """åˆ›å»ºæ··åˆæ¨¡å‹ï¼šPyTorch Backbone + Jittor FPN + Jittor Head"""
    print("ğŸ” åˆ›å»ºæ··åˆæ¨¡å‹: PyTorch Backbone + Jittor FPN + Jittor Head")
    
    if not PYTORCH_AVAILABLE:
        print("âŒ PyTorchç‰ˆæœ¬ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ··åˆæ¨¡å‹")
        return None
    
    # è¿™é‡Œéœ€è¦å®ç°æ··åˆæ¨¡å‹çš„åˆ›å»ºé€»è¾‘
    # ç”±äºæ¡†æ¶å·®å¼‚ï¼Œè¿™å¯èƒ½æ¯”è¾ƒå¤æ‚
    print("âš ï¸ æ··åˆæ¨¡å‹åˆ›å»ºéœ€è¦ç‰¹æ®Šçš„æ¡†æ¶æ¡¥æ¥å®ç°")
    return None


def create_hybrid_model_fpn_pytorch():
    """åˆ›å»ºæ··åˆæ¨¡å‹ï¼šJittor Backbone + PyTorch FPN + Jittor Head"""
    print("ğŸ” åˆ›å»ºæ··åˆæ¨¡å‹: Jittor Backbone + PyTorch FPN + Jittor Head")
    
    if not PYTORCH_AVAILABLE:
        print("âŒ PyTorchç‰ˆæœ¬ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ··åˆæ¨¡å‹")
        return None
    
    print("âš ï¸ æ··åˆæ¨¡å‹åˆ›å»ºéœ€è¦ç‰¹æ®Šçš„æ¡†æ¶æ¡¥æ¥å®ç°")
    return None


def create_hybrid_model_head_pytorch():
    """åˆ›å»ºæ··åˆæ¨¡å‹ï¼šJittor Backbone + Jittor FPN + PyTorch Head"""
    print("ğŸ” åˆ›å»ºæ··åˆæ¨¡å‹: Jittor Backbone + Jittor FPN + PyTorch Head")
    
    if not PYTORCH_AVAILABLE:
        print("âŒ PyTorchç‰ˆæœ¬ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ··åˆæ¨¡å‹")
        return None
    
    print("âš ï¸ æ··åˆæ¨¡å‹åˆ›å»ºéœ€è¦ç‰¹æ®Šçš„æ¡†æ¶æ¡¥æ¥å®ç°")
    return None


def compare_component_outputs():
    """æ¯”è¾ƒå„ç»„ä»¶çš„è¾“å‡ºå·®å¼‚"""
    print("ğŸ” æ¯”è¾ƒå„ç»„ä»¶çš„è¾“å‡ºå·®å¼‚")
    print("=" * 60)
    
    # åˆ›å»ºçº¯Jittoræ¨¡å‹
    jittor_model = create_pure_jittor_model()
    
    # æµ‹è¯•çº¯Jittoræ¨¡å‹
    jittor_result = test_model_inference(jittor_model, "çº¯Jittoræ¨¡å‹")
    
    # å¦‚æœPyTorchå¯ç”¨ï¼Œåˆ›å»ºå¹¶æµ‹è¯•PyTorchæ¨¡å‹
    pytorch_result = None
    if PYTORCH_AVAILABLE:
        pytorch_model = create_pure_pytorch_model()
        if pytorch_model is not None:
            pytorch_result = test_model_inference(pytorch_model, "çº¯PyTorchæ¨¡å‹")
    
    # æµ‹è¯•æ··åˆæ¨¡å‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    hybrid_results = []
    
    # ç”±äºæ¡†æ¶å·®å¼‚ï¼Œæ··åˆæ¨¡å‹çš„å®ç°æ¯”è¾ƒå¤æ‚
    # è¿™é‡Œæˆ‘ä»¬å…ˆä¸“æ³¨äºåˆ†æçº¯Jittoræ¨¡å‹çš„å„ä¸ªç»„ä»¶
    
    return {
        'jittor': jittor_result,
        'pytorch': pytorch_result,
        'hybrid': hybrid_results
    }


def analyze_component_differences():
    """åˆ†æç»„ä»¶å·®å¼‚çš„æ›¿ä»£æ–¹æ³•"""
    print("ğŸ” åˆ†æç»„ä»¶å·®å¼‚ï¼ˆæ›¿ä»£æ–¹æ³•ï¼‰")
    print("=" * 60)
    
    # ç”±äºç›´æ¥æ··åˆPyTorchå’ŒJittorç»„ä»¶æ¯”è¾ƒå›°éš¾
    # æˆ‘ä»¬é‡‡ç”¨æ›¿ä»£æ–¹æ³•ï¼šåˆ†æå„ç»„ä»¶çš„æƒé‡å’Œè¾“å‡º
    
    jittor_model = create_pure_jittor_model()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    np.random.seed(42)
    input_data = np.random.randn(1, 3, 320, 320).astype(np.float32)
    jittor_input = jt.array(input_data)
    
    print("1. åˆ†æBackboneè¾“å‡º...")
    with jt.no_grad():
        # è·å–backboneè¾“å‡º
        backbone_features = jittor_model.backbone(jittor_input)
        
        print(f"  Backboneè¾“å‡ºå±‚æ•°: {len(backbone_features)}")
        for i, feat in enumerate(backbone_features):
            print(f"    å±‚{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")
    
    print("2. åˆ†æFPNè¾“å‡º...")
    with jt.no_grad():
        # è·å–FPNè¾“å‡º
        fpn_features = jittor_model.fpn(backbone_features)
        
        print(f"  FPNè¾“å‡ºå±‚æ•°: {len(fpn_features)}")
        for i, feat in enumerate(fpn_features):
            print(f"    å±‚{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")
    
    print("3. åˆ†æHeadè¾“å‡º...")
    with jt.no_grad():
        # è·å–Headè¾“å‡º
        head_output = jittor_model.head(fpn_features)
        
        print(f"  Headè¾“å‡º: {head_output.shape}, èŒƒå›´[{head_output.min():.6f}, {head_output.max():.6f}]")
        
        # åˆ†æåˆ†ç±»å’Œå›å½’è¾“å‡º
        cls_preds = head_output[:, :, :20]
        reg_preds = head_output[:, :, 20:]
        
        print(f"  åˆ†ç±»é¢„æµ‹: èŒƒå›´[{cls_preds.min():.6f}, {cls_preds.max():.6f}]")
        print(f"  å›å½’é¢„æµ‹: èŒƒå›´[{reg_preds.min():.6f}, {reg_preds.max():.6f}]")
        
        # è®¡ç®—ç½®ä¿¡åº¦
        cls_scores = jt.sigmoid(cls_preds)
        max_conf = float(cls_scores.max().numpy())
        
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.6f}")
    
    print("4. åˆ†ææƒé‡åˆ†å¸ƒ...")
    
    # æ£€æŸ¥å…³é”®æƒé‡
    key_weights = [
        'backbone.stage2.0.branch1.0.weight',
        'fpn.reduce_layers.0.weight',
        'head.gfl_cls.0.weight',
        'head.gfl_cls.0.bias'
    ]
    
    for weight_name in key_weights:
        found = False
        for name, param in jittor_model.named_parameters():
            if weight_name in name:
                weight = param.numpy()
                print(f"  {name}: {weight.shape}, èŒƒå›´[{weight.min():.6f}, {weight.max():.6f}]")
                found = True
                break
        if not found:
            print(f"  âš ï¸ æœªæ‰¾åˆ°æƒé‡: {weight_name}")
    
    return max_conf


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ§åˆ¶å˜é‡æ³•äº¤å‰éªŒè¯")
    print("ç›®æ ‡: é€ä¸ªç»„ä»¶æ›¿æ¢ï¼Œç²¾ç¡®å®šä½æ€§èƒ½å·®å¼‚")
    print("=" * 80)
    
    try:
        # æ–¹æ³•1: ç›´æ¥æ¯”è¾ƒç»„ä»¶è¾“å‡ºï¼ˆæ¨èï¼‰
        max_conf = analyze_component_differences()
        
        # æ–¹æ³•2: å°è¯•æ··åˆæ¨¡å‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        if PYTORCH_AVAILABLE:
            print(f"\nå°è¯•æ··åˆæ¨¡å‹æµ‹è¯•...")
            results = compare_component_outputs()
        else:
            print(f"\nâš ï¸ PyTorchç‰ˆæœ¬ä¸å¯ç”¨ï¼Œè·³è¿‡æ··åˆæ¨¡å‹æµ‹è¯•")
        
        print(f"\nğŸ“Š æ§åˆ¶å˜é‡æ³•åˆ†æç»“æœ:")
        print("=" * 80)
        
        print(f"å½“å‰Jittoræ¨¡å‹æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.6f}")
        
        if max_conf < 0.05:
            print(f"  âŒ ç½®ä¿¡åº¦è¿‡ä½ï¼Œå¯èƒ½çš„é—®é¢˜ç»„ä»¶:")
            print(f"    1. Headçš„biasåˆå§‹åŒ–")
            print(f"    2. FPNçš„ç‰¹å¾èåˆ")
            print(f"    3. Backboneçš„ç‰¹å¾æå–")
            print(f"    4. æ¿€æ´»å‡½æ•°å®ç°å·®å¼‚")
        elif max_conf < 0.1:
            print(f"  âš ï¸ ç½®ä¿¡åº¦åä½ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            print(f"  âœ… ç½®ä¿¡åº¦æ­£å¸¸")
        
        print(f"\nğŸ’¡ å»ºè®®çš„ä¼˜åŒ–æ–¹å‘:")
        print(f"  1. é‡ç‚¹æ£€æŸ¥Headç»„ä»¶çš„å®ç°")
        print(f"  2. å¯¹æ¯”FPNçš„ç‰¹å¾èåˆé€»è¾‘")
        print(f"  3. éªŒè¯æ¿€æ´»å‡½æ•°çš„ä¸€è‡´æ€§")
        print(f"  4. æ£€æŸ¥BatchNormçš„è¡Œä¸º")
        
        print(f"\nâœ… æ§åˆ¶å˜é‡æ³•åˆ†æå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
