#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¯¦ç»†çš„é€å±‚åˆ†æ
æ‰¾å‡ºæ¨¡å‹å·®å¼‚çš„å…·ä½“ä½ç½®
"""

import os
import sys
import torch
import jittor as jt
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def create_test_input():
    """åˆ›å»ºå›ºå®šçš„æµ‹è¯•è¾“å…¥"""
    np.random.seed(42)
    torch.manual_seed(42)
    jt.set_global_seed(42)
    
    # ä½¿ç”¨å›ºå®šçš„æµ‹è¯•æ•°æ®
    if os.path.exists("fixed_input_data.npy"):
        input_data = np.load("fixed_input_data.npy")
    else:
        input_data = np.random.randn(1, 3, 320, 320).astype(np.float32)
        np.save("fixed_input_data.npy", input_data)
    
    return input_data


def create_jittor_model():
    """åˆ›å»ºJittoræ¨¡å‹"""
    print("ğŸ” åˆ›å»ºJittoræ¨¡å‹...")
    
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    # åŠ è½½æƒé‡
    print("åŠ è½½PyTorchæƒé‡...")
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    # æƒé‡åŠ è½½
    for pytorch_name, pytorch_param in state_dict.items():
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]
        
        if "num_batches_tracked" in jittor_name or jittor_name.startswith("avg_"):
            continue
        
        if "distribution_project.project" in jittor_name:
            continue
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            if list(pytorch_param.shape) == list(jittor_param.shape):
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
    
    model.eval()
    return model


def analyze_first_few_layers():
    """åˆ†æå‰å‡ å±‚çš„è¯¦ç»†è¡Œä¸º"""
    print(f"ğŸ” åˆ†æå‰å‡ å±‚çš„è¯¦ç»†è¡Œä¸º")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_jittor_model()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    input_data = create_test_input()
    jittor_input = jt.array(input_data)
    
    print(f"è¾“å…¥æ•°æ®: {input_data.shape}, èŒƒå›´[{input_data.min():.6f}, {input_data.max():.6f}]")
    
    with jt.no_grad():
        print(f"\nğŸ” é€å±‚å‰å‘ä¼ æ’­åˆ†æ:")
        
        # 1. è¾“å…¥å±‚
        x = jittor_input
        print(f"  è¾“å…¥: {x.shape}, èŒƒå›´[{x.min():.6f}, {x.max():.6f}]")
        
        # 2. Conv1å±‚è¯¦ç»†åˆ†æ
        print(f"\n  ğŸ” Conv1å±‚è¯¦ç»†åˆ†æ:")
        
        # Conv1çš„å„ä¸ªå­å±‚
        conv1_conv = model.backbone.conv1[0]  # Conv2d
        conv1_bn = model.backbone.conv1[1]    # BatchNorm2d
        conv1_act = model.backbone.conv1[2]   # LeakyReLU
        
        # Convè¾“å‡º
        conv_out = conv1_conv(x)
        print(f"    Conv2dè¾“å‡º: {conv_out.shape}, èŒƒå›´[{conv_out.min():.6f}, {conv_out.max():.6f}]")
        
        # BatchNormè¾“å‡º
        bn_out = conv1_bn(conv_out)
        print(f"    BatchNormè¾“å‡º: {bn_out.shape}, èŒƒå›´[{bn_out.min():.6f}, {bn_out.max():.6f}]")
        
        # æ¿€æ´»å‡½æ•°è¾“å‡º
        act_out = conv1_act(bn_out)
        print(f"    LeakyReLUè¾“å‡º: {act_out.shape}, èŒƒå›´[{act_out.min():.6f}, {act_out.max():.6f}]")
        
        # å®Œæ•´conv1è¾“å‡º
        conv1_full_out = model.backbone.conv1(x)
        print(f"    Conv1å®Œæ•´è¾“å‡º: {conv1_full_out.shape}, èŒƒå›´[{conv1_full_out.min():.6f}, {conv1_full_out.max():.6f}]")
        
        # éªŒè¯ä¸€è‡´æ€§
        diff = jt.abs(act_out - conv1_full_out).max()
        print(f"    ä¸€è‡´æ€§æ£€æŸ¥å·®å¼‚: {diff:.10f}")
        
        # 3. MaxPoolå±‚
        print(f"\n  ğŸ” MaxPoolå±‚:")
        x = conv1_full_out
        maxpool_out = model.backbone.maxpool(x)
        print(f"    MaxPoolè¾“å‡º: {maxpool_out.shape}, èŒƒå›´[{maxpool_out.min():.6f}, {maxpool_out.max():.6f}]")
        
        # 4. Stage2ç¬¬ä¸€ä¸ªblockè¯¦ç»†åˆ†æ
        print(f"\n  ğŸ” Stage2ç¬¬ä¸€ä¸ªblockè¯¦ç»†åˆ†æ:")
        x = maxpool_out
        
        # Stage2çš„ç¬¬ä¸€ä¸ªblock
        first_block = model.backbone.stage2[0]
        
        # åˆ†æbranch1å’Œbranch2
        if hasattr(first_block, 'branch1') and len(first_block.branch1) > 0:
            branch1_out = first_block.branch1(x)
            print(f"    Branch1è¾“å‡º: {branch1_out.shape}, èŒƒå›´[{branch1_out.min():.6f}, {branch1_out.max():.6f}]")
        
        if hasattr(first_block, 'branch2'):
            branch2_out = first_block.branch2(x)
            print(f"    Branch2è¾“å‡º: {branch2_out.shape}, èŒƒå›´[{branch2_out.min():.6f}, {branch2_out.max():.6f}]")
        
        # å®Œæ•´blockè¾“å‡º
        block_out = first_block(x)
        print(f"    Blockå®Œæ•´è¾“å‡º: {block_out.shape}, èŒƒå›´[{block_out.min():.6f}, {block_out.max():.6f}]")
        
        # 5. ç»§ç»­åˆ†ææ›´å¤šå±‚
        print(f"\n  ğŸ” ç»§ç»­åˆ†æStage2:")
        x = block_out
        
        for i, block in enumerate(model.backbone.stage2[1:], 1):
            x = block(x)
            print(f"    Stage2 Block{i}è¾“å‡º: {x.shape}, èŒƒå›´[{x.min():.6f}, {x.max():.6f}]")
        
        stage2_out = x
        print(f"    Stage2å®Œæ•´è¾“å‡º: {stage2_out.shape}, èŒƒå›´[{stage2_out.min():.6f}, {stage2_out.max():.6f}]")

        # 6. Stage3åˆ†æ
        print(f"\n  ğŸ” Stage3åˆ†æ:")
        x = stage2_out

        for i, block in enumerate(model.backbone.stage3):
            x = block(x)
            print(f"    Stage3 Block{i}è¾“å‡º: {x.shape}, èŒƒå›´[{x.min():.6f}, {x.max():.6f}]")

        stage3_out = x
        print(f"    Stage3å®Œæ•´è¾“å‡º: {stage3_out.shape}, èŒƒå›´[{stage3_out.min():.6f}, {stage3_out.max():.6f}]")

        # 7. Stage4åˆ†æ
        print(f"\n  ğŸ” Stage4åˆ†æ:")
        x = stage3_out

        for i, block in enumerate(model.backbone.stage4):
            x = block(x)
            print(f"    Stage4 Block{i}è¾“å‡º: {x.shape}, èŒƒå›´[{x.min():.6f}, {x.max():.6f}]")

        stage4_out = x
        print(f"    Stage4å®Œæ•´è¾“å‡º: {stage4_out.shape}, èŒƒå›´[{stage4_out.min():.6f}, {stage4_out.max():.6f}]")

        # 8. å®Œæ•´Backboneè¾“å‡º
        print(f"\n  ğŸ” å®Œæ•´Backboneè¾“å‡º:")
        backbone_features = model.backbone(jittor_input)
        for i, feat in enumerate(backbone_features):
            print(f"    Backboneç‰¹å¾{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")

        # 9. FPNè¯¦ç»†åˆ†æ
        print(f"\n  ğŸ” FPNè¯¦ç»†åˆ†æ:")
        fpn_features = model.fpn(backbone_features)
        for i, feat in enumerate(fpn_features):
            print(f"    FPNç‰¹å¾{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")

        # 10. Headè¯¦ç»†åˆ†æ
        print(f"\n  ğŸ” Headè¯¦ç»†åˆ†æ:")
        head_output = model.head(fpn_features)
        print(f"    HeadåŸå§‹è¾“å‡º: {head_output.shape}, èŒƒå›´[{head_output.min():.6f}, {head_output.max():.6f}]")

        # åˆ†æHeadè¾“å‡ºçš„ç»„æˆ
        cls_preds = head_output[:, :, :20]
        reg_preds = head_output[:, :, 20:]
        cls_scores = jt.sigmoid(cls_preds)

        print(f"    åˆ†ç±»é¢„æµ‹: {cls_preds.shape}, èŒƒå›´[{cls_preds.min():.6f}, {cls_preds.max():.6f}]")
        print(f"    å›å½’é¢„æµ‹: {reg_preds.shape}, èŒƒå›´[{reg_preds.min():.6f}, {reg_preds.max():.6f}]")
        print(f"    åˆ†ç±»ç½®ä¿¡åº¦: èŒƒå›´[{cls_scores.min():.6f}, {cls_scores.max():.6f}]")
        print(f"    æœ€é«˜ç½®ä¿¡åº¦: {cls_scores.max():.6f}")

        # 11. å¯¹æ¯”å®Œæ•´æ¨¡å‹è¾“å‡º
        print(f"\n  ğŸ” å®Œæ•´æ¨¡å‹è¾“å‡ºå¯¹æ¯”:")
        full_output = model(jittor_input)
        print(f"    å®Œæ•´æ¨¡å‹è¾“å‡º: {full_output.shape}, èŒƒå›´[{full_output.min():.6f}, {full_output.max():.6f}]")

        # éªŒè¯ä¸€è‡´æ€§
        head_vs_full_diff = jt.abs(head_output - full_output).max()
        print(f"    Head vs å®Œæ•´æ¨¡å‹å·®å¼‚: {head_vs_full_diff:.10f}")

        if head_vs_full_diff < 1e-6:
            print(f"    âœ… Headè¾“å‡ºä¸å®Œæ•´æ¨¡å‹ä¸€è‡´")
        else:
            print(f"    âŒ Headè¾“å‡ºä¸å®Œæ•´æ¨¡å‹ä¸ä¸€è‡´")


def check_batchnorm_detailed():
    """è¯¦ç»†æ£€æŸ¥BatchNormè¡Œä¸º"""
    print(f"\nğŸ” è¯¦ç»†æ£€æŸ¥BatchNormè¡Œä¸º")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_jittor_model()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    input_data = create_test_input()
    jittor_input = jt.array(input_data)
    
    with jt.no_grad():
        # è·å–ç¬¬ä¸€ä¸ªBatchNormå±‚
        conv1_conv = model.backbone.conv1[0]
        conv1_bn = model.backbone.conv1[1]
        
        # è·å–convè¾“å‡ºä½œä¸ºBatchNormè¾“å…¥
        conv_out = conv1_conv(jittor_input)
        
        print(f"BatchNormè¾“å…¥: {conv_out.shape}, èŒƒå›´[{conv_out.min():.6f}, {conv_out.max():.6f}]")
        
        # æ£€æŸ¥BatchNormå‚æ•°
        print(f"\nBatchNormå‚æ•°:")
        print(f"  weight: å½¢çŠ¶{conv1_bn.weight.shape}, èŒƒå›´[{conv1_bn.weight.min():.6f}, {conv1_bn.weight.max():.6f}]")
        print(f"  bias: å½¢çŠ¶{conv1_bn.bias.shape}, èŒƒå›´[{conv1_bn.bias.min():.6f}, {conv1_bn.bias.max():.6f}]")
        print(f"  running_mean: å½¢çŠ¶{conv1_bn.running_mean.shape}, èŒƒå›´[{conv1_bn.running_mean.min():.6f}, {conv1_bn.running_mean.max():.6f}]")
        print(f"  running_var: å½¢çŠ¶{conv1_bn.running_var.shape}, èŒƒå›´[{conv1_bn.running_var.min():.6f}, {conv1_bn.running_var.max():.6f}]")
        print(f"  eps: {conv1_bn.eps}")
        print(f"  momentum: {conv1_bn.momentum}")
        print(f"  is_train: {conv1_bn.is_train}")
        
        # BatchNormè¾“å‡º
        bn_out = conv1_bn(conv_out)
        print(f"\nBatchNormè¾“å‡º: {bn_out.shape}, èŒƒå›´[{bn_out.min():.6f}, {bn_out.max():.6f}]")
        
        # æ‰‹åŠ¨è®¡ç®—BatchNormï¼ˆè¯„ä¼°æ¨¡å¼ï¼‰
        print(f"\næ‰‹åŠ¨è®¡ç®—BatchNorm:")
        
        # é‡å¡‘å‚æ•°ä»¥ä¾¿å¹¿æ’­
        mean = conv1_bn.running_mean.view(1, -1, 1, 1)
        var = conv1_bn.running_var.view(1, -1, 1, 1)
        weight = conv1_bn.weight.view(1, -1, 1, 1)
        bias = conv1_bn.bias.view(1, -1, 1, 1)
        
        print(f"  meanå½¢çŠ¶: {mean.shape}, èŒƒå›´[{mean.min():.6f}, {mean.max():.6f}]")
        print(f"  varå½¢çŠ¶: {var.shape}, èŒƒå›´[{var.min():.6f}, {var.max():.6f}]")
        print(f"  weightå½¢çŠ¶: {weight.shape}, èŒƒå›´[{weight.min():.6f}, {weight.max():.6f}]")
        print(f"  biaså½¢çŠ¶: {bias.shape}, èŒƒå›´[{bias.min():.6f}, {bias.max():.6f}]")
        
        # æ ‡å‡†åŒ–
        normalized = (conv_out - mean) / jt.sqrt(var + conv1_bn.eps)
        print(f"  æ ‡å‡†åŒ–å: èŒƒå›´[{normalized.min():.6f}, {normalized.max():.6f}]")
        
        # ä»¿å°„å˜æ¢
        manual_bn_out = normalized * weight + bias
        print(f"  æ‰‹åŠ¨BatchNormè¾“å‡º: èŒƒå›´[{manual_bn_out.min():.6f}, {manual_bn_out.max():.6f}]")
        
        # å¯¹æ¯”å·®å¼‚
        bn_diff = jt.abs(bn_out - manual_bn_out).max()
        print(f"  BatchNormå·®å¼‚: {bn_diff:.10f}")
        
        if bn_diff < 1e-5:
            print(f"  âœ… BatchNormè®¡ç®—æ­£ç¡®")
        else:
            print(f"  âŒ BatchNormè®¡ç®—æœ‰è¯¯")
            
            # è¯¦ç»†åˆ†æå·®å¼‚
            print(f"    è¯¦ç»†å·®å¼‚åˆ†æ:")
            print(f"    æœ€å¤§ç»å¯¹å·®å¼‚: {bn_diff:.10f}")
            print(f"    å¹³å‡ç»å¯¹å·®å¼‚: {jt.abs(bn_out - manual_bn_out).mean():.10f}")
            print(f"    ç›¸å¯¹å·®å¼‚: {(bn_diff / jt.abs(bn_out).max()):.10f}")


def analyze_fpn_internal():
    """åˆ†æFPNå†…éƒ¨ç»“æ„"""
    print(f"\nğŸ” åˆ†æFPNå†…éƒ¨ç»“æ„")
    print("=" * 60)

    # åˆ›å»ºæ¨¡å‹
    model = create_jittor_model()

    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    input_data = create_test_input()
    jittor_input = jt.array(input_data)

    with jt.no_grad():
        # è·å–backboneç‰¹å¾
        backbone_features = model.backbone(jittor_input)
        print(f"Backboneç‰¹å¾è¾“å…¥åˆ°FPN:")
        for i, feat in enumerate(backbone_features):
            print(f"  ç‰¹å¾{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")

        # åˆ†æFPNçš„å†…éƒ¨å¤„ç†
        fpn = model.fpn

        # æ£€æŸ¥FPNçš„å„ä¸ªç»„ä»¶
        print(f"\nFPNç»„ä»¶åˆ†æ:")

        # å¦‚æœFPNæœ‰ç‰¹å®šçš„å¤„ç†æ­¥éª¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ‰§è¡Œ
        # è¿™é‡Œæˆ‘ä»¬å…ˆè·å–FPNçš„è¾“å‡ºï¼Œç„¶ååˆ†æ
        fpn_features = fpn(backbone_features)
        print(f"FPNè¾“å‡ºç‰¹å¾:")
        for i, feat in enumerate(fpn_features):
            print(f"  FPNç‰¹å¾{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")

        # æ£€æŸ¥ç‰¹å¾å˜åŒ–
        print(f"\nç‰¹å¾å˜åŒ–åˆ†æ:")
        for i, (backbone_feat, fpn_feat) in enumerate(zip(backbone_features, fpn_features[:len(backbone_features)])):
            if backbone_feat.shape == fpn_feat.shape:
                diff = jt.abs(backbone_feat - fpn_feat).max()
                print(f"  ç‰¹å¾{i}å˜åŒ–: {diff:.6f}")
            else:
                print(f"  ç‰¹å¾{i}å½¢çŠ¶å˜åŒ–: {backbone_feat.shape} -> {fpn_feat.shape}")


def analyze_head_internal():
    """åˆ†æHeadå†…éƒ¨ç»“æ„"""
    print(f"\nğŸ” åˆ†æHeadå†…éƒ¨ç»“æ„")
    print("=" * 60)

    # åˆ›å»ºæ¨¡å‹
    model = create_jittor_model()

    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    input_data = create_test_input()
    jittor_input = jt.array(input_data)

    with jt.no_grad():
        # è·å–FPNç‰¹å¾
        backbone_features = model.backbone(jittor_input)
        fpn_features = model.fpn(backbone_features)

        print(f"FPNç‰¹å¾è¾“å…¥åˆ°Head:")
        for i, feat in enumerate(fpn_features):
            print(f"  ç‰¹å¾{i}: {feat.shape}, èŒƒå›´[{feat.min():.6f}, {feat.max():.6f}]")

        # åˆ†æHeadçš„å¤„ç†
        head = model.head

        # Headè¾“å‡º
        head_output = head(fpn_features)
        print(f"\nHeadè¾“å‡º:")
        print(f"  Headè¾“å‡º: {head_output.shape}, èŒƒå›´[{head_output.min():.6f}, {head_output.max():.6f}]")

        # åˆ†æè¾“å‡ºç»„æˆ
        cls_preds = head_output[:, :, :20]
        reg_preds = head_output[:, :, 20:]

        print(f"  åˆ†ç±»é¢„æµ‹: {cls_preds.shape}, èŒƒå›´[{cls_preds.min():.6f}, {cls_preds.max():.6f}]")
        print(f"  å›å½’é¢„æµ‹: {reg_preds.shape}, èŒƒå›´[{reg_preds.min():.6f}, {reg_preds.max():.6f}]")

        # åˆ†æç½®ä¿¡åº¦
        cls_scores = jt.sigmoid(cls_preds)
        print(f"  ç½®ä¿¡åº¦: èŒƒå›´[{cls_scores.min():.6f}, {cls_scores.max():.6f}]")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {cls_scores.max():.6f}")

        # åˆ†ææ¯ä¸ªå°ºåº¦çš„è¾“å‡º
        print(f"\næŒ‰å°ºåº¦åˆ†æ:")
        # å‡è®¾æœ‰4ä¸ªå°ºåº¦ï¼Œæ¯ä¸ªå°ºåº¦çš„anchoræ•°é‡ä¸åŒ
        # è¿™éœ€è¦æ ¹æ®å…·ä½“çš„Headå®ç°æ¥è°ƒæ•´
        total_anchors = head_output.shape[1]
        print(f"  æ€»anchoræ•°: {total_anchors}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è¯¦ç»†å±‚åˆ†æ")

    # åˆ†æå‰å‡ å±‚
    analyze_first_few_layers()

    # è¯¦ç»†æ£€æŸ¥BatchNorm
    check_batchnorm_detailed()

    # åˆ†æFPNå†…éƒ¨
    analyze_fpn_internal()

    # åˆ†æHeadå†…éƒ¨
    analyze_head_internal()

    print(f"\nâœ… è¯¦ç»†åˆ†æå®Œæˆ")


if __name__ == '__main__':
    main()
