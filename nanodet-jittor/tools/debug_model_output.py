#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•æ¨¡å‹è¾“å‡º
æ·±å…¥åˆ†æä¸ºä»€ä¹ˆæ¨¡å‹æ²¡æœ‰äº§ç”Ÿæ£€æµ‹ç»“æœ
"""

import os
import sys
import cv2
import torch
import jittor as jt
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def create_jittor_model():
    """åˆ›å»ºJittoræ¨¡å‹å¹¶åŠ è½½å¾®è°ƒæƒé‡"""
    print("ğŸ” åˆ›å»ºJittoræ¨¡å‹...")
    
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': False  # ä¸åŠ è½½ImageNeté¢„è®­ç»ƒ
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    # åŠ è½½å¾®è°ƒåçš„æƒé‡
    print("åŠ è½½å¾®è°ƒåçš„PyTorchæƒé‡...")
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    print(f"PyTorch checkpointåŒ…å« {len(state_dict)} ä¸ªå‚æ•°")
    
    # æ£€æŸ¥ä¸€äº›å…³é”®æƒé‡
    print("æ£€æŸ¥å…³é”®æƒé‡:")
    for name in ['model.backbone.stage2.0.branch1.0.weight', 'model.head.gfl_cls.0.weight', 'model.head.gfl_cls.0.bias']:
        if name in state_dict:
            param = state_dict[name]
            print(f"  {name}: {param.shape}, èŒƒå›´[{param.min():.6f}, {param.max():.6f}]")
    
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    print(f"Jittoræ¨¡å‹åŒ…å« {len(jittor_state_dict)} ä¸ªå‚æ•°")
    
    # æƒé‡åŠ è½½
    loaded_count = 0
    total_count = 0
    
    for pytorch_name, pytorch_param in state_dict.items():
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]
        
        if "num_batches_tracked" in jittor_name or jittor_name.startswith("avg_"):
            continue
        
        if "distribution_project.project" in jittor_name:
            continue
        
        total_count += 1
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            if list(pytorch_param.shape) == list(jittor_param.shape):
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
                loaded_count += 1
    
    print(f"âœ… æƒé‡åŠ è½½: {loaded_count}/{total_count} ({loaded_count/total_count*100:.1f}%)")
    
    # éªŒè¯å…³é”®æƒé‡æ˜¯å¦æ­£ç¡®åŠ è½½
    print("éªŒè¯å…³é”®æƒé‡åŠ è½½:")
    for jittor_name in ['head.gfl_cls.0.weight', 'head.gfl_cls.0.bias']:
        if jittor_name in jittor_state_dict:
            param = jittor_state_dict[jittor_name].numpy()
            print(f"  {jittor_name}: {param.shape}, èŒƒå›´[{param.min():.6f}, {param.max():.6f}]")
    
    model.eval()
    return model


def debug_model_inference():
    """è°ƒè¯•æ¨¡å‹æ¨ç†è¿‡ç¨‹"""
    print("\nğŸ” è°ƒè¯•æ¨¡å‹æ¨ç†è¿‡ç¨‹")
    print("=" * 60)
    
    model = create_jittor_model()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    np.random.seed(42)
    input_data = np.random.randn(1, 3, 320, 320).astype(np.float32)
    jittor_input = jt.array(input_data)
    
    print(f"è¾“å…¥æ•°æ®: {input_data.shape}, èŒƒå›´[{input_data.min():.6f}, {input_data.max():.6f}]")
    
    with jt.no_grad():
        # æ¨ç†
        output = model(jittor_input)
        
        print(f"\næ¨¡å‹è¾“å‡º:")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  è¾“å‡ºèŒƒå›´: [{output.min():.6f}, {output.max():.6f}]")
        
        # åˆ†æåˆ†ç±»å’Œå›å½’é¢„æµ‹
        cls_preds = output[:, :, :20]  # [1, num_anchors, 20]
        reg_preds = output[:, :, 20:]  # [1, num_anchors, 32]
        
        print(f"  åˆ†ç±»é¢„æµ‹: {cls_preds.shape}, èŒƒå›´[{cls_preds.min():.6f}, {cls_preds.max():.6f}]")
        print(f"  å›å½’é¢„æµ‹: {reg_preds.shape}, èŒƒå›´[{reg_preds.min():.6f}, {reg_preds.max():.6f}]")
        
        # è®¡ç®—ç½®ä¿¡åº¦
        cls_scores = jt.sigmoid(cls_preds)
        print(f"  ç½®ä¿¡åº¦: èŒƒå›´[{cls_scores.min():.6f}, {cls_scores.max():.6f}]")
        
        # ç»Ÿè®¡ç½®ä¿¡åº¦åˆ†å¸ƒ
        cls_scores_np = cls_scores.numpy()
        print(f"  ç½®ä¿¡åº¦ç»Ÿè®¡:")
        print(f"    å‡å€¼: {cls_scores_np.mean():.6f}")
        print(f"    æ ‡å‡†å·®: {cls_scores_np.std():.6f}")
        print(f"    >0.01çš„æ•°é‡: {(cls_scores_np > 0.01).sum()}")
        print(f"    >0.05çš„æ•°é‡: {(cls_scores_np > 0.05).sum()}")
        print(f"    >0.1çš„æ•°é‡: {(cls_scores_np > 0.1).sum()}")
        print(f"    >0.5çš„æ•°é‡: {(cls_scores_np > 0.5).sum()}")
        
        # æ‰¾å‡ºæœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
        max_conf_idx = np.unravel_index(np.argmax(cls_scores_np), cls_scores_np.shape)
        max_conf = cls_scores_np[max_conf_idx]
        
        print(f"  æœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹:")
        print(f"    ä½ç½®: {max_conf_idx}")
        print(f"    ç½®ä¿¡åº¦: {max_conf:.6f}")
        print(f"    ç±»åˆ«: {max_conf_idx[2]}")
        
        # æ£€æŸ¥ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ£€æµ‹æ•°é‡
        print(f"\nä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ£€æµ‹æ•°é‡:")
        for threshold in [0.01, 0.05, 0.1, 0.3, 0.5]:
            max_scores = jt.max(cls_scores, dim=2)[0]  # [1, num_anchors]
            valid_detections = (max_scores > threshold).sum()
            print(f"    é˜ˆå€¼ {threshold}: {valid_detections} ä¸ªæ£€æµ‹")
        
        return output, cls_scores


def test_with_real_image():
    """ä½¿ç”¨çœŸå®å›¾åƒæµ‹è¯•"""
    print(f"\nğŸ” ä½¿ç”¨çœŸå®å›¾åƒæµ‹è¯•")
    print("=" * 60)
    
    model = create_jittor_model()
    
    # åŠ è½½ä¸€å¼ çœŸå®çš„VOCå›¾åƒ
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    val_file = os.path.join(voc_root, "ImageSets/Main/val.txt")
    
    with open(val_file, 'r') as f:
        image_ids = [line.strip() for line in f.readlines()]
    
    # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾åƒ
    image_id = image_ids[0]
    image_path = os.path.join(voc_root, f"JPEGImages/{image_id}.jpg")
    
    print(f"æµ‹è¯•å›¾åƒ: {image_path}")
    
    # é¢„å¤„ç†å›¾åƒ
    image = cv2.imread(image_path)
    original_height, original_width = image.shape[:2]
    
    # è°ƒæ•´å¤§å°
    input_size = 320
    scale = min(input_size / original_width, input_size / original_height)
    new_width = int(original_width * scale)
    new_height = int(original_height * scale)
    
    image = cv2.resize(image, (new_width, new_height))
    
    # å¡«å……
    padded_image = np.zeros((input_size, input_size, 3), dtype=np.uint8)
    padded_image[:new_height, :new_width] = image
    
    # å½’ä¸€åŒ–
    image = cv2.cvtColor(padded_image, cv2.COLOR_BGR2RGB)
    image = image.astype(np.float32)
    
    # ä½¿ç”¨ä¸PyTorchè®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°
    mean = np.array([103.53, 116.28, 123.675])
    std = np.array([57.375, 57.12, 58.395])
    image = (image - mean) / std
    
    # è½¬æ¢ä¸ºCHWæ ¼å¼
    image = image.transpose(2, 0, 1)
    image = image[np.newaxis, ...]
    
    print(f"é¢„å¤„ç†å: {image.shape}, èŒƒå›´[{image.min():.6f}, {image.max():.6f}]")
    
    jittor_input = jt.array(image)
    
    with jt.no_grad():
        output = model(jittor_input)
        
        # åˆ†æè¾“å‡º
        cls_preds = output[:, :, :20]
        cls_scores = jt.sigmoid(cls_preds)
        
        max_conf = float(cls_scores.max().numpy())
        mean_conf = float(cls_scores.mean().numpy())
        
        print(f"çœŸå®å›¾åƒæ¨ç†ç»“æœ:")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.6f}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {mean_conf:.6f}")
        
        # æ£€æŸ¥ä¸åŒé˜ˆå€¼ä¸‹çš„æ£€æµ‹æ•°é‡
        for threshold in [0.01, 0.05, 0.1, 0.3, 0.5]:
            max_scores = jt.max(cls_scores, dim=2)[0]
            valid_detections = (max_scores > threshold).sum()
            print(f"  é˜ˆå€¼ {threshold}: {valid_detections} ä¸ªæ£€æµ‹")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è°ƒè¯•æ¨¡å‹è¾“å‡º")
    print("ç›®æ ‡: æ‰¾å‡ºä¸ºä»€ä¹ˆæ¨¡å‹æ²¡æœ‰äº§ç”Ÿæ£€æµ‹ç»“æœ")
    
    try:
        # 1. è°ƒè¯•æ¨¡å‹æ¨ç†
        output, cls_scores = debug_model_inference()
        
        # 2. ä½¿ç”¨çœŸå®å›¾åƒæµ‹è¯•
        test_with_real_image()
        
        print(f"\nğŸ¯ è°ƒè¯•æ€»ç»“:")
        print("=" * 60)
        
        max_conf = float(cls_scores.max().numpy())
        
        if max_conf < 0.01:
            print(f"  âŒ æœ€é«˜ç½®ä¿¡åº¦è¿‡ä½ ({max_conf:.6f})")
            print(f"  å¯èƒ½åŸå› :")
            print(f"    1. æƒé‡åŠ è½½æœ‰é—®é¢˜")
            print(f"    2. æ¨¡å‹æ¶æ„ä¸åŒ¹é…")
            print(f"    3. é¢„å¤„ç†ä¸ä¸€è‡´")
            print(f"    4. Headçš„biasåˆå§‹åŒ–é—®é¢˜")
        elif max_conf < 0.05:
            print(f"  âš ï¸ æœ€é«˜ç½®ä¿¡åº¦åä½ ({max_conf:.6f})")
            print(f"  éœ€è¦è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼æˆ–ä¼˜åŒ–æ¨¡å‹")
        else:
            print(f"  âœ… æœ€é«˜ç½®ä¿¡åº¦æ­£å¸¸ ({max_conf:.6f})")
            print(f"  é—®é¢˜å¯èƒ½åœ¨åå¤„ç†æµç¨‹")
        
        print(f"\nâœ… è°ƒè¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
