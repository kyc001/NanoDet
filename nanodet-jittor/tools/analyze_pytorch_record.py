#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åˆ†æPyTorchå‚è€ƒè®°å½•ï¼Œæ‰¾å‡º29,116å‚æ•°å·®å¼‚
"""

import json
import sys
from collections import defaultdict

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def load_pytorch_record():
    """åŠ è½½PyTorchå‚è€ƒè®°å½•"""
    try:
        with open('pytorch_reference_record.json', 'r') as f:
            record = json.load(f)
        return record
    except FileNotFoundError:
        print("âŒ PyTorchå‚è€ƒè®°å½•æ–‡ä»¶ä¸å­˜åœ¨")
        return None


def create_jittor_model():
    """åˆ›å»ºJittoræ¨¡å‹"""
    print("åˆ›å»ºJittoræ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®å­—å…¸ - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    # åˆ›å»ºaux_headé…ç½® - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,  # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'stacked_convs': 4,    # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    return model


def analyze_parameter_differences():
    """åˆ†æå‚æ•°å·®å¼‚"""
    print("ğŸ” åˆ†æå‚æ•°å·®å¼‚")
    print("=" * 80)
    
    # åŠ è½½PyTorchè®°å½•
    pytorch_record = load_pytorch_record()
    if not pytorch_record:
        return False
    
    pytorch_params = pytorch_record['model_params']
    
    # ç»Ÿè®¡PyTorchå‚æ•°
    pytorch_total = 0
    pytorch_modules = defaultdict(int)
    
    for name, details in pytorch_params.items():
        count = details['count']
        pytorch_total += count
        
        module = name.split('.')[0]
        pytorch_modules[module] += count
    
    print(f"âœ“ PyTorchæ¨¡å‹: {pytorch_total:,} å‚æ•°, {len(pytorch_params)} é¡¹")
    
    # åˆ›å»ºJittoræ¨¡å‹
    jittor_model = create_jittor_model()
    
    # ç»Ÿè®¡Jittorå‚æ•°
    jittor_params = {}
    jittor_total = 0
    jittor_modules = defaultdict(int)
    
    for name, param in jittor_model.named_parameters():
        count = param.numel() if hasattr(param, 'numel') else param.size
        jittor_params[name] = {
            'shape': list(param.shape),
            'count': count
        }
        jittor_total += count
        
        module = name.split('.')[0]
        jittor_modules[module] += count
    
    print(f"âœ“ Jittoræ¨¡å‹: {jittor_total:,} å‚æ•°, {len(jittor_params)} é¡¹")
    
    # è®¡ç®—å·®å¼‚
    difference = abs(pytorch_total - jittor_total)
    print(f"\nğŸ“Š å‚æ•°å·®å¼‚: {difference:,} ({difference/pytorch_total*100:.3f}%)")
    
    if difference == 0:
        print("ğŸ‰ å‚æ•°æ•°é‡100%å¯¹é½ï¼")
        return True
    
    # æŒ‰æ¨¡å—å¯¹æ¯”
    all_modules = set(pytorch_modules.keys()) | set(jittor_modules.keys())
    
    print(f"\nğŸ“Š æŒ‰æ¨¡å—å¯¹æ¯”:")
    print(f"{'æ¨¡å—':<20} {'PyTorch':<12} {'Jittor':<12} {'å·®å¼‚':<12}")
    print("-" * 60)
    
    module_differences = {}
    for module in sorted(all_modules):
        pytorch_count = pytorch_modules.get(module, 0)
        jittor_count = jittor_modules.get(module, 0)
        diff = pytorch_count - jittor_count
        module_differences[module] = diff
        
        status = "âœ…" if diff == 0 else "âŒ"
        print(f"{module:<20} {pytorch_count:<12,} {jittor_count:<12,} {diff:<12,} {status}")
    
    print("-" * 60)
    print(f"{'æ€»è®¡':<20} {pytorch_total:<12,} {jittor_total:<12,} {pytorch_total-jittor_total:<12,}")
    
    # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„æ¨¡å—
    max_diff_module = max(module_differences.keys(), key=lambda x: abs(module_differences[x]))
    max_diff = abs(module_differences[max_diff_module])
    
    print(f"\nğŸ¯ å·®å¼‚æœ€å¤§çš„æ¨¡å—: {max_diff_module} (å·®å¼‚: {module_differences[max_diff_module]:,} å‚æ•°)")
    
    # è¯¦ç»†åˆ†æå·®å¼‚æœ€å¤§çš„æ¨¡å—
    if max_diff > 0:
        print(f"\nğŸ” è¯¦ç»†åˆ†æ {max_diff_module} æ¨¡å—:")
        
        # PyTorchè¯¥æ¨¡å—çš„å‚æ•°
        pytorch_module_params = {k: v for k, v in pytorch_params.items() if k.startswith(max_diff_module)}
        jittor_module_params = {k: v for k, v in jittor_params.items() if k.startswith(max_diff_module)}
        
        print(f"  PyTorch {max_diff_module} å‚æ•°é¡¹: {len(pytorch_module_params)}")
        print(f"  Jittor {max_diff_module} å‚æ•°é¡¹: {len(jittor_module_params)}")
        
        # æ‰¾å‡ºå·®å¼‚
        pytorch_names = set(pytorch_module_params.keys())
        jittor_names = set(jittor_module_params.keys())
        
        only_pytorch = pytorch_names - jittor_names
        only_jittor = jittor_names - pytorch_names
        common = pytorch_names & jittor_names
        
        print(f"  å…±åŒå‚æ•°: {len(common)}")
        print(f"  åªåœ¨PyTorchä¸­: {len(only_pytorch)}")
        print(f"  åªåœ¨Jittorä¸­: {len(only_jittor)}")
        
        if only_pytorch:
            print(f"\n  åªåœ¨PyTorchä¸­çš„å‚æ•°:")
            only_pytorch_total = 0
            for name in sorted(only_pytorch)[:20]:
                details = pytorch_module_params[name]
                only_pytorch_total += details['count']
                print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
            if len(only_pytorch) > 20:
                remaining = len(only_pytorch) - 20
                remaining_total = sum(pytorch_module_params[name]['count'] for name in list(only_pytorch)[20:])
                print(f"    ... è¿˜æœ‰ {remaining} ä¸ªå‚æ•° ({remaining_total:,} å‚æ•°)")
                only_pytorch_total += remaining_total
            print(f"  åªåœ¨PyTorchä¸­çš„å‚æ•°æ€»è®¡: {only_pytorch_total:,}")
        
        if only_jittor:
            print(f"\n  åªåœ¨Jittorä¸­çš„å‚æ•°:")
            only_jittor_total = 0
            for name in sorted(only_jittor)[:20]:
                details = jittor_module_params[name]
                only_jittor_total += details['count']
                print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
            if len(only_jittor) > 20:
                remaining = len(only_jittor) - 20
                remaining_total = sum(jittor_module_params[name]['count'] for name in list(only_jittor)[20:])
                print(f"    ... è¿˜æœ‰ {remaining} ä¸ªå‚æ•° ({remaining_total:,} å‚æ•°)")
                only_jittor_total += remaining_total
            print(f"  åªåœ¨Jittorä¸­çš„å‚æ•°æ€»è®¡: {only_jittor_total:,}")
        
        # æ£€æŸ¥å½¢çŠ¶ä¸åŒ¹é…
        shape_mismatches = []
        for name in common:
            pytorch_shape = pytorch_module_params[name]['shape']
            jittor_shape = jittor_module_params[name]['shape']
            if pytorch_shape != jittor_shape:
                shape_mismatches.append({
                    'name': name,
                    'pytorch_shape': pytorch_shape,
                    'jittor_shape': jittor_shape,
                    'pytorch_count': pytorch_module_params[name]['count'],
                    'jittor_count': jittor_module_params[name]['count']
                })
        
        if shape_mismatches:
            print(f"\n  å½¢çŠ¶ä¸åŒ¹é…çš„å‚æ•°:")
            for mismatch in shape_mismatches:
                print(f"    {mismatch['name']}:")
                print(f"      PyTorch: {mismatch['pytorch_shape']} ({mismatch['pytorch_count']} å‚æ•°)")
                print(f"      Jittor: {mismatch['jittor_shape']} ({mismatch['jittor_count']} å‚æ•°)")
    
    # åˆ†ææ‰€æœ‰æ¨¡å—çš„å·®å¼‚
    print(f"\nğŸ“Š æ‰€æœ‰æ¨¡å—å·®å¼‚æ±‡æ€»:")
    for module in sorted(module_differences.keys(), key=lambda x: abs(module_differences[x]), reverse=True):
        diff = module_differences[module]
        if diff != 0:
            print(f"  {module}: {diff:+,} å‚æ•°")
    
    return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†æ29,116å‚æ•°å·®å¼‚")
    print("ç›®æ ‡: 100%å‚æ•°å¯¹é½ï¼Œä¸å…è®¸ä»»ä½•å·®å¼‚")
    
    success = analyze_parameter_differences()
    
    if success:
        print("\nâœ… å‚æ•°100%å¯¹é½æˆåŠŸï¼")
    else:
        print("\nâŒ ä»æœ‰å‚æ•°å·®å¼‚ï¼Œéœ€è¦ç»§ç»­ä¿®å¤")
        print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
        print("1. æ£€æŸ¥æ¨¡å—ç»“æ„æ˜¯å¦å®Œå…¨ä¸€è‡´")
        print("2. æ£€æŸ¥é…ç½®å‚æ•°æ˜¯å¦å®Œå…¨å¯¹é½")
        print("3. æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„å±‚æˆ–å‚æ•°")
    
    return success


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
