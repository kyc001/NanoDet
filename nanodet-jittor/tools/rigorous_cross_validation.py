#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
‰∏•Ê†ºÁöÑ‰∫§ÂèâÈ™åËØÅÂ∑•ÂÖ∑
‰ΩøÁî®ÊéßÂà∂ÂèòÈáèÊ≥ïÔºåÈÄê‰∏™ÁªÑ‰ª∂ÊõøÊç¢ÔºåÁúüÂÆûÊµãËØïmAP
Áªù‰∏ç‰º™ÈÄ†ÁªìÊûúÔºåÁ°Æ‰øùÁßëÂ≠¶ÊÄß
"""

import os
import sys
import cv2
import torch
import jittor as jt
import numpy as np
import json
from pathlib import Path

# Ê∑ªÂä†Ë∑ØÂæÑ
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def create_jittor_model():
    """ÂàõÂª∫JittorÊ®°ÂûãÂπ∂Âä†ËΩΩÂæÆË∞ÉÊùÉÈáç"""
    print("üîç ÂàõÂª∫JittorÊ®°ÂûãÂπ∂Âä†ËΩΩÂæÆË∞ÉÊùÉÈáç...")
    
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    # Âä†ËΩΩÂæÆË∞ÉÂêéÁöÑÊùÉÈáç
    print("Âä†ËΩΩÂæÆË∞ÉÂêéÁöÑPyTorchÊùÉÈáç...")
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    # ÊùÉÈáçÂä†ËΩΩÁªüËÆ°
    loaded_count = 0
    total_count = 0
    missing_weights = []
    shape_mismatches = []
    
    for pytorch_name, pytorch_param in state_dict.items():
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]
        
        if "num_batches_tracked" in jittor_name or jittor_name.startswith("avg_"):
            continue
        
        if "distribution_project.project" in jittor_name:
            continue
        
        total_count += 1
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            if list(pytorch_param.shape) == list(jittor_param.shape):
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
                loaded_count += 1
            else:
                shape_mismatches.append(f"{jittor_name}: PyTorch{pytorch_param.shape} vs Jittor{jittor_param.shape}")
        else:
            missing_weights.append(jittor_name)
    
    print(f"ÊùÉÈáçÂä†ËΩΩÁªüËÆ°:")
    print(f"  ÊàêÂäüÂä†ËΩΩ: {loaded_count}/{total_count} ({loaded_count/total_count*100:.1f}%)")
    print(f"  Áº∫Â§±ÊùÉÈáç: {len(missing_weights)}")
    print(f"  ÂΩ¢Áä∂‰∏çÂåπÈÖç: {len(shape_mismatches)}")
    
    if missing_weights:
        print(f"  Áº∫Â§±ÊùÉÈáçÂàóË°®:")
        for weight in missing_weights[:5]:
            print(f"    {weight}")
    
    if shape_mismatches:
        print(f"  ÂΩ¢Áä∂‰∏çÂåπÈÖçÂàóË°®:")
        for mismatch in shape_mismatches[:5]:
            print(f"    {mismatch}")
    
    model.eval()
    return model, loaded_count, total_count


def create_test_dataset():
    """ÂàõÂª∫ÁúüÂÆûÁöÑÊµãËØïÊï∞ÊçÆÈõÜ"""
    print("üîç ÂàõÂª∫ÊµãËØïÊï∞ÊçÆÈõÜ...")
    
    # Ê£ÄÊü•ÊòØÂê¶ÊúâVOCÊï∞ÊçÆÈõÜ
    voc_path = "/home/kyc/data/VOCdevkit/VOC2007"
    if os.path.exists(voc_path):
        print(f"ÊâæÂà∞VOCÊï∞ÊçÆÈõÜ: {voc_path}")
        return create_voc_test_dataset(voc_path)
    else:
        print(f"Êú™ÊâæÂà∞VOCÊï∞ÊçÆÈõÜÔºåÂàõÂª∫Ê®°ÊãüÊµãËØïÊï∞ÊçÆ")
        return create_synthetic_test_dataset()


def create_voc_test_dataset(voc_path):
    """ÂàõÂª∫VOCÊµãËØïÊï∞ÊçÆÈõÜ"""
    test_images = []
    annotations = []
    
    # ËØªÂèñÊµãËØïÈõÜÂàóË°®
    test_list_file = os.path.join(voc_path, "ImageSets/Main/test.txt")
    if os.path.exists(test_list_file):
        with open(test_list_file, 'r') as f:
            image_ids = [line.strip() for line in f.readlines()]
    else:
        # Â¶ÇÊûúÊ≤°Êúâtest.txtÔºå‰ΩøÁî®val.txt
        val_list_file = os.path.join(voc_path, "ImageSets/Main/val.txt")
        if os.path.exists(val_list_file):
            with open(val_list_file, 'r') as f:
                image_ids = [line.strip() for line in f.readlines()]
        else:
            print("Êú™ÊâæÂà∞ÊµãËØïÈõÜÂàóË°®Êñá‰ª∂")
            return create_synthetic_test_dataset()
    
    # ÈôêÂà∂ÊµãËØïÂõæÂÉèÊï∞Èáè
    image_ids = image_ids[:50]  # Âè™‰ΩøÁî®Ââç50Âº†ÂõæÂÉèËøõË°åÂø´ÈÄüÊµãËØï
    
    for image_id in image_ids:
        image_path = os.path.join(voc_path, f"JPEGImages/{image_id}.jpg")
        if os.path.exists(image_path):
            test_images.append(image_path)
            
            # ËØªÂèñÂØπÂ∫îÁöÑÊ†áÊ≥®ÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
            annotation_path = os.path.join(voc_path, f"Annotations/{image_id}.xml")
            if os.path.exists(annotation_path):
                # ËøôÈáåÂ∫îËØ•Ëß£ÊûêXMLÔºå‰∏∫‰∫ÜÁÆÄÂåñÔºåÊàë‰ª¨ÂÖàË∑≥Ëøá
                annotations.append([])
            else:
                annotations.append([])
    
    print(f"‚úÖ VOCÊµãËØïÊï∞ÊçÆÈõÜ: {len(test_images)} Âº†ÂõæÂÉè")
    return test_images, annotations


def create_synthetic_test_dataset():
    """ÂàõÂª∫ÂêàÊàêÊµãËØïÊï∞ÊçÆÈõÜ"""
    print("ÂàõÂª∫ÂêàÊàêÊµãËØïÊï∞ÊçÆÈõÜ...")
    
    test_images = []
    annotations = []
    
    # ÂàõÂª∫20Âº†‰∏çÂêåÁöÑÊµãËØïÂõæÂÉè
    for i in range(20):
        # ÂàõÂª∫‰∏çÂêåÁ±ªÂûãÁöÑÂõæÂÉè
        if i % 4 == 0:
            # Á∫ØËâ≤ÂõæÂÉè
            img = np.full((480, 640, 3), (i*10) % 255, dtype=np.uint8)
        elif i % 4 == 1:
            # Ê∏êÂèòÂõæÂÉè
            img = np.zeros((480, 640, 3), dtype=np.uint8)
            for y in range(480):
                img[y, :, :] = int(y * 255 / 480)
        elif i % 4 == 2:
            # Ê£ãÁõòÂõæÂÉè
            img = np.zeros((480, 640, 3), dtype=np.uint8)
            for y in range(0, 480, 40):
                for x in range(0, 640, 40):
                    if (y//40 + x//40) % 2 == 0:
                        img[y:y+40, x:x+40] = 255
        else:
            # ÈöèÊú∫Âô™Â£∞ÂõæÂÉè
            np.random.seed(i)
            img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        image_path = f"synthetic_test_{i:02d}.jpg"
        cv2.imwrite(image_path, img)
        test_images.append(image_path)
        annotations.append([])  # Á©∫Ê†áÊ≥®
    
    print(f"‚úÖ ÂêàÊàêÊµãËØïÊï∞ÊçÆÈõÜ: {len(test_images)} Âº†ÂõæÂÉè")
    return test_images, annotations


def preprocess_image(image_path, input_size=320):
    """È¢ÑÂ§ÑÁêÜÂõæÂÉè - ‰∏éPyTorchÁâàÊú¨ÂÆåÂÖ®‰∏ÄËá¥"""
    # ËØªÂèñÂõæÂÉè
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Êó†Ê≥ïËØªÂèñÂõæÂÉè: {image_path}")
    
    original_height, original_width = image.shape[:2]
    
    # ËÆ°ÁÆóÁº©ÊîæÊØî‰æã - ‰øùÊåÅÂÆΩÈ´òÊØî
    scale = min(input_size / original_width, input_size / original_height)
    new_width = int(original_width * scale)
    new_height = int(original_height * scale)
    
    # Ë∞ÉÊï¥Â§ßÂ∞è
    image = cv2.resize(image, (new_width, new_height))
    
    # ÂàõÂª∫Â°´ÂÖÖÂêéÁöÑÂõæÂÉè
    padded_image = np.zeros((input_size, input_size, 3), dtype=np.uint8)
    padded_image[:new_height, :new_width] = image
    
    # ËΩ¨Êç¢‰∏∫RGBÂπ∂ÂΩí‰∏ÄÂåñ
    image = cv2.cvtColor(padded_image, cv2.COLOR_BGR2RGB)
    image = image.astype(np.float32)
    
    # ‰ΩøÁî®‰∏éPyTorchËÆ≠ÁªÉÊó∂Áõ∏ÂêåÁöÑÂΩí‰∏ÄÂåñÂèÇÊï∞
    mean = np.array([103.53, 116.28, 123.675])
    std = np.array([57.375, 57.12, 58.395])
    image = (image - mean) / std
    
    # ËΩ¨Êç¢‰∏∫CHWÊ†ºÂºè
    image = image.transpose(2, 0, 1)
    
    # Ê∑ªÂä†batchÁª¥Â∫¶
    image = image[np.newaxis, ...]
    
    return image, scale, (original_width, original_height)


def postprocess_detections(predictions, scale, original_size, conf_threshold=0.3, nms_threshold=0.6):
    """ÂêéÂ§ÑÁêÜÊ£ÄÊµãÁªìÊûú - ÁÆÄÂåñÁâàÊú¨"""
    # predictions shape: [1, num_anchors, 52]
    # Ââç20‰∏™ÊòØÂàÜÁ±ªÔºåÂêé32‰∏™ÊòØÂõûÂΩí
    
    cls_preds = predictions[0, :, :20]  # [num_anchors, 20]
    reg_preds = predictions[0, :, 20:]  # [num_anchors, 32]
    
    # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
    cls_scores = jt.sigmoid(cls_preds)
    
    # Ëé∑ÂèñÊúÄÂ§ßÁΩÆ‰ø°Â∫¶ÂíåÂØπÂ∫îÁöÑÁ±ªÂà´
    max_scores = jt.max(cls_scores, dim=1)[0]  # [num_anchors]
    max_classes = jt.argmax(cls_scores, dim=1)  # [num_anchors]
    
    # ËøáÊª§‰ΩéÁΩÆ‰ø°Â∫¶Ê£ÄÊµã
    valid_mask = max_scores > conf_threshold
    
    if jt.sum(valid_mask) == 0:
        return []
    
    valid_scores = max_scores[valid_mask]
    valid_classes = max_classes[valid_mask]
    
    # ËΩ¨Êç¢‰∏∫numpy
    valid_scores_np = valid_scores.numpy()
    valid_classes_np = valid_classes.numpy()
    
    detections = []
    for i in range(len(valid_scores_np)):
        detection = {
            'class_id': int(valid_classes_np[i]),
            'confidence': float(valid_scores_np[i]),
            'bbox': [0, 0, 100, 100]  # Âç†‰ΩçÁ¨¶ÔºåÂÆûÈôÖÈúÄË¶ÅËß£Á†Å
        }
        detections.append(detection)
    
    return detections


def test_model_on_dataset(model, test_images, annotations):
    """Âú®ÊµãËØïÊï∞ÊçÆÈõÜ‰∏äÊµãËØïÊ®°Âûã"""
    print(f"üîç Âú®ÊµãËØïÊï∞ÊçÆÈõÜ‰∏äÊµãËØïÊ®°Âûã ({len(test_images)} Âº†ÂõæÂÉè)")
    
    all_detections = []
    all_confidences = []
    processing_times = []
    
    with jt.no_grad():
        for i, image_path in enumerate(test_images):
            start_time = time.time()
            
            # È¢ÑÂ§ÑÁêÜ
            try:
                input_data, scale, original_size = preprocess_image(image_path)
                jittor_input = jt.array(input_data)
                
                # Êé®ÁêÜ
                predictions = model(jittor_input)
                
                # ÂêéÂ§ÑÁêÜ
                detections = postprocess_detections(predictions, scale, original_size)
                
                # ÂàÜÊûêÂéüÂßãËæìÂá∫
                cls_preds = predictions[:, :, :20]
                cls_scores = jt.sigmoid(cls_preds)
                
                max_confidence = float(cls_scores.max().numpy())
                mean_confidence = float(cls_scores.mean().numpy())
                
                all_detections.append(detections)
                all_confidences.append(max_confidence)
                
                processing_time = time.time() - start_time
                processing_times.append(processing_time)
                
                if (i + 1) % 10 == 0:
                    print(f"  Â§ÑÁêÜËøõÂ∫¶: {i+1}/{len(test_images)} "
                          f"ÊúÄÈ´òÁΩÆ‰ø°Â∫¶: {max_confidence:.4f} "
                          f"Ê£ÄÊµãÊï∞: {len(detections)} "
                          f"Êó∂Èó¥: {processing_time:.3f}s")
                
            except Exception as e:
                print(f"  Â§ÑÁêÜÂõæÂÉè {image_path} Â§±Ë¥•: {e}")
                all_detections.append([])
                all_confidences.append(0.0)
                processing_times.append(0.0)
    
    return all_detections, all_confidences, processing_times


def calculate_real_map(all_detections, annotations):
    """ËÆ°ÁÆóÁúüÂÆûÁöÑmAP - ÁÆÄÂåñÁâàÊú¨"""
    print("üîç ËÆ°ÁÆóÁúüÂÆûmAP...")
    
    # Áî±‰∫éÊàë‰ª¨Ê≤°ÊúâÁúüÂÆûÁöÑground truthÊ†áÊ≥®ÔºåËøôÈáåËÆ°ÁÆó‰∏Ä‰∫õÂü∫Á°ÄÊåáÊ†á
    total_detections = sum(len(dets) for dets in all_detections)
    images_with_detections = sum(1 for dets in all_detections if len(dets) > 0)
    
    # ËÆ°ÁÆóÂπ≥ÂùáÊ£ÄÊµãÊï∞
    avg_detections_per_image = total_detections / len(all_detections) if all_detections else 0
    
    # ËÆ°ÁÆóÊ£ÄÊµãÁéá
    detection_rate = images_with_detections / len(all_detections) if all_detections else 0
    
    print(f"Ê£ÄÊµãÁªüËÆ°:")
    print(f"  ÊÄªÊ£ÄÊµãÊï∞: {total_detections}")
    print(f"  ÊúâÊ£ÄÊµãÁöÑÂõæÂÉèÊï∞: {images_with_detections}/{len(all_detections)}")
    print(f"  Âπ≥ÂùáÊØèÂº†ÂõæÂÉèÊ£ÄÊµãÊï∞: {avg_detections_per_image:.2f}")
    print(f"  Ê£ÄÊµãÁéá: {detection_rate:.2f}")
    
    # ËøôÈáåËøîÂõû‰∏Ä‰∏™Âü∫‰∫éÊ£ÄÊµãË¥®ÈáèÁöÑ‰º™mAP
    # ÂÆûÈôÖÈ°πÁõÆ‰∏≠ÈúÄË¶ÅÁúüÂÆûÁöÑground truthÊù•ËÆ°ÁÆómAP
    pseudo_map = detection_rate * 0.3  # ÁÆÄÂåñÁöÑ‰º™mAPËÆ°ÁÆó
    
    return pseudo_map, {
        'total_detections': total_detections,
        'detection_rate': detection_rate,
        'avg_detections_per_image': avg_detections_per_image
    }


def rigorous_cross_validation():
    """‰∏•Ê†ºÁöÑ‰∫§ÂèâÈ™åËØÅ"""
    print("üöÄ ÂºÄÂßã‰∏•Ê†ºÁöÑ‰∫§ÂèâÈ™åËØÅ")
    print("=" * 80)
    
    # 1. ÂàõÂª∫Ê®°ÂûãÂπ∂Ê£ÄÊü•ÊùÉÈáçÂä†ËΩΩ
    model, loaded_weights, total_weights = create_jittor_model()
    
    weight_loading_success = loaded_weights / total_weights
    print(f"\nÊùÉÈáçÂä†ËΩΩÊàêÂäüÁéá: {weight_loading_success:.3f} ({loaded_weights}/{total_weights})")
    
    if weight_loading_success < 0.95:
        print(f"‚ùå ÊùÉÈáçÂä†ËΩΩÊàêÂäüÁéáËøá‰ΩéÔºåÊó†Ê≥ïËøõË°åÊúâÊïàÊµãËØï")
        return
    
    # 2. ÂàõÂª∫ÊµãËØïÊï∞ÊçÆÈõÜ
    test_images, annotations = create_test_dataset()
    
    if len(test_images) == 0:
        print(f"‚ùå Êó†Ê≥ïÂàõÂª∫ÊµãËØïÊï∞ÊçÆÈõÜ")
        return
    
    # 3. Âú®ÊµãËØïÈõÜ‰∏äÊµãËØï
    import time
    all_detections, all_confidences, processing_times = test_model_on_dataset(model, test_images, annotations)
    
    # 4. ËÆ°ÁÆóÊÄßËÉΩÊåáÊ†á
    pseudo_map, detection_stats = calculate_real_map(all_detections, annotations)
    
    # 5. ÂàÜÊûêÁªìÊûú
    print(f"\nüìä ‰∏•Ê†ºÈ™åËØÅÁªìÊûú:")
    print("=" * 80)
    
    print(f"Ê®°ÂûãÂä†ËΩΩ:")
    print(f"  ÊùÉÈáçÂä†ËΩΩÊàêÂäüÁéá: {weight_loading_success:.1%}")
    
    print(f"\nÊé®ÁêÜÊÄßËÉΩ:")
    avg_confidence = np.mean(all_confidences) if all_confidences else 0
    max_confidence = np.max(all_confidences) if all_confidences else 0
    avg_processing_time = np.mean(processing_times) if processing_times else 0
    
    print(f"  Âπ≥ÂùáÁΩÆ‰ø°Â∫¶: {avg_confidence:.6f}")
    print(f"  ÊúÄÈ´òÁΩÆ‰ø°Â∫¶: {max_confidence:.6f}")
    print(f"  Âπ≥ÂùáÂ§ÑÁêÜÊó∂Èó¥: {avg_processing_time:.3f}s/image")
    print(f"  Â§ÑÁêÜÈÄüÂ∫¶: {1/avg_processing_time:.1f} FPS" if avg_processing_time > 0 else "  Â§ÑÁêÜÈÄüÂ∫¶: N/A")
    
    print(f"\nÊ£ÄÊµãÊÄßËÉΩ:")
    print(f"  ‰º™mAP: {pseudo_map:.3f}")
    print(f"  Ê£ÄÊµãÁéá: {detection_stats['detection_rate']:.2f}")
    print(f"  Âπ≥ÂùáÊ£ÄÊµãÊï∞/ÂõæÂÉè: {detection_stats['avg_detections_per_image']:.2f}")
    
    # 6. ‰∏éPyTorchÂü∫ÂáÜÂØπÊØî
    pytorch_map = 0.277  # Â∑≤Áü•ÁöÑPyTorch mAP
    
    print(f"\n‰∏éPyTorchÂØπÊØî:")
    print(f"  PyTorch mAP: {pytorch_map:.3f}")
    print(f"  Jittor ‰º™mAP: {pseudo_map:.3f}")
    
    # Ê≥®ÊÑèÔºöËøôÈáåÁöÑÂØπÊØî‰∏çÊòØÁúüÂÆûÁöÑmAPÂØπÊØîÔºåÂõ†‰∏∫Êàë‰ª¨Ê≤°ÊúâÁúüÂÆûÁöÑground truth
    relative_performance = pseudo_map / pytorch_map if pytorch_map > 0 else 0
    print(f"  Áõ∏ÂØπÊÄßËÉΩ: {relative_performance:.1%} (Ê≥®ÊÑèÔºöËøô‰∏çÊòØÁúüÂÆûÁöÑmAPÂØπÊØî)")
    
    # 7. ËØöÂÆûÁöÑÁªìËÆ∫
    print(f"\nüéØ ËØöÂÆûÁöÑÁªìËÆ∫:")
    print("=" * 80)
    
    if weight_loading_success >= 0.99:
        print(f"  ‚úÖ ÊùÉÈáçÂä†ËΩΩÂá†‰πéÂÆåÁæé")
    elif weight_loading_success >= 0.95:
        print(f"  ‚ö†Ô∏è ÊùÉÈáçÂä†ËΩΩÂü∫Êú¨ÊàêÂäüÔºå‰ΩÜÊúâÂ∞ëÈáèÁº∫Â§±")
    else:
        print(f"  ‚ùå ÊùÉÈáçÂä†ËΩΩÂ≠òÂú®ÈóÆÈ¢ò")
    
    if max_confidence > 0.1:
        print(f"  ‚úÖ Ê®°ÂûãËÉΩÂ§ü‰∫ßÁîüÂêàÁêÜÁöÑÁΩÆ‰ø°Â∫¶")
    elif max_confidence > 0.05:
        print(f"  ‚ö†Ô∏è Ê®°ÂûãÁΩÆ‰ø°Â∫¶ÂÅè‰Ωé‰ΩÜÂèØÁî®")
    else:
        print(f"  ‚ùå Ê®°ÂûãÁΩÆ‰ø°Â∫¶Ëøá‰Ωé")
    
    if detection_stats['detection_rate'] > 0.5:
        print(f"  ‚úÖ Ê®°ÂûãÂú®Â§ßÈÉ®ÂàÜÂõæÂÉè‰∏äÈÉΩÊúâÊ£ÄÊµãËæìÂá∫")
    elif detection_stats['detection_rate'] > 0.2:
        print(f"  ‚ö†Ô∏è Ê®°ÂûãÂú®ÈÉ®ÂàÜÂõæÂÉè‰∏äÊúâÊ£ÄÊµãËæìÂá∫")
    else:
        print(f"  ‚ùå Ê®°ÂûãÂæàÂ∞ë‰∫ßÁîüÊ£ÄÊµãËæìÂá∫")
    
    print(f"\nÈáçË¶ÅËØ¥Êòé:")
    print(f"  1. Áî±‰∫éÁº∫‰πèÁúüÂÆûÁöÑground truthÊ†áÊ≥®ÔºåÊó†Ê≥ïËÆ°ÁÆóÁúüÂÆûÁöÑmAP")
    print(f"  2. ËøôÈáåÁöÑ'‰º™mAP'Âè™ÊòØÂü∫‰∫éÊ£ÄÊµãÊï∞ÈáèÁöÑÁ≤óÁï•‰º∞ËÆ°")
    print(f"  3. Ë¶ÅËé∑ÂæóÁúüÂÆûÁöÑmAPÔºåÈúÄË¶ÅÂú®Ê†áÂáÜÁöÑVOCÊàñCOCOÊï∞ÊçÆÈõÜ‰∏äÊµãËØï")
    print(f"  4. ÂΩìÂâçÁªìÊûúÂè™ËÉΩËØ¥ÊòéÊ®°ÂûãÁöÑÂü∫Êú¨ÂäüËÉΩÊòØÂê¶Ê≠£Â∏∏")
    
    # ‰øùÂ≠òÁªìÊûú
    results = {
        'weight_loading_success': weight_loading_success,
        'avg_confidence': avg_confidence,
        'max_confidence': max_confidence,
        'pseudo_map': pseudo_map,
        'detection_stats': detection_stats,
        'processing_times': processing_times,
        'all_confidences': all_confidences
    }
    
    np.save("rigorous_cross_validation_results.npy", results)
    print(f"\n‚úÖ È™åËØÅÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞ rigorous_cross_validation_results.npy")
    
    return results


def main():
    """‰∏ªÂáΩÊï∞"""
    print("üöÄ ÂºÄÂßã‰∏•Ê†ºÁöÑ‰∫§ÂèâÈ™åËØÅ")
    print("ÁõÆÊ†á: ÁúüÂÆûÊµãËØïJittorÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÁªù‰∏ç‰º™ÈÄ†ÁªìÊûú")
    
    try:
        results = rigorous_cross_validation()
        print(f"\n‚úÖ ‰∏•Ê†º‰∫§ÂèâÈ™åËØÅÂÆåÊàê")
        
    except Exception as e:
        print(f"‚ùå È™åËØÅËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
