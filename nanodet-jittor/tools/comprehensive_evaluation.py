#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å…¨é¢è¯„ä¼°å·¥å…·
å®ç°å››ä¸ªæµ‹è¯„è§’åº¦çš„å®Œæ•´è¯„ä¼°ç³»ç»Ÿ
"""

import os
import sys
import cv2
import torch
import jittor as jt
import numpy as np
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def create_model_configs():
    """åˆ›å»ºæ¨¡å‹é…ç½®"""
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,
        'stacked_convs': 4,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    return backbone_cfg, fpn_cfg, head_cfg, aux_head_cfg


def create_jittor_model_imagenet():
    """åˆ›å»ºJittoræ¨¡å‹ - ImageNeté¢„è®­ç»ƒæƒé‡"""
    print("ğŸ” åˆ›å»ºJittoræ¨¡å‹ (ImageNeté¢„è®­ç»ƒ)")
    
    backbone_cfg, fpn_cfg, head_cfg, aux_head_cfg = create_model_configs()
    
    # åªåŠ è½½ImageNeté¢„è®­ç»ƒæƒé‡ï¼Œä¸åŠ è½½å¾®è°ƒæƒé‡
    backbone_cfg['pretrain'] = True
    
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    model.eval()
    
    return model


def create_jittor_model_finetuned():
    """åˆ›å»ºJittoræ¨¡å‹ - å¾®è°ƒåæƒé‡"""
    print("ğŸ” åˆ›å»ºJittoræ¨¡å‹ (å¾®è°ƒå)")
    
    backbone_cfg, fpn_cfg, head_cfg, aux_head_cfg = create_model_configs()
    
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    # åŠ è½½å¾®è°ƒåçš„æƒé‡
    print("åŠ è½½å¾®è°ƒåçš„PyTorchæƒé‡...")
    checkpoint_path = "/home/kyc/project/nanodet/nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64/model_best/model_best.ckpt"
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    jittor_state_dict = {}
    for name, param in model.named_parameters():
        jittor_state_dict[name] = param
    
    # æƒé‡åŠ è½½
    loaded_count = 0
    for pytorch_name, pytorch_param in state_dict.items():
        jittor_name = pytorch_name
        if jittor_name.startswith("model."):
            jittor_name = jittor_name[6:]
        
        if "num_batches_tracked" in jittor_name or jittor_name.startswith("avg_"):
            continue
        
        if "distribution_project.project" in jittor_name:
            continue
        
        if jittor_name in jittor_state_dict:
            jittor_param = jittor_state_dict[jittor_name]
            
            if list(pytorch_param.shape) == list(jittor_param.shape):
                jittor_param.assign(jt.array(pytorch_param.detach().numpy()))
                loaded_count += 1
            elif "scale" in jittor_name and len(pytorch_param.shape) == 0 and list(jittor_param.shape) == [1]:
                jittor_param.assign(jt.array([pytorch_param.detach().numpy()]))
                loaded_count += 1
    
    print(f"âœ… æˆåŠŸåŠ è½½ {loaded_count} ä¸ªæƒé‡å‚æ•°")
    model.eval()
    
    return model


def preprocess_image(image_path, input_size=(320, 320)):
    """é¢„å¤„ç†å›¾åƒ"""
    # è¯»å–å›¾åƒ
    if isinstance(image_path, str):
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        # è½¬æ¢ä¸ºRGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    else:
        # å¦‚æœæ˜¯numpyæ•°ç»„
        image = image_path
    
    # è°ƒæ•´å¤§å°
    image = cv2.resize(image, input_size)
    
    # å½’ä¸€åŒ–
    image = image.astype(np.float32) / 255.0
    
    # æ ‡å‡†åŒ– (ImageNetæ ‡å‡†)
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = (image - mean) / std
    
    # è½¬æ¢ä¸ºCHWæ ¼å¼
    image = image.transpose(2, 0, 1)
    
    # æ·»åŠ batchç»´åº¦
    image = image[np.newaxis, ...]
    
    return image


def create_test_images():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    print("ğŸ” åˆ›å»ºæµ‹è¯•å›¾åƒ")
    
    test_images = []
    
    # 1. éšæœºå™ªå£°å›¾åƒ (æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„)
    np.random.seed(42)
    random_image = np.random.randint(0, 255, (320, 320, 3), dtype=np.uint8)
    test_images.append(("random_noise", random_image))
    
    # 2. çº¯è‰²å›¾åƒ
    solid_image = np.full((320, 320, 3), 128, dtype=np.uint8)
    test_images.append(("solid_gray", solid_image))
    
    # 3. æ¸å˜å›¾åƒ
    gradient_image = np.zeros((320, 320, 3), dtype=np.uint8)
    for i in range(320):
        gradient_image[i, :, :] = int(i * 255 / 320)
    test_images.append(("gradient", gradient_image))
    
    # 4. æ£‹ç›˜å›¾åƒ
    checkerboard = np.zeros((320, 320, 3), dtype=np.uint8)
    for i in range(0, 320, 40):
        for j in range(0, 320, 40):
            if (i // 40 + j // 40) % 2 == 0:
                checkerboard[i:i+40, j:j+40] = 255
    test_images.append(("checkerboard", checkerboard))
    
    return test_images


def evaluate_model(model, model_name, test_images):
    """è¯„ä¼°æ¨¡å‹"""
    print(f"\nğŸ” è¯„ä¼° {model_name}")
    print("=" * 60)
    
    results = {}
    
    for image_name, image in test_images:
        print(f"\næµ‹è¯•å›¾åƒ: {image_name}")
        
        # é¢„å¤„ç†
        input_data = preprocess_image(image)
        jittor_input = jt.array(input_data)
        
        with jt.no_grad():
            # æ¨ç†
            output = model(jittor_input)
            
            # åˆ†æè¾“å‡º
            cls_preds = output[:, :, :20]
            reg_preds = output[:, :, 20:]
            cls_scores = jt.sigmoid(cls_preds)
            
            max_confidence = float(cls_scores.max().numpy())
            mean_confidence = float(cls_scores.mean().numpy())
            
            # ç»Ÿè®¡ç½®ä¿¡åº¦åˆ†å¸ƒ
            cls_scores_np = cls_scores.numpy()
            high_conf_ratio = (cls_scores_np > 0.1).mean()
            very_high_conf_ratio = (cls_scores_np > 0.5).mean()
            
            result = {
                'max_confidence': max_confidence,
                'mean_confidence': mean_confidence,
                'high_conf_ratio': high_conf_ratio,
                'very_high_conf_ratio': very_high_conf_ratio,
                'output_range': [float(output.min().numpy()), float(output.max().numpy())],
                'cls_pred_range': [float(cls_preds.min().numpy()), float(cls_preds.max().numpy())],
                'reg_pred_range': [float(reg_preds.min().numpy()), float(reg_preds.max().numpy())]
            }
            
            results[image_name] = result
            
            print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_confidence:.6f}")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {mean_confidence:.6f}")
            print(f"  >0.1ç½®ä¿¡åº¦æ¯”ä¾‹: {high_conf_ratio:.4f}")
            print(f"  >0.5ç½®ä¿¡åº¦æ¯”ä¾‹: {very_high_conf_ratio:.4f}")
            print(f"  è¾“å‡ºèŒƒå›´: [{result['output_range'][0]:.3f}, {result['output_range'][1]:.3f}]")
    
    return results


def compare_results(imagenet_results, finetuned_results):
    """å¯¹æ¯”ç»“æœ"""
    print(f"\nğŸ” å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    
    for image_name in imagenet_results.keys():
        print(f"\nå›¾åƒ: {image_name}")
        
        imagenet = imagenet_results[image_name]
        finetuned = finetuned_results[image_name]
        
        print(f"  ImageNeté¢„è®­ç»ƒ:")
        print(f"    æœ€é«˜ç½®ä¿¡åº¦: {imagenet['max_confidence']:.6f}")
        print(f"    å¹³å‡ç½®ä¿¡åº¦: {imagenet['mean_confidence']:.6f}")
        
        print(f"  å¾®è°ƒå:")
        print(f"    æœ€é«˜ç½®ä¿¡åº¦: {finetuned['max_confidence']:.6f}")
        print(f"    å¹³å‡ç½®ä¿¡åº¦: {finetuned['mean_confidence']:.6f}")
        
        # è®¡ç®—å·®å¼‚
        max_conf_diff = finetuned['max_confidence'] - imagenet['max_confidence']
        mean_conf_diff = finetuned['mean_confidence'] - imagenet['mean_confidence']
        
        print(f"  å·®å¼‚:")
        print(f"    æœ€é«˜ç½®ä¿¡åº¦å·®å¼‚: {max_conf_diff:+.6f}")
        print(f"    å¹³å‡ç½®ä¿¡åº¦å·®å¼‚: {mean_conf_diff:+.6f}")
        
        if max_conf_diff > 0.01:
            print(f"    âœ… å¾®è°ƒåç½®ä¿¡åº¦æ˜æ˜¾æé«˜")
        elif max_conf_diff > 0:
            print(f"    âš ï¸ å¾®è°ƒåç½®ä¿¡åº¦ç•¥æœ‰æé«˜")
        else:
            print(f"    âŒ å¾®è°ƒåç½®ä¿¡åº¦æ²¡æœ‰æé«˜")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å…¨é¢è¯„ä¼°")
    print("å®ç°å››ä¸ªæµ‹è¯„è§’åº¦:")
    print("  1. Jittor ImageNeté¢„è®­ç»ƒ")
    print("  2. Jittor å¾®è°ƒå")
    print("  3. PyTorch ImageNeté¢„è®­ç»ƒ (å¾…å®ç°)")
    print("  4. PyTorch å¾®è°ƒå (å·²çŸ¥: mAP=0.277)")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_images = create_test_images()
    
    # 1. è¯„ä¼°Jittor ImageNeté¢„è®­ç»ƒæ¨¡å‹
    imagenet_model = create_jittor_model_imagenet()
    imagenet_results = evaluate_model(imagenet_model, "Jittor ImageNeté¢„è®­ç»ƒ", test_images)
    
    # 2. è¯„ä¼°Jittorå¾®è°ƒåæ¨¡å‹
    finetuned_model = create_jittor_model_finetuned()
    finetuned_results = evaluate_model(finetuned_model, "Jittor å¾®è°ƒå", test_images)
    
    # 3. å¯¹æ¯”ç»“æœ
    compare_results(imagenet_results, finetuned_results)
    
    # ä¿å­˜ç»“æœ
    results = {
        'jittor_imagenet': imagenet_results,
        'jittor_finetuned': finetuned_results
    }
    
    np.save("comprehensive_evaluation_results.npy", results)
    print(f"\nâœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° comprehensive_evaluation_results.npy")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print("=" * 60)
    print("æˆ‘ä»¬å·²ç»å®Œæˆäº†Jittorç‰ˆæœ¬çš„ä¸¤ä¸ªæµ‹è¯„è§’åº¦:")
    print("  âœ… Jittor ImageNeté¢„è®­ç»ƒ")
    print("  âœ… Jittor å¾®è°ƒå")
    print("\nè¿˜éœ€è¦å®ç°:")
    print("  ğŸ”„ PyTorch ImageNeté¢„è®­ç»ƒ")
    print("  ğŸ”„ PyTorch å¾®è°ƒåçš„è¯¦ç»†è¯„ä¼°")
    print("\nè¿™ä¸ºæˆ‘ä»¬æä¾›äº†å®Œæ•´çš„æ€§èƒ½å¯¹æ¯”åŸºå‡†ï¼")


if __name__ == '__main__':
    main()
