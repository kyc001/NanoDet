#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®VOCæ•°æ®è®­ç»ƒï¼ˆç¦ç”¨é¢„è®­ç»ƒæƒé‡ï¼‰
é¿å…é…ç½®æ–‡ä»¶é—®é¢˜ï¼Œç›´æ¥æ‰‹åŠ¨æ„å»º
"""

import os
import sys
import logging
import jittor as jt
from pathlib import Path
import time
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def check_voc_data():
    """æ£€æŸ¥VOCæ•°æ®"""
    logger = logging.getLogger(__name__)
    
    data_root = project_root / "data"
    train_ann = data_root / "annotations" / "voc_train.json"
    val_ann = data_root / "annotations" / "voc_val.json"
    img_dir = data_root / "VOCdevkit" / "VOC2007" / "JPEGImages"
    
    logger.info("æ£€æŸ¥VOCæ•°æ®...")
    logger.info(f"è®­ç»ƒæ ‡æ³¨: {train_ann.exists()}")
    logger.info(f"éªŒè¯æ ‡æ³¨: {val_ann.exists()}")
    logger.info(f"å›¾åƒç›®å½•: {img_dir.exists()}")
    
    if img_dir.exists():
        images = list(img_dir.glob("*.jpg"))
        logger.info(f"å›¾åƒæ•°é‡: {len(images)}")
    
    if train_ann.exists():
        with open(train_ann, 'r') as f:
            train_data = json.load(f)
        logger.info(f"è®­ç»ƒé›†: {len(train_data.get('images', []))}å›¾åƒ, {len(train_data.get('annotations', []))}æ ‡æ³¨")
    
    if val_ann.exists():
        with open(val_ann, 'r') as f:
            val_data = json.load(f)
        logger.info(f"éªŒè¯é›†: {len(val_data.get('images', []))}å›¾åƒ, {len(val_data.get('annotations', []))}æ ‡æ³¨")
    
    return train_ann.exists() and val_ann.exists() and img_dir.exists()

def create_model_no_pretrain():
    """åˆ›å»ºæ¨¡å‹ï¼ˆæ— é¢„è®­ç»ƒæƒé‡ï¼‰"""
    from nanodet.model import build_model
    
    model_cfg = {
        'name': 'NanoDetPlus',
        'backbone': {
            'name': 'ShuffleNetV2',
            'model_size': '1.0x',
            'out_stages': [2, 3, 4],
            'activation': 'LeakyReLU',
            'pretrain': False  # ç¦ç”¨é¢„è®­ç»ƒ
        },
        'fpn': {
            'name': 'GhostPAN',
            'in_channels': [116, 232, 464],
            'out_channels': 96,
            'kernel_size': 5,
            'num_extra_level': 1,
            'use_depthwise': True,
            'activation': 'LeakyReLU'
        },
        'head': {
            'name': 'NanoDetPlusHead',
            'num_classes': 20,
            'input_channel': 96,
            'feat_channels': 96,
            'stacked_convs': 2,
            'kernel_size': 5,
            'strides': [8, 16, 32, 64],
            'activation': 'LeakyReLU',
            'reg_max': 7,
            'norm_cfg': {'type': 'BN'},
            'loss': {
                'loss_qfl': {
                    'name': 'QualityFocalLoss',
                    'use_sigmoid': True,
                    'beta': 2.0,
                    'loss_weight': 1.0
                },
                'loss_dfl': {
                    'name': 'DistributionFocalLoss',
                    'loss_weight': 0.25
                },
                'loss_bbox': {
                    'name': 'GIoULoss',
                    'loss_weight': 2.0
                }
            }
        },
        'aux_head': {
            'name': 'SimpleConvHead',
            'num_classes': 20,
            'input_channel': 192,
            'feat_channels': 192,
            'stacked_convs': 4,
            'strides': [8, 16, 32, 64],
            'activation': 'LeakyReLU',
            'norm_cfg': {'type': 'BN'}
        },
        'detach_epoch': 10
    }
    
    return build_model(model_cfg)

def create_simple_voc_dataloader():
    """åˆ›å»ºç®€åŒ–çš„VOCæ•°æ®åŠ è½½å™¨"""
    logger = logging.getLogger(__name__)
    
    try:
        # è¯»å–æ ‡æ³¨æ–‡ä»¶
        data_root = project_root / "data"
        train_ann_file = data_root / "annotations" / "voc_train.json"
        
        with open(train_ann_file, 'r') as f:
            coco_data = json.load(f)
        
        images = coco_data['images']
        annotations = coco_data['annotations']
        
        # æ„å»ºå›¾åƒIDåˆ°æ ‡æ³¨çš„æ˜ å°„
        img_id_to_anns = {}
        for ann in annotations:
            img_id = ann['image_id']
            if img_id not in img_id_to_anns:
                img_id_to_anns[img_id] = []
            img_id_to_anns[img_id].append(ann)
        
        logger.info(f"åŠ è½½äº†{len(images)}å¼ å›¾åƒï¼Œ{len(annotations)}ä¸ªæ ‡æ³¨")
        
        # ç®€åŒ–çš„æ•°æ®ç”Ÿæˆå™¨
        def data_generator():
            import cv2
            import numpy as np
            
            img_dir = data_root / "VOCdevkit" / "VOC2007" / "JPEGImages"
            batch_size = 4
            batch_images = []
            batch_bboxes = []
            batch_labels = []
            batch_info = []
            
            for i, img_info in enumerate(images[:100]):  # åªç”¨å‰100å¼ å›¾åƒæµ‹è¯•
                img_path = img_dir / img_info['file_name']
                
                if not img_path.exists():
                    continue
                
                # è¯»å–å›¾åƒ
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                # è°ƒæ•´å¤§å°åˆ°320x320
                img = cv2.resize(img, (320, 320))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = img.astype(np.float32) / 255.0
                img = np.transpose(img, (2, 0, 1))  # HWC -> CHW
                
                # è·å–æ ‡æ³¨
                img_id = img_info['id']
                anns = img_id_to_anns.get(img_id, [])
                
                if len(anns) == 0:
                    continue
                
                # å¤„ç†bboxå’Œæ ‡ç­¾
                bboxes = []
                labels = []
                for ann in anns:
                    bbox = ann['bbox']  # [x, y, w, h]
                    # è½¬æ¢ä¸º[x1, y1, x2, y2]å¹¶ç¼©æ”¾åˆ°320x320
                    x1 = bbox[0] * 320 / img_info['width']
                    y1 = bbox[1] * 320 / img_info['height']
                    x2 = (bbox[0] + bbox[2]) * 320 / img_info['width']
                    y2 = (bbox[1] + bbox[3]) * 320 / img_info['height']
                    
                    bboxes.append([x1, y1, x2, y2])
                    labels.append(ann['category_id'] - 1)  # COCOç±»åˆ«IDä»1å¼€å§‹ï¼Œè½¬æ¢ä¸º0å¼€å§‹
                
                if len(bboxes) == 0:
                    continue
                
                batch_images.append(jt.array(img))
                batch_bboxes.append(jt.array(bboxes))
                batch_labels.append(jt.array(labels))
                batch_info.append({
                    'height': 320,
                    'width': 320,
                    'id': img_id
                })
                
                if len(batch_images) == batch_size:
                    # è¿”å›ä¸€ä¸ªbatch
                    gt_meta = {
                        'img': jt.stack(batch_images),
                        'gt_bboxes': batch_bboxes,
                        'gt_labels': batch_labels,
                        'img_info': batch_info
                    }
                    
                    yield gt_meta
                    
                    # é‡ç½®batch
                    batch_images = []
                    batch_bboxes = []
                    batch_labels = []
                    batch_info = []
        
        return data_generator()
        
    except Exception as e:
        logger.error(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def real_voc_training():
    """çœŸå®VOCæ•°æ®è®­ç»ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("çœŸå®VOCæ•°æ®è®­ç»ƒï¼ˆæ— é¢„è®­ç»ƒæƒé‡ï¼‰")
    logger.info("=" * 50)
    
    try:
        # æ£€æŸ¥æ•°æ®
        if not check_voc_data():
            logger.error("âŒ VOCæ•°æ®ä¸å®Œæ•´")
            return False
        
        # è®¾ç½®è®¾å¤‡
        if jt.has_cuda:
            jt.flags.use_cuda = 1
            logger.info("âœ… ä½¿ç”¨GPUæ¨¡å¼")
        else:
            jt.flags.use_cuda = 0
            logger.info("ä½¿ç”¨CPUæ¨¡å¼")
        
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹ï¼ˆæ— é¢„è®­ç»ƒï¼‰...")
        model = create_model_no_pretrain()
        model.train()
        logger.info("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        logger.info("åˆ›å»ºçœŸå®æ•°æ®åŠ è½½å™¨...")
        dataloader = create_simple_voc_dataloader()
        if dataloader is None:
            logger.error("âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥")
            return False
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)
        logger.info("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # è®­ç»ƒå¾ªç¯
        logger.info("å¼€å§‹çœŸå®VOCæ•°æ®è®­ç»ƒ...")
        
        epoch_loss = 0
        num_batches = 0
        
        for batch_idx, gt_meta in enumerate(dataloader):
            if batch_idx >= 10:  # åªè®­ç»ƒ10ä¸ªbatchä½œä¸ºéªŒè¯
                break
            
            try:
                # å‰å‘ä¼ æ’­
                head_out, loss, loss_states = model.forward_train(gt_meta)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                optimizer.backward(loss)
                optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                logger.info(f"Batch {batch_idx}: loss = {loss.item():.4f}")
                
                # æ‰“å°è¯¦ç»†æŸå¤±
                if loss_states:
                    for key, value in loss_states.items():
                        if hasattr(value, 'item'):
                            logger.info(f"  {key}: {value.item():.4f}")
                
            except Exception as e:
                logger.warning(f"è®­ç»ƒbatch {batch_idx}å¤±è´¥: {e}")
                continue
        
        avg_loss = epoch_loss / max(num_batches, 1)
        logger.info(f"è®­ç»ƒå®Œæˆ: å¹³å‡æŸå¤± = {avg_loss:.4f}")
        
        # æµ‹è¯•æ¨ç†
        logger.info("æµ‹è¯•æ¨ç†...")
        model.eval()
        test_images = jt.randn(2, 3, 320, 320)
        with jt.no_grad():
            outputs = model(test_images)
        logger.info(f"æ¨ç†æˆåŠŸ: {outputs.shape}")
        
        logger.info("ğŸ‰ çœŸå®VOCæ•°æ®è®­ç»ƒéªŒè¯æˆåŠŸï¼")
        logger.info("âœ… è¯æ˜Jittorç‰ˆæœ¬å¯ä»¥åœ¨çœŸå®æ•°æ®ä¸Šæ­£å¸¸è®­ç»ƒï¼")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ çœŸå®VOCæ•°æ®è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logging()
    logger.info("å¼€å§‹çœŸå®VOCæ•°æ®è®­ç»ƒéªŒè¯ï¼ˆæ— é¢„è®­ç»ƒæƒé‡ï¼‰...")
    
    success = real_voc_training()
    
    if success:
        logger.info("ğŸ‰ çœŸå®VOCæ•°æ®è®­ç»ƒéªŒè¯æˆåŠŸï¼")
        return True
    else:
        logger.error("âŒ çœŸå®VOCæ•°æ®è®­ç»ƒéªŒè¯å¤±è´¥ï¼")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
