#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•é¢„è®­ç»ƒæƒé‡æ¨ç†
éªŒè¯Jittorç‰ˆæœ¬èƒ½å¦ç›´æ¥ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡è¿›è¡Œæ¨ç†
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from nanodet.model import build_model


def create_model():
    """åˆ›å»ºNanoDetæ¨¡å‹"""
    model_cfg = {
        'name': 'NanoDetPlus',
        'backbone': {
            'name': 'ShuffleNetV2',
            'model_size': '1.0x',
            'out_stages': [2, 3, 4],
            'activation': 'LeakyReLU',
            'pretrain': True  # åŠ è½½ImageNeté¢„è®­ç»ƒæƒé‡
        },
        'fpn': {
            'name': 'GhostPAN',
            'in_channels': [116, 232, 464],
            'out_channels': 96,
            'kernel_size': 5,
            'num_extra_level': 1,
            'use_depthwise': True,
            'activation': 'LeakyReLU'
        },
        'aux_head': {
            'name': 'SimpleConvHead',
            'num_classes': 20,
            'input_channel': 192,
            'feat_channels': 192,
            'stacked_convs': 4,
            'strides': [8, 16, 32, 64],
            'activation': 'LeakyReLU',
            'reg_max': 7
        },
        'head': {
            'name': 'NanoDetPlusHead',
            'num_classes': 20,
            'input_channel': 96,
            'feat_channels': 96,
            'stacked_convs': 2,
            'kernel_size': 5,
            'strides': [8, 16, 32, 64],
            'conv_type': 'DWConv',
            'norm_cfg': dict(type='BN'),
            'reg_max': 7,
            'activation': 'LeakyReLU',
            'loss': {
                'loss_qfl': {'beta': 2.0, 'loss_weight': 1.0},
                'loss_dfl': {'loss_weight': 0.25},
                'loss_bbox': {'loss_weight': 2.0}
            }
        },
        'detach_epoch': 10
    }
    
    return build_model(model_cfg)


def preprocess_image(img_path, input_size=(320, 320)):
    """é¢„å¤„ç†çœŸå®å›¾åƒ"""
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"Cannot load image: {img_path}")

    # è°ƒæ•´å¤§å°
    img = cv2.resize(img, input_size)

    # å½’ä¸€åŒ– (ImageNetæ ‡å‡†)
    mean = np.array([103.53, 116.28, 123.675])
    std = np.array([57.375, 57.12, 58.395])

    img = img.astype(np.float32)
    img -= mean
    img /= std

    # è½¬æ¢ä¸ºCHWæ ¼å¼
    img = img.transpose(2, 0, 1)

    # æ·»åŠ batchç»´åº¦
    img = np.expand_dims(img, axis=0)

    return jt.array(img)


def test_pretrained_inference():
    """æµ‹è¯•é¢„è®­ç»ƒæƒé‡æ¨ç†"""
    print("=" * 60)
    print("æµ‹è¯•é¢„è®­ç»ƒæƒé‡æ¨ç†")
    print("=" * 60)
    
    # è®¾ç½®CUDA
    if jt.has_cuda:
        jt.flags.use_cuda = 1
        print("âœ“ Using CUDA")
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = create_model()
    model.eval()
    
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"  å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
    test_input = jt.randn(1, 3, 320, 320)
    
    with jt.no_grad():
        try:
            output = model(test_input)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"  è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"  è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
            if output.shape[0] == 1 and output.shape[1] > 1000:  # åº”è¯¥æœ‰å¾ˆå¤šanchorç‚¹
                print("âœ“ è¾“å‡ºå½¢çŠ¶åˆç†")
            else:
                print("âš  è¾“å‡ºå½¢çŠ¶å¯èƒ½ä¸æ­£ç¡®")
                
        except Exception as e:
            print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False
    
    # æµ‹è¯•çœŸå®VOCå›¾åƒ
    test_images = [
        "data/VOCdevkit/VOC2007/JPEGImages/000001.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000002.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000003.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000004.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000005.jpg"
    ]

    successful_tests = 0
    for img_path in test_images:
        if os.path.exists(img_path):
            print(f"\næµ‹è¯•çœŸå®VOCå›¾åƒ: {img_path}")
            try:
                img_tensor = preprocess_image(img_path)
                with jt.no_grad():
                    output = model(img_tensor)
                print(f"âœ“ å›¾åƒæ¨ç†æˆåŠŸ: {output.shape}")
                print(f"  è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
                successful_tests += 1
            except Exception as e:
                print(f"âš  å›¾åƒæ¨ç†å¤±è´¥: {e}")
        else:
            print(f"âš  å›¾åƒä¸å­˜åœ¨: {img_path}")

    print(f"\nâœ“ æˆåŠŸæµ‹è¯•äº† {successful_tests}/{len(test_images)} å¼ çœŸå®å›¾åƒ")
    
    print("\n" + "=" * 60)
    print("é¢„è®­ç»ƒæƒé‡æ¨ç†æµ‹è¯•å®Œæˆ")
    print("=" * 60)
    
    return True


def compare_with_pytorch():
    """ä¸PyTorchç‰ˆæœ¬å¯¹æ¯”ï¼ˆå¦‚æœå¯èƒ½ï¼‰"""
    print("\n" + "=" * 40)
    print("ä¸PyTorchç‰ˆæœ¬å¯¹æ¯”")
    print("=" * 40)
    
    try:
        # å°è¯•åŠ è½½PyTorchç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”
        import torch
        sys.path.insert(0, '../nanodet-pytorch')
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ PyTorchç‰ˆæœ¬çš„å¯¹æ¯”ä»£ç 
        print("âš  PyTorchå¯¹æ¯”åŠŸèƒ½å¾…å®ç°")
        
    except Exception as e:
        print(f"âš  æ— æ³•è¿›è¡ŒPyTorchå¯¹æ¯”: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("Jittor NanoDet é¢„è®­ç»ƒæƒé‡æ¨ç†æµ‹è¯•")
    
    # æµ‹è¯•é¢„è®­ç»ƒæ¨ç†
    success = test_pretrained_inference()
    
    if success:
        print("\nğŸ‰ é¢„è®­ç»ƒæƒé‡æ¨ç†æµ‹è¯•æˆåŠŸï¼")
        print("âœ“ æ¨¡å‹æ¶æ„æ­£ç¡®")
        print("âœ“ ImageNeté¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸ")
        print("âœ“ å‰å‘ä¼ æ’­æ­£å¸¸")
    else:
        print("\nâŒ é¢„è®­ç»ƒæƒé‡æ¨ç†æµ‹è¯•å¤±è´¥")
        return False
    
    # å¯¹æ¯”æµ‹è¯•
    compare_with_pytorch()
    
    return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
