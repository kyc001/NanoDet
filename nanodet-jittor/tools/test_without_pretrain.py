#!/usr/bin/env python3
"""
æµ‹è¯•ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡çš„æ¨¡å‹æ„å»º
éªŒè¯æ˜¯å¦æ˜¯é¢„è®­ç»ƒæƒé‡åŠ è½½å¯¼è‡´çš„æ®µé”™è¯¯
"""

import os
import sys
import logging
import jittor as jt
from pathlib import Path
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def test_backbone_without_pretrain():
    """æµ‹è¯•ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡çš„Backbone"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡çš„Backbone")
    logger.info("=" * 50)
    
    try:
        from nanodet.model.backbone import build_backbone
        
        # ç¦ç”¨é¢„è®­ç»ƒæƒé‡
        backbone_cfg = {
            'name': 'ShuffleNetV2',
            'model_size': '1.0x',
            'out_stages': [2, 3, 4],
            'activation': 'LeakyReLU',
            'pretrain': False  # å…³é”®ï¼šç¦ç”¨é¢„è®­ç»ƒ
        }
        
        logger.info(f"æ„å»ºBackboneï¼ˆæ— é¢„è®­ç»ƒï¼‰: {backbone_cfg}")
        backbone = build_backbone(backbone_cfg)
        logger.info("âœ… Backboneæ„å»ºæˆåŠŸï¼ˆæ— é¢„è®­ç»ƒï¼‰")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = jt.randn(1, 3, 320, 320)
        outputs = backbone(x)
        logger.info(f"å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡º: {[out.shape for out in outputs]}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Backboneæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_full_model_without_pretrain():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹ï¼ˆæ— é¢„è®­ç»ƒï¼‰"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•å®Œæ•´æ¨¡å‹ï¼ˆæ— é¢„è®­ç»ƒï¼‰")
    logger.info("=" * 50)
    
    try:
        from nanodet.model import build_model
        
        # æ‰‹åŠ¨æ„å»ºé…ç½®ï¼Œç¦ç”¨é¢„è®­ç»ƒ
        model_cfg = {
            'name': 'NanoDetPlus',
            'backbone': {
                'name': 'ShuffleNetV2',
                'model_size': '1.0x',
                'out_stages': [2, 3, 4],
                'activation': 'LeakyReLU',
                'pretrain': False  # å…³é”®ï¼šç¦ç”¨é¢„è®­ç»ƒ
            },
            'fpn': {
                'name': 'GhostPAN',
                'in_channels': [116, 232, 464],
                'out_channels': 96,
                'kernel_size': 5,
                'num_extra_level': 1,
                'use_depthwise': True,
                'activation': 'LeakyReLU'
            },
            'head': {
                'name': 'NanoDetPlusHead',
                'num_classes': 20,
                'input_channel': 96,
                'feat_channels': 96,
                'stacked_convs': 2,
                'kernel_size': 5,
                'strides': [8, 16, 32, 64],
                'activation': 'LeakyReLU',
                'reg_max': 7,
                'norm_cfg': {'type': 'BN'},
                'loss': {
                    'loss_qfl': {
                        'name': 'QualityFocalLoss',
                        'use_sigmoid': True,
                        'beta': 2.0,
                        'loss_weight': 1.0
                    },
                    'loss_dfl': {
                        'name': 'DistributionFocalLoss',
                        'loss_weight': 0.25
                    },
                    'loss_bbox': {
                        'name': 'GIoULoss',
                        'loss_weight': 2.0
                    }
                }
            },
            'aux_head': {
                'name': 'SimpleConvHead',
                'num_classes': 20,
                'input_channel': 192,
                'feat_channels': 192,
                'stacked_convs': 4,
                'strides': [8, 16, 32, 64],
                'activation': 'LeakyReLU',
                'norm_cfg': {'type': 'BN'}
            },
            'detach_epoch': 10
        }
        
        logger.info("æ„å»ºå®Œæ•´æ¨¡å‹ï¼ˆæ— é¢„è®­ç»ƒï¼‰...")
        model = build_model(model_cfg)
        logger.info("âœ… å®Œæ•´æ¨¡å‹æ„å»ºæˆåŠŸï¼ˆæ— é¢„è®­ç»ƒï¼‰")
        
        # æµ‹è¯•æ¨ç†
        x = jt.randn(1, 3, 320, 320)
        model.eval()
        with jt.no_grad():
            outputs = model(x)
        logger.info(f"æ¨ç†æˆåŠŸï¼Œè¾“å‡º: {outputs.shape}")
        
        return model
        
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return None

def test_config_file_without_pretrain():
    """æµ‹è¯•ä¿®æ”¹é…ç½®æ–‡ä»¶ç¦ç”¨é¢„è®­ç»ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•é…ç½®æ–‡ä»¶ï¼ˆç¦ç”¨é¢„è®­ç»ƒï¼‰")
    logger.info("=" * 50)
    
    try:
        from nanodet.util.config import load_config
        from nanodet.model import build_model
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = project_root / "config" / "nanodet-plus-m_320_voc.yml"
        cfg = load_config(str(config_path))
        logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # ä¿®æ”¹é…ç½®ï¼Œç¦ç”¨é¢„è®­ç»ƒ
        cfg.model.arch.backbone.pretrain = False
        logger.info("ä¿®æ”¹é…ç½®ï¼šç¦ç”¨é¢„è®­ç»ƒæƒé‡")
        
        # æ„å»ºæ¨¡å‹
        logger.info("æ„å»ºæ¨¡å‹ï¼ˆé…ç½®æ–‡ä»¶ï¼Œæ— é¢„è®­ç»ƒï¼‰...")
        model = build_model(cfg.model)
        logger.info("âœ… é…ç½®æ–‡ä»¶æ¨¡å‹æ„å»ºæˆåŠŸï¼ˆæ— é¢„è®­ç»ƒï¼‰")
        
        # æµ‹è¯•æ¨ç†
        x = jt.randn(1, 3, 320, 320)
        model.eval()
        with jt.no_grad():
            outputs = model(x)
        logger.info(f"æ¨ç†æˆåŠŸï¼Œè¾“å‡º: {outputs.shape}")
        
        return model
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return None

def test_training_without_pretrain():
    """æµ‹è¯•è®­ç»ƒï¼ˆæ— é¢„è®­ç»ƒï¼‰"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•è®­ç»ƒï¼ˆæ— é¢„è®­ç»ƒï¼‰")
    logger.info("=" * 50)
    
    try:
        # ä½¿ç”¨æ‰‹åŠ¨æ„å»ºçš„æ¨¡å‹
        model = test_full_model_without_pretrain()
        if model is None:
            return False
        
        model.train()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        batch_size = 4
        images = jt.randn(batch_size, 3, 320, 320)
        gt_meta = {
            'img': images,
            'gt_bboxes': [jt.randn(3, 4) * 100 + 50 for _ in range(batch_size)],
            'gt_labels': [jt.randint(0, 20, (3,)) for _ in range(batch_size)],
            'img_info': [
                {'height': 320, 'width': 320, 'id': i} for i in range(batch_size)
            ]
        }
        
        # è®­ç»ƒå‡ ä¸ªæ­¥éª¤
        logger.info("å¼€å§‹è®­ç»ƒæµ‹è¯•...")
        for step in range(3):
            # å‰å‘ä¼ æ’­
            head_out, loss, loss_states = model.forward_train(gt_meta)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            optimizer.backward(loss)
            optimizer.step()
            
            logger.info(f"Step {step + 1}: loss = {loss.item():.4f}")
            
            if loss_states:
                for key, value in loss_states.items():
                    if hasattr(value, 'item'):
                        logger.info(f"  {key}: {value.item():.4f}")
        
        logger.info("âœ… è®­ç»ƒæµ‹è¯•æˆåŠŸï¼ˆæ— é¢„è®­ç»ƒï¼‰")
        return True
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    # å¼ºåˆ¶CPUæ¨¡å¼
    jt.flags.use_cuda = 0
    
    logger = setup_logging()
    logger.info("å¼€å§‹æµ‹è¯•æ— é¢„è®­ç»ƒæƒé‡çš„æ¨¡å‹...")
    
    # æµ‹è¯•1: Backbone
    backbone_ok = test_backbone_without_pretrain()
    if not backbone_ok:
        logger.error("Backboneæµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•2: å®Œæ•´æ¨¡å‹
    model_ok = test_full_model_without_pretrain()
    if model_ok is None:
        logger.error("å®Œæ•´æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•3: é…ç½®æ–‡ä»¶æ¨¡å‹
    config_model_ok = test_config_file_without_pretrain()
    if config_model_ok is None:
        logger.error("é…ç½®æ–‡ä»¶æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•4: è®­ç»ƒ
    training_ok = test_training_without_pretrain()
    if not training_ok:
        logger.error("è®­ç»ƒæµ‹è¯•å¤±è´¥")
        return False
    
    logger.info("ğŸ‰ æ‰€æœ‰æ— é¢„è®­ç»ƒæµ‹è¯•é€šè¿‡ï¼")
    logger.info("âœ… ç¡®è®¤é—®é¢˜å‡ºåœ¨é¢„è®­ç»ƒæƒé‡åŠ è½½ä¸Š")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
