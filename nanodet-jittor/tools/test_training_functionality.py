#!/usr/bin/env python3
"""
éªŒè¯NanoDetè®­ç»ƒåŠŸèƒ½
ä½¿ç”¨æ‰‹åŠ¨æ„å»ºçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒéªŒè¯
"""

import os
import sys
import logging
import jittor as jt
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def create_model():
    """åˆ›å»ºNanoDetPlusæ¨¡å‹"""
    from nanodet.model import build_model
    
    model_cfg = {
        'name': 'NanoDetPlus',
        'backbone': {
            'name': 'ShuffleNetV2',
            'model_size': '1.0x',
            'out_stages': [2, 3, 4],
            'activation': 'LeakyReLU',
            'pretrain': True
        },
        'fpn': {
            'name': 'GhostPAN',
            'in_channels': [116, 232, 464],
            'out_channels': 96,
            'kernel_size': 5,
            'num_extra_level': 1,
            'use_depthwise': True,
            'activation': 'LeakyReLU'
        },
        'head': {
            'name': 'NanoDetPlusHead',
            'num_classes': 20,
            'input_channel': 96,
            'feat_channels': 96,
            'stacked_convs': 2,
            'kernel_size': 5,
            'strides': [8, 16, 32, 64],
            'activation': 'LeakyReLU',
            'reg_max': 7,
            'norm_cfg': {'type': 'BN'},
            'loss': {
                'loss_qfl': {
                    'name': 'QualityFocalLoss',
                    'use_sigmoid': True,
                    'beta': 2.0,
                    'loss_weight': 1.0
                },
                'loss_dfl': {
                    'name': 'DistributionFocalLoss',
                    'loss_weight': 0.25
                },
                'loss_bbox': {
                    'name': 'GIoULoss',
                    'loss_weight': 2.0
                }
            }
        },
        'aux_head': {
            'name': 'SimpleConvHead',
            'num_classes': 20,
            'input_channel': 192,
            'feat_channels': 192,
            'stacked_convs': 4,
            'strides': [8, 16, 32, 64],
            'activation': 'LeakyReLU',
            'norm_cfg': {'type': 'BN'}
        },
        'detach_epoch': 10
    }
    
    return build_model(model_cfg)

def create_dummy_data(batch_size=2):
    """åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®"""
    # åˆ›å»ºå›¾åƒæ•°æ®
    images = jt.randn(batch_size, 3, 320, 320)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„GTæ•°æ®
    gt_meta = {
        'img': images,
        'gt_bboxes': [jt.randn(5, 4) * 100 + 50 for _ in range(batch_size)],  # 5ä¸ªbbox per image
        'gt_labels': [jt.randint(0, 20, (5,)) for _ in range(batch_size)],  # 5ä¸ªæ ‡ç­¾ per image
        'img_info': [
            {'height': 320, 'width': 320, 'id': i} for i in range(batch_size)
        ]
    }
    
    return gt_meta

def test_training_loop():
    """æµ‹è¯•è®­ç»ƒå¾ªç¯"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•è®­ç»ƒå¾ªç¯")
    logger.info("=" * 50)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        model = create_model()
        model.train()
        logger.info("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        logger.info("åˆ›å»ºä¼˜åŒ–å™¨...")
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)
        logger.info("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # è®­ç»ƒå¾ªç¯
        logger.info("å¼€å§‹è®­ç»ƒå¾ªç¯...")
        num_epochs = 3
        
        for epoch in range(num_epochs):
            logger.info(f"Epoch {epoch + 1}/{num_epochs}")
            
            # åˆ›å»ºä¸€ä¸ªbatchçš„æ•°æ®
            gt_meta = create_dummy_data(batch_size=2)
            
            start_time = time.time()
            
            # å‰å‘ä¼ æ’­
            head_out, loss, loss_states = model.forward_train(gt_meta)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            optimizer.backward(loss)
            optimizer.step()
            
            end_time = time.time()
            
            logger.info(f"  æŸå¤±: {loss.item():.4f}")
            logger.info(f"  æ—¶é—´: {end_time - start_time:.2f}s")
            
            # æ‰“å°è¯¦ç»†çš„æŸå¤±ä¿¡æ¯
            if loss_states:
                for key, value in loss_states.items():
                    if hasattr(value, 'item'):
                        logger.info(f"  {key}: {value.item():.4f}")
                    else:
                        logger.info(f"  {key}: {value}")
        
        logger.info("âœ… è®­ç»ƒå¾ªç¯æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¾ªç¯æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_inference():
    """æµ‹è¯•æ¨ç†åŠŸèƒ½"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•æ¨ç†åŠŸèƒ½")
    logger.info("=" * 50)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        model = create_model()
        model.eval()
        logger.info("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¨ç†
        logger.info("æµ‹è¯•æ¨ç†...")
        batch_size = 4
        images = jt.randn(batch_size, 3, 320, 320)
        
        start_time = time.time()
        
        with jt.no_grad():
            outputs = model(images)
        
        end_time = time.time()
        
        logger.info(f"è¾“å…¥: {images.shape}")
        logger.info(f"è¾“å‡º: {outputs.shape}")
        logger.info(f"æ¨ç†æ—¶é—´: {end_time - start_time:.2f}s")
        logger.info(f"å¹³å‡æ¯å¼ å›¾ç‰‡: {(end_time - start_time) / batch_size * 1000:.1f}ms")
        
        logger.info("âœ… æ¨ç†æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_model_save_load():
    """æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 50)
    logger.info("æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
    logger.info("=" * 50)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        model = create_model()
        logger.info("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # ä¿å­˜æ¨¡å‹
        save_path = project_root / "work_dirs" / "test_model.pkl"
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ä¿å­˜æ¨¡å‹åˆ°: {save_path}")
        jt.save(model.state_dict(), str(save_path))
        logger.info("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
        
        # åˆ›å»ºæ–°æ¨¡å‹å¹¶åŠ è½½æƒé‡
        logger.info("åˆ›å»ºæ–°æ¨¡å‹å¹¶åŠ è½½æƒé‡...")
        new_model = create_model()
        state_dict = jt.load(str(save_path))
        new_model.load_state_dict(state_dict)
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # éªŒè¯åŠ è½½çš„æ¨¡å‹
        logger.info("éªŒè¯åŠ è½½çš„æ¨¡å‹...")
        new_model.eval()
        images = jt.randn(1, 3, 320, 320)
        
        with jt.no_grad():
            outputs = new_model(images)
        
        logger.info(f"åŠ è½½æ¨¡å‹è¾“å‡º: {outputs.shape}")
        logger.info("âœ… æ¨¡å‹ä¿å­˜åŠ è½½æµ‹è¯•æˆåŠŸ")
        
        # æ¸…ç†æ–‡ä»¶
        save_path.unlink()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹ä¿å­˜åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    # å¼ºåˆ¶ä½¿ç”¨CPU
    jt.flags.use_cuda = 0
    
    logger = setup_logging()
    logger.info("å¼€å§‹NanoDetè®­ç»ƒåŠŸèƒ½éªŒè¯...")
    logger.info(f"Jittor CUDA available: {jt.has_cuda}")
    logger.info(f"Jittor using CUDA: {jt.flags.use_cuda}")
    
    # æµ‹è¯•æ¨ç†åŠŸèƒ½
    inference_success = test_inference()
    if not inference_success:
        logger.error("âŒ æ¨ç†æµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•è®­ç»ƒå¾ªç¯
    training_success = test_training_loop()
    if not training_success:
        logger.error("âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•æ¨¡å‹ä¿å­˜åŠ è½½
    save_load_success = test_model_save_load()
    if not save_load_success:
        logger.error("âŒ æ¨¡å‹ä¿å­˜åŠ è½½æµ‹è¯•å¤±è´¥")
        return False
    
    logger.info("ğŸ‰ æ‰€æœ‰è®­ç»ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    logger.info("âœ… NanoDet Jittorç‰ˆæœ¬æ ¸å¿ƒåŠŸèƒ½éªŒè¯æˆåŠŸï¼")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
