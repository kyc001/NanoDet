#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éªŒè¯100%å‚æ•°å¯¹é½
æ’é™¤BatchNormç»Ÿè®¡å‚æ•°ï¼Œåªç»Ÿè®¡å¯è®­ç»ƒå‚æ•°
"""

import json
import sys
from collections import defaultdict

# æ·»åŠ è·¯å¾„
sys.path.append('/home/kyc/project/nanodet/nanodet-jittor')
from nanodet.model.arch.nanodet_plus import NanoDetPlus


def load_pytorch_record():
    """åŠ è½½PyTorchå‚è€ƒè®°å½•"""
    try:
        with open('pytorch_reference_record.json', 'r') as f:
            record = json.load(f)
        return record
    except FileNotFoundError:
        print("âŒ PyTorchå‚è€ƒè®°å½•æ–‡ä»¶ä¸å­˜åœ¨")
        return None


def create_jittor_model():
    """åˆ›å»ºJittoræ¨¡å‹"""
    print("åˆ›å»ºJittoræ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®å­—å…¸ - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    backbone_cfg = {
        'name': 'ShuffleNetV2',
        'model_size': '1.0x',
        'out_stages': [2, 3, 4],
        'activation': 'LeakyReLU',
        'pretrain': True
    }
    
    fpn_cfg = {
        'name': 'GhostPAN',
        'in_channels': [116, 232, 464],
        'out_channels': 96,
        'kernel_size': 5,
        'num_extra_level': 1,
        'use_depthwise': True,
        'activation': 'LeakyReLU'
    }
    
    head_cfg = {
        'name': 'NanoDetPlusHead',
        'num_classes': 20,
        'input_channel': 96,
        'feat_channels': 96,
        'stacked_convs': 2,
        'kernel_size': 5,
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7,
        'norm_cfg': {'type': 'BN'},
        'loss': {
            'loss_qfl': {
                'name': 'QualityFocalLoss',
                'use_sigmoid': True,
                'beta': 2.0,
                'loss_weight': 1.0
            },
            'loss_dfl': {
                'name': 'DistributionFocalLoss',
                'loss_weight': 0.25
            },
            'loss_bbox': {
                'name': 'GIoULoss',
                'loss_weight': 2.0
            }
        }
    }
    
    # åˆ›å»ºaux_headé…ç½® - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬
    aux_head_cfg = {
        'name': 'SimpleConvHead',
        'num_classes': 20,
        'input_channel': 192,
        'feat_channels': 192,  # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'stacked_convs': 4,    # ä¸PyTorchç‰ˆæœ¬ä¸€è‡´
        'strides': [8, 16, 32, 64],
        'activation': 'LeakyReLU',
        'reg_max': 7
    }
    
    # åˆ›å»ºå®Œæ•´æ¨¡å‹
    model = NanoDetPlus(backbone_cfg, fpn_cfg, aux_head_cfg, head_cfg)
    
    return model


def filter_trainable_parameters(params_dict):
    """è¿‡æ»¤å‡ºå¯è®­ç»ƒå‚æ•°ï¼Œæ’é™¤BatchNormç»Ÿè®¡å‚æ•°"""
    filtered_params = {}
    
    for name, details in params_dict.items():
        # æ’é™¤BatchNormçš„ç»Ÿè®¡å‚æ•°
        if 'running_mean' in name or 'running_var' in name or 'num_batches_tracked' in name:
            continue
        
        # åªä¿ç•™å¯è®­ç»ƒå‚æ•°
        if 'requires_grad' in details:
            if details['requires_grad']:
                filtered_params[name] = details
        else:
            # å¯¹äºJittorï¼Œé»˜è®¤éƒ½æ˜¯å¯è®­ç»ƒçš„
            filtered_params[name] = details
    
    return filtered_params


def verify_100_percent_alignment():
    """éªŒè¯100%å‚æ•°å¯¹é½"""
    print("ğŸ” éªŒè¯100%å‚æ•°å¯¹é½")
    print("=" * 80)
    
    # åŠ è½½PyTorchè®°å½•
    pytorch_record = load_pytorch_record()
    if not pytorch_record:
        return False
    
    pytorch_params = pytorch_record['model_params']
    
    # è¿‡æ»¤PyTorchå¯è®­ç»ƒå‚æ•°
    pytorch_trainable = filter_trainable_parameters(pytorch_params)
    
    # ç»Ÿè®¡PyTorchå¯è®­ç»ƒå‚æ•°
    pytorch_total = sum(details['count'] for details in pytorch_trainable.values())
    pytorch_modules = defaultdict(int)
    
    for name, details in pytorch_trainable.items():
        count = details['count']
        module = name.split('.')[0]
        pytorch_modules[module] += count
    
    print(f"âœ“ PyTorchå¯è®­ç»ƒå‚æ•°: {pytorch_total:,} å‚æ•°, {len(pytorch_trainable)} é¡¹")
    
    # åˆ›å»ºJittoræ¨¡å‹
    jittor_model = create_jittor_model()
    
    # ç»Ÿè®¡Jittorå¯è®­ç»ƒå‚æ•°
    jittor_params = {}
    jittor_total = 0
    jittor_modules = defaultdict(int)
    
    for name, param in jittor_model.named_parameters():
        # æ’é™¤BatchNormç»Ÿè®¡å‚æ•°
        if 'running_mean' in name or 'running_var' in name or 'num_batches_tracked' in name:
            continue
        
        count = param.numel() if hasattr(param, 'numel') else param.size
        jittor_params[name] = {
            'shape': list(param.shape),
            'count': count
        }
        jittor_total += count
        
        module = name.split('.')[0]
        jittor_modules[module] += count
    
    print(f"âœ“ Jittorå¯è®­ç»ƒå‚æ•°: {jittor_total:,} å‚æ•°, {len(jittor_params)} é¡¹")
    
    # è®¡ç®—å·®å¼‚
    difference = abs(pytorch_total - jittor_total)
    print(f"\nğŸ“Š å¯è®­ç»ƒå‚æ•°å·®å¼‚: {difference:,} ({difference/pytorch_total*100:.6f}%)")
    
    if difference == 0:
        print("ğŸ‰ å¯è®­ç»ƒå‚æ•°100%å¯¹é½ï¼")
        
        # è¿›ä¸€æ­¥éªŒè¯å‚æ•°åå’Œå½¢çŠ¶
        print(f"\nğŸ” éªŒè¯å‚æ•°åå’Œå½¢çŠ¶å¯¹é½:")
        
        pytorch_names = set(pytorch_trainable.keys())
        jittor_names = set(jittor_params.keys())
        
        common = pytorch_names & jittor_names
        only_pytorch = pytorch_names - jittor_names
        only_jittor = jittor_names - pytorch_names
        
        print(f"  å…±åŒå‚æ•°: {len(common)}")
        print(f"  åªåœ¨PyTorchä¸­: {len(only_pytorch)}")
        print(f"  åªåœ¨Jittorä¸­: {len(only_jittor)}")
        
        if len(only_pytorch) == 0 and len(only_jittor) == 0:
            print("âœ… å‚æ•°å100%å¯¹é½ï¼")
            
            # æ£€æŸ¥å½¢çŠ¶å¯¹é½
            shape_mismatches = 0
            for name in common:
                pytorch_shape = pytorch_trainable[name]['shape']
                jittor_shape = jittor_params[name]['shape']
                if pytorch_shape != jittor_shape:
                    shape_mismatches += 1
                    print(f"âŒ å½¢çŠ¶ä¸åŒ¹é…: {name}")
                    print(f"   PyTorch: {pytorch_shape}")
                    print(f"   Jittor: {jittor_shape}")
            
            if shape_mismatches == 0:
                print("âœ… å‚æ•°å½¢çŠ¶100%å¯¹é½ï¼")
                print("\nğŸ‰ æ­å–œï¼å®ç°äº†100%å®Œç¾å¯¹é½ï¼")
                return True
            else:
                print(f"âŒ æœ‰ {shape_mismatches} ä¸ªå‚æ•°å½¢çŠ¶ä¸åŒ¹é…")
        else:
            if only_pytorch:
                print(f"\n  åªåœ¨PyTorchä¸­çš„å‚æ•°:")
                for name in sorted(only_pytorch)[:10]:
                    details = pytorch_trainable[name]
                    print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
            
            if only_jittor:
                print(f"\n  åªåœ¨Jittorä¸­çš„å‚æ•°:")
                for name in sorted(only_jittor)[:10]:
                    details = jittor_params[name]
                    print(f"    {name}: {details['shape']} ({details['count']} å‚æ•°)")
        
        return False
    
    # å¦‚æœè¿˜æœ‰å·®å¼‚ï¼Œç»§ç»­åˆ†æ
    print(f"\nğŸ“Š æŒ‰æ¨¡å—å¯¹æ¯”å¯è®­ç»ƒå‚æ•°:")
    print(f"{'æ¨¡å—':<20} {'PyTorch':<12} {'Jittor':<12} {'å·®å¼‚':<12}")
    print("-" * 60)
    
    all_modules = set(pytorch_modules.keys()) | set(jittor_modules.keys())
    
    for module in sorted(all_modules):
        pytorch_count = pytorch_modules.get(module, 0)
        jittor_count = jittor_modules.get(module, 0)
        diff = pytorch_count - jittor_count
        
        status = "âœ…" if diff == 0 else "âŒ"
        print(f"{module:<20} {pytorch_count:<12,} {jittor_count:<12,} {diff:<12,} {status}")
    
    print("-" * 60)
    print(f"{'æ€»è®¡':<20} {pytorch_total:<12,} {jittor_total:<12,} {pytorch_total-jittor_total:<12,}")
    
    return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹éªŒè¯100%å‚æ•°å¯¹é½")
    print("ç›®æ ‡: å¯è®­ç»ƒå‚æ•°100%å¯¹é½ï¼Œä¸å…è®¸ä»»ä½•å·®å¼‚")
    
    success = verify_100_percent_alignment()
    
    if success:
        print("\nâœ… 100%å‚æ•°å¯¹é½éªŒè¯æˆåŠŸï¼")
        print("ğŸ‰ æ¨¡å‹ç»“æ„å®Œå…¨æ­£ç¡®ï¼Œå¯ä»¥è¿›è¡Œæœ€ç»ˆmAPæµ‹è¯•ï¼")
    else:
        print("\nâŒ ä»æœ‰å‚æ•°å·®å¼‚ï¼Œéœ€è¦ç»§ç»­ä¿®å¤")
    
    return success


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
