#!/usr/bin/env python3
"""
ğŸ” æ£€æŸ¥æ¨¡å‹å‚æ•°æ•°é‡å’Œå†…å­˜ä½¿ç”¨
"""

import sys
sys.path.insert(0, '.')

import jittor as jt
from nanodet.util import cfg, load_config
from nanodet.model.arch import build_model

def count_parameters(model):
    """ç»Ÿè®¡æ¨¡å‹å‚æ•°æ•°é‡"""
    total_params = 0
    trainable_params = 0
    
    for name, param in model.named_parameters():
        param_count = param.numel()
        total_params += param_count
        if param.requires_grad:
            trainable_params += param_count
        
        # æ˜¾ç¤ºå¤§å‚æ•°å±‚
        if param_count > 100000:  # è¶…è¿‡10ä¸‡å‚æ•°çš„å±‚
            print(f"å¤§å‚æ•°å±‚: {name} - {param_count:,} å‚æ•°, å½¢çŠ¶: {param.shape}")
    
    return total_params, trainable_params

def analyze_depthwise_modules(model):
    """åˆ†æ DepthwiseConvModule çš„å‚æ•°ä½¿ç”¨"""
    depthwise_count = 0
    depthwise_params = 0
    
    def count_depthwise(module, prefix=""):
        nonlocal depthwise_count, depthwise_params
        
        for name, child in module.named_children():
            full_name = f"{prefix}.{name}" if prefix else name
            
            if "DepthwiseConvModule" in str(type(child)):
                depthwise_count += 1
                module_params = sum(p.numel() for p in child.parameters())
                depthwise_params += module_params
                
                print(f"DepthwiseConvModule #{depthwise_count}: {full_name}")
                print(f"  å‚æ•°æ•°é‡: {module_params:,}")
                
                # æ£€æŸ¥ depthwise_convs
                if hasattr(child, 'depthwise_convs'):
                    conv_count = len(child.depthwise_convs)
                    conv_params = sum(sum(p.numel() for p in conv.parameters()) 
                                    for conv in child.depthwise_convs)
                    print(f"  ç‹¬ç«‹å·ç§¯æ•°é‡: {conv_count}")
                    print(f"  ç‹¬ç«‹å·ç§¯å‚æ•°: {conv_params:,}")
                
                print()
            else:
                count_depthwise(child, full_name)
    
    count_depthwise(model)
    return depthwise_count, depthwise_params

def main():
    print("ğŸ” å¼€å§‹æ£€æŸ¥æ¨¡å‹å¤§å°å’Œå†…å­˜ä½¿ç”¨...")
    
    # è®¾ç½® Jittor
    jt.flags.use_cuda = 1 if jt.has_cuda else 0
    
    # åŠ è½½é…ç½®
    load_config(cfg, 'config/nanodet-plus-m_320_voc_bs64_50epochs.yml')
    print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ” åˆ›å»ºæ¨¡å‹...")
    model = build_model(cfg.model)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # ç»Ÿè®¡æ€»å‚æ•°
    print("\nğŸ” ç»Ÿè®¡æ¨¡å‹å‚æ•°...")
    total_params, trainable_params = count_parameters(model)
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  å‚æ•°å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")
    
    # åˆ†æ DepthwiseConvModule
    print("\nğŸ” åˆ†æ DepthwiseConvModule...")
    dw_count, dw_params = analyze_depthwise_modules(model)
    
    print(f"ğŸ“Š DepthwiseConvModule ç»Ÿè®¡:")
    print(f"  æ¨¡å—æ•°é‡: {dw_count}")
    print(f"  æ€»å‚æ•°æ•°é‡: {dw_params:,}")
    print(f"  å æ€»å‚æ•°æ¯”ä¾‹: {dw_params/total_params*100:.1f}%")
    
    # ä¼°ç®—å†…å­˜ä½¿ç”¨
    print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨ä¼°ç®—:")
    
    # å‚æ•°å†…å­˜
    param_memory = total_params * 4 / 1024 / 1024  # MB
    print(f"  å‚æ•°å†…å­˜: {param_memory:.2f} MB")
    
    # æ¢¯åº¦å†…å­˜ï¼ˆä¸å‚æ•°ç›¸åŒï¼‰
    grad_memory = param_memory
    print(f"  æ¢¯åº¦å†…å­˜: {grad_memory:.2f} MB")
    
    # ä¼˜åŒ–å™¨çŠ¶æ€å†…å­˜ï¼ˆAdamW éœ€è¦ 2x å‚æ•°å†…å­˜ï¼‰
    optimizer_memory = param_memory * 2
    print(f"  ä¼˜åŒ–å™¨å†…å­˜: {optimizer_memory:.2f} MB")
    
    # æ¿€æ´»å†…å­˜ï¼ˆä¼°ç®—ï¼‰
    batch_size = cfg.device.batchsize_per_gpu
    input_size = 320  # ä»é…ç½®ä¸­è·å–
    # ä¼°ç®—æ¿€æ´»å†…å­˜ï¼šbatch_size * channels * height * width * 4 bytes * å±‚æ•°
    activation_memory = batch_size * 96 * (input_size//8) * (input_size//8) * 4 * 20 / 1024 / 1024  # MB
    print(f"  æ¿€æ´»å†…å­˜ä¼°ç®—: {activation_memory:.2f} MB")
    
    total_memory = param_memory + grad_memory + optimizer_memory + activation_memory
    print(f"  æ€»å†…å­˜ä¼°ç®—: {total_memory:.2f} MB ({total_memory/1024:.2f} GB)")
    
    # æ£€æŸ¥æ˜¯å¦è¶…å‡º GPU å†…å­˜
    gpu_memory = 8000  # 8GB GPU
    if total_memory > gpu_memory:
        print(f"  âŒ ä¼°ç®—å†…å­˜ ({total_memory:.0f}MB) è¶…å‡º GPU å†…å­˜ ({gpu_memory}MB)!")
        print(f"  è¶…å‡º: {total_memory - gpu_memory:.0f}MB")
    else:
        print(f"  âœ… ä¼°ç®—å†…å­˜åœ¨ GPU å†…å­˜èŒƒå›´å†…")
    
    print("\nğŸ¯ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
