#!/usr/bin/env python3
"""
ğŸ” è¯¦ç»†åˆ†æå‚æ•°åˆ†å¸ƒï¼Œæ‰¾å‡ºä¸ PyTorch ç‰ˆæœ¬çš„å·®å¼‚
"""

import sys
sys.path.insert(0, '.')

import jittor as jt
from nanodet.util import cfg, load_config
from nanodet.model.arch import build_model

def compare_with_expected():
    """ä¸æœŸæœ›çš„å‚æ•°æ•°é‡å¯¹æ¯”"""
    print("ğŸ” å¼€å§‹è¯¦ç»†å‚æ•°åˆ†æ...")
    
    # åŠ è½½é…ç½®
    load_config(cfg, 'config/nanodet-plus-m_320_voc_bs64_50epochs.yml')
    
    # åˆ›å»ºæ¨¡å‹
    model = build_model(cfg.model)
    
    # ç»Ÿè®¡æ€»å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ“Š æ€»ä½“å‚æ•°ç»Ÿè®¡:")
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"å‚æ•°å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    # ä¸å®˜æ–¹å¯¹æ¯”
    official_params = 1170000  # 1.17M
    ratio = total_params / official_params
    print(f"\nğŸ” ä¸å®˜æ–¹ NanoDet-Plus-m å¯¹æ¯”:")
    print(f"å®˜æ–¹å‚æ•°æ•°é‡: {official_params:,}")
    print(f"æˆ‘ä»¬çš„å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å·®å¼‚å€æ•°: {ratio:.2f}x")
    print(f"å¤šå‡ºå‚æ•°: {total_params - official_params:,}")
    
    if ratio > 1.5:
        print("âŒ å‚æ•°æ•°é‡ä¸¥é‡è¶…æ ‡ï¼éœ€è¦æ£€æŸ¥å®ç°")
    elif ratio > 1.1:
        print("âš ï¸ å‚æ•°æ•°é‡åé«˜ï¼Œéœ€è¦ä¼˜åŒ–")
    else:
        print("âœ… å‚æ•°æ•°é‡åœ¨åˆç†èŒƒå›´å†…")
    
    # åˆ†æå„ä¸ªä¸»è¦æ¨¡å—
    backbone_params = sum(p.numel() for p in model.backbone.parameters())
    fpn_params = sum(p.numel() for p in model.fpn.parameters())
    head_params = sum(p.numel() for p in model.head.parameters())
    
    print(f"\nğŸ” ä¸»è¦æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
    print(f"backbone: {backbone_params:,} å‚æ•° ({backbone_params/total_params*100:.1f}%)")
    print(f"fpn: {fpn_params:,} å‚æ•° ({fpn_params/total_params*100:.1f}%)")
    print(f"head: {head_params:,} å‚æ•° ({head_params/total_params*100:.1f}%)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ aux_fpn å’Œ aux_head
    if hasattr(model, 'aux_fpn') and model.aux_fpn is not None:
        aux_fpn_params = sum(p.numel() for p in model.aux_fpn.parameters())
        print(f"aux_fpn: {aux_fpn_params:,} å‚æ•° ({aux_fpn_params/total_params*100:.1f}%)")
    
    if hasattr(model, 'aux_head') and model.aux_head is not None:
        aux_head_params = sum(p.numel() for p in model.aux_head.parameters())
        print(f"aux_head: {aux_head_params:,} å‚æ•° ({aux_head_params/total_params*100:.1f}%)")
    
    # åˆ†æ FPN ä¸­çš„ DepthwiseConvModule
    print(f"\nğŸ” DepthwiseConvModule åˆ†æ:")
    dw_count = 0
    dw_total_params = 0
    
    def count_dw_modules(module, prefix=""):
        nonlocal dw_count, dw_total_params
        for name, child in module.named_children():
            full_name = f"{prefix}.{name}" if prefix else name
            if "DepthwiseConvModule" in str(type(child)):
                dw_count += 1
                child_params = sum(p.numel() for p in child.parameters())
                dw_total_params += child_params
                print(f"  #{dw_count}: {full_name} - {child_params:,} å‚æ•°")
                
                # åˆ†æ DepthwiseConvModule å†…éƒ¨
                if hasattr(child, 'depthwise_weight'):
                    dw_weight_params = child.depthwise_weight.numel()
                    print(f"    depthwise_weight: {dw_weight_params:,} å‚æ•°")
                if hasattr(child, 'pointwise'):
                    pw_params = sum(p.numel() for p in child.pointwise.parameters())
                    print(f"    pointwise: {pw_params:,} å‚æ•°")
            else:
                count_dw_modules(child, full_name)
    
    count_dw_modules(model)
    print(f"\nDepthwiseConvModule æ€»è®¡: {dw_count} ä¸ªï¼Œ{dw_total_params:,} å‚æ•° ({dw_total_params/total_params*100:.1f}%)")

if __name__ == "__main__":
    compare_with_expected()
