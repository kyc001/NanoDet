#!/usr/bin/env python3
"""
ğŸ” Jittor åŸºç¡€åŠŸèƒ½æµ‹è¯•
éªŒè¯ loss å®šä¹‰å’Œä¼˜åŒ–å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.insert(0, '.')

import jittor as jt

def test_basic_functionality():
    print("ğŸ” æµ‹è¯• Jittor åŸºç¡€åŠŸèƒ½")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['DISABLE_MULTIPROCESSING'] = '1'
    
    # å¯ç”¨ CUDA
    jt.flags.use_cuda = 1 if jt.has_cuda else 0
    print(f"âœ… CUDA: {'å¯ç”¨' if jt.flags.use_cuda else 'ç¦ç”¨'}")
    
    try:
        print("\nğŸ§ª æµ‹è¯•1: ç®€å•çº¿æ€§æ¨¡å‹")
        
        # ç®€å•æ¨¡å‹å’Œæ•°æ®
        model = jt.nn.Linear(10, 2)
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01)
        x = jt.randn(2, 10)
        label = jt.array([0, 1])
        
        print(f"   æ¨¡å‹: Linear(10, 2)")
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"   æ ‡ç­¾å½¢çŠ¶: {label.shape}")

        # å‰å‘è®¡ç®—ä¸loss
        pred = model(x)
        loss = jt.nn.cross_entropy_loss(pred, label)

        print(f"   é¢„æµ‹å½¢çŠ¶: {pred.shape}")
        print(f"   Lossç±»å‹: {type(loss)}")
        print(f"   Losså½¢çŠ¶: {loss.shape}")
        
        # éªŒè¯ loss æ˜¯ Jittor Var ç±»å‹
        assert isinstance(loss, jt.Var), f"Loss ä¸æ˜¯ Jittor Var ç±»å‹: {type(loss)}"
        print("   âœ… Loss æ˜¯æ­£ç¡®çš„ Jittor Var ç±»å‹")
        
        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        optimizer.zero_grad()
        optimizer.step(loss)
        
        print("   âœ… åŸºç¡€è®­ç»ƒæ­¥éª¤æˆåŠŸï¼")
        
    except Exception as e:
        print(f"   âŒ åŸºç¡€æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    try:
        print("\nğŸ§ª æµ‹è¯•2: å¤æ‚ä¸€ç‚¹çš„æ¨¡å‹")
        
        # ç¨å¾®å¤æ‚çš„æ¨¡å‹
        model = jt.nn.Sequential(
            jt.nn.Linear(10, 20),
            jt.nn.ReLU(),
            jt.nn.Linear(20, 5),
            jt.nn.ReLU(),
            jt.nn.Linear(5, 2)
        )
        
        optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
        
        # å¤šä¸ªæ‰¹æ¬¡æµ‹è¯•
        for i in range(3):
            x = jt.randn(4, 10)  # æ‰¹æ¬¡å¤§å°ä¸º4
            label = jt.randint(0, 2, (4,))
            
            pred = model(x)
            loss = jt.nn.cross_entropy_loss(pred, label)
            
            optimizer.zero_grad()
            optimizer.step(loss)
            
            print(f"   æ‰¹æ¬¡ {i+1}: Losså½¢çŠ¶ {loss.shape}")
        
        print("   âœ… å¤æ‚æ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
        
    except Exception as e:
        print(f"   âŒ å¤æ‚æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

def test_nanodet_loss():
    print("\nğŸ§ª æµ‹è¯•3: NanoDet ç›¸å…³çš„ Loss è®¡ç®—")
    print("-" * 50)
    
    try:
        # æ¨¡æ‹Ÿ NanoDet çš„æŸå¤±è®¡ç®—
        from nanodet.util import cfg, load_config
        
        # åŠ è½½é…ç½®
        load_config(cfg, 'config/nanodet-plus-m_320_voc_bs64_50epochs.yml')
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„æŸå¤±æ•°æ®
        batch_size = 2
        num_classes = 20
        
        # æ¨¡æ‹Ÿåˆ†ç±»æŸå¤±
        pred_scores = jt.randn(batch_size, 1000, num_classes)  # æ¨¡æ‹Ÿé¢„æµ‹åˆ†æ•°
        labels = jt.randint(0, num_classes, (batch_size, 1000))  # æ¨¡æ‹Ÿæ ‡ç­¾
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss_cls = jt.nn.cross_entropy_loss(pred_scores.view(-1, num_classes), labels.view(-1))
        
        print(f"   åˆ†ç±»æŸå¤±å½¢çŠ¶: {loss_cls.shape}")
        print(f"   åˆ†ç±»æŸå¤±ç±»å‹: {type(loss_cls)}")
        
        # æ¨¡æ‹Ÿå›å½’æŸå¤±
        pred_bbox = jt.randn(batch_size, 1000, 4)  # æ¨¡æ‹Ÿè¾¹ç•Œæ¡†é¢„æµ‹
        target_bbox = jt.randn(batch_size, 1000, 4)  # æ¨¡æ‹Ÿç›®æ ‡è¾¹ç•Œæ¡†
        
        loss_bbox = jt.nn.mse_loss(pred_bbox, target_bbox)
        
        print(f"   å›å½’æŸå¤±å½¢çŠ¶: {loss_bbox.shape}")
        print(f"   å›å½’æŸå¤±ç±»å‹: {type(loss_bbox)}")
        
        # æ€»æŸå¤±
        total_loss = loss_cls + loss_bbox
        
        print(f"   æ€»æŸå¤±å½¢çŠ¶: {total_loss.shape}")
        print(f"   æ€»æŸå¤±ç±»å‹: {type(total_loss)}")
        
        # éªŒè¯æŸå¤±æ˜¯æ­£ç¡®çš„ Jittor Var ç±»å‹
        assert isinstance(total_loss, jt.Var), f"æ€»æŸå¤±ä¸æ˜¯ Jittor Var ç±»å‹: {type(total_loss)}"
        print("   âœ… NanoDet é£æ ¼çš„æŸå¤±è®¡ç®—æˆåŠŸï¼")
        
        return True
        
    except Exception as e:
        print(f"   âŒ NanoDet æŸå¤±æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ” Jittor åŸºç¡€åŠŸèƒ½éªŒè¯")
    print("æ ¹æ®é”™è¯¯åˆ†æï¼ŒéªŒè¯ loss å®šä¹‰æ˜¯å¦ç¬¦åˆ Jittor è§„èŒƒ")
    print("=" * 60)
    
    # æµ‹è¯•åŸºç¡€åŠŸèƒ½
    basic_ok = test_basic_functionality()
    
    if basic_ok:
        print("\nâœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        
        # æµ‹è¯• NanoDet ç›¸å…³åŠŸèƒ½
        nanodet_ok = test_nanodet_loss()
        
        if nanodet_ok:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("âœ… Jittor åŸºç¡€åŠŸèƒ½æ­£å¸¸")
            print("âœ… Loss å®šä¹‰ç¬¦åˆè§„èŒƒ")
            print("âœ… å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥è°ƒè¯•")
        else:
            print("\nâš ï¸ NanoDet æŸå¤±æµ‹è¯•å¤±è´¥")
            print("é—®é¢˜å¯èƒ½å‡ºç°åœ¨å¤æ‚çš„æŸå¤±è®¡ç®—é€»è¾‘ä¸­")
    else:
        print("\nâŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print("é—®é¢˜å‡ºç°åœ¨ Jittor ç¯å¢ƒæˆ–åŸºç¡€é…ç½®ä¸­")
        print("å»ºè®®æ£€æŸ¥ CUDA ç¯å¢ƒå’Œ Jittor å®‰è£…")

if __name__ == "__main__":
    main()
