#!/usr/bin/env python3
"""
ğŸ”¥ æœ€å°åŒ–è®­ç»ƒè„šæœ¬ - ç›´æ¥éªŒè¯è®­ç»ƒæ˜¯å¦å¯ä»¥è¿›è¡Œ
"""

import sys
sys.path.insert(0, '.')

import os
import time
import jittor as jt
from nanodet.util import cfg, load_config
from nanodet.model.arch import build_model
from nanodet.data.dataset import build_dataset
from nanodet.data.collate import naive_collate
from nanodet.trainer.task import TrainingTask

def main():
    print("ğŸ”¥ æœ€å°åŒ–è®­ç»ƒæµ‹è¯•")
    print("=" * 40)
    
    # è®¾ç½®ç¯å¢ƒ
    os.environ['DISABLE_MULTIPROCESSING'] = '1'
    jt.flags.use_cuda = 1 if jt.has_cuda else 0
    
    # åŠ è½½é…ç½®
    load_config(cfg, 'config/nanodet-plus-m_320_voc_bs64_50epochs.yml')
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = build_dataset(cfg.data.train, 'train')
    print(f"âœ… æ•°æ®é›†: {len(train_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    model = build_model(cfg.model)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºè®­ç»ƒä»»åŠ¡
    task = TrainingTask(cfg, model)
    optimizer, scheduler = task.configure_optimizers()
    print(f"âœ… è®­ç»ƒä»»åŠ¡åˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from jittor.dataset import DataLoader
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=0,
        collate_batch=naive_collate,
        drop_last=False
    )
    print(f"âœ… æ•°æ®åŠ è½½å™¨: {len(train_dataloader)} æ‰¹æ¬¡")
    
    # å¼€å§‹è®­ç»ƒæµ‹è¯•
    print("\nğŸ”¥ å¼€å§‹è®­ç»ƒæµ‹è¯•...")
    
    try:
        from types import SimpleNamespace
        
        model.train()
        
        # åªæµ‹è¯•å‰5ä¸ªæ‰¹æ¬¡
        for batch_idx, batch in enumerate(train_dataloader):
            if batch_idx >= 5:
                break
                
            print(f"\n--- æ‰¹æ¬¡ {batch_idx + 1}/5 ---")
            
            # åˆ›å»º trainer mock
            trainer_mock = SimpleNamespace(
                current_epoch=0,
                global_step=batch_idx,
                num_training_batches=5,
                num_val_batches=100,
                optimizer=optimizer
            )
            
            try:
                # å‰å‘ä¼ æ’­
                print("  å‰å‘ä¼ æ’­...")
                loss_dict = task.training_step(batch, batch_idx, trainer_mock)
                total_loss = loss_dict['loss']
                print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ŒæŸå¤±å½¢çŠ¶: {total_loss.shape}")
                
                # åå‘ä¼ æ’­
                print("  åå‘ä¼ æ’­...")
                optimizer.step(total_loss)
                print(f"  âœ… åå‘ä¼ æ’­æˆåŠŸ")
                
                print(f"  âœ… æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ æ‰¹æ¬¡ {batch_idx + 1} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                break
        
        print("\nğŸ‰ è®­ç»ƒæµ‹è¯•å®Œæˆï¼")
        print("âœ… NanoDet-Plus Jittor å¯ä»¥æ­£å¸¸è®­ç»ƒï¼")
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
