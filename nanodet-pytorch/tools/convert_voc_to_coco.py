#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°†VOCæ•°æ®é›†è½¬æ¢ä¸ºCOCOæ ¼å¼
ç”¨äºPyTorchè¯„ä¼°è„šæœ¬
"""

import os
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from datetime import datetime

# VOCç±»åˆ«æ˜ å°„åˆ°COCOæ ¼å¼
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
    'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

# åˆ›å»ºç±»åˆ«IDæ˜ å°„
CLASS_TO_ID = {cls_name: i + 1 for i, cls_name in enumerate(VOC_CLASSES)}


def parse_voc_annotation(xml_path):
    """è§£æVOC XMLæ ‡æ³¨æ–‡ä»¶"""
    tree = ET.parse(xml_path)
    root = tree.getroot()
    
    # è·å–å›¾åƒä¿¡æ¯
    filename = root.find('filename').text
    size = root.find('size')
    width = int(size.find('width').text)
    height = int(size.find('height').text)
    
    # è·å–æ‰€æœ‰ç›®æ ‡
    objects = []
    for obj in root.findall('object'):
        class_name = obj.find('name').text
        if class_name not in VOC_CLASSES:
            continue
        
        # è·å–è¾¹ç•Œæ¡†
        bbox = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        
        # è½¬æ¢ä¸ºCOCOæ ¼å¼ [x, y, width, height]
        coco_bbox = [xmin, ymin, xmax - xmin, ymax - ymin]
        area = (xmax - xmin) * (ymax - ymin)
        
        objects.append({
            'class_name': class_name,
            'class_id': CLASS_TO_ID[class_name],
            'bbox': coco_bbox,
            'area': area
        })
    
    return {
        'filename': filename,
        'width': width,
        'height': height,
        'objects': objects
    }


def convert_voc_to_coco(voc_root, split='val', output_file=None):
    """å°†VOCæ•°æ®é›†è½¬æ¢ä¸ºCOCOæ ¼å¼"""
    print(f"ğŸ” è½¬æ¢VOC {split} æ•°æ®é›†ä¸ºCOCOæ ¼å¼...")
    
    # è¯»å–å›¾åƒåˆ—è¡¨
    split_file = os.path.join(voc_root, f"ImageSets/Main/{split}.txt")
    with open(split_file, 'r') as f:
        image_ids = [line.strip() for line in f.readlines()]
    
    print(f"æ‰¾åˆ° {len(image_ids)} å¼ å›¾åƒ")
    
    # åˆå§‹åŒ–COCOæ ¼å¼æ•°æ®
    coco_data = {
        "info": {
            "description": f"VOC2007 {split} dataset in COCO format",
            "version": "1.0",
            "year": 2007,
            "contributor": "PASCAL VOC",
            "date_created": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "licenses": [
            {
                "id": 1,
                "name": "Unknown",
                "url": ""
            }
        ],
        "categories": [],
        "images": [],
        "annotations": []
    }
    
    # æ·»åŠ ç±»åˆ«ä¿¡æ¯
    for i, class_name in enumerate(VOC_CLASSES):
        coco_data["categories"].append({
            "id": i + 1,
            "name": class_name,
            "supercategory": "object"
        })
    
    annotation_id = 1
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for image_id, img_id in enumerate(image_ids, 1):
        # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        image_path = os.path.join(voc_root, f"JPEGImages/{img_id}.jpg")
        if not os.path.exists(image_path):
            print(f"âš ï¸ å›¾åƒä¸å­˜åœ¨: {image_path}")
            continue
        
        # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        annotation_path = os.path.join(voc_root, f"Annotations/{img_id}.xml")
        if not os.path.exists(annotation_path):
            print(f"âš ï¸ æ ‡æ³¨ä¸å­˜åœ¨: {annotation_path}")
            continue
        
        try:
            # è§£ææ ‡æ³¨
            annotation_data = parse_voc_annotation(annotation_path)
            
            # æ·»åŠ å›¾åƒä¿¡æ¯
            coco_data["images"].append({
                "id": image_id,
                "file_name": annotation_data['filename'],
                "width": annotation_data['width'],
                "height": annotation_data['height'],
                "license": 1,
                "flickr_url": "",
                "coco_url": "",
                "date_captured": ""
            })
            
            # æ·»åŠ æ ‡æ³¨ä¿¡æ¯
            for obj in annotation_data['objects']:
                coco_data["annotations"].append({
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": obj['class_id'],
                    "bbox": obj['bbox'],
                    "area": obj['area'],
                    "iscrowd": 0,
                    "segmentation": []
                })
                annotation_id += 1
        
        except Exception as e:
            print(f"âŒ å¤„ç† {img_id} å¤±è´¥: {e}")
            continue
        
        if (image_id) % 500 == 0:
            print(f"  å·²å¤„ç†: {image_id}/{len(image_ids)}")
    
    print(f"âœ… è½¬æ¢å®Œæˆ:")
    print(f"  å›¾åƒæ•°: {len(coco_data['images'])}")
    print(f"  æ ‡æ³¨æ•°: {len(coco_data['annotations'])}")
    print(f"  ç±»åˆ«æ•°: {len(coco_data['categories'])}")
    
    # ä¿å­˜COCOæ ¼å¼æ–‡ä»¶
    if output_file is None:
        output_file = f"data/annotations/voc_{split}.json"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w') as f:
        json.dump(coco_data, f, indent=2)
    
    print(f"âœ… COCOæ ¼å¼æ–‡ä»¶å·²ä¿å­˜: {output_file}")
    
    return output_file


def create_data_symlinks():
    """åˆ›å»ºæ•°æ®é›†è½¯é“¾æ¥"""
    print("ğŸ” åˆ›å»ºæ•°æ®é›†è½¯é“¾æ¥...")
    
    # åˆ›å»ºdataç›®å½•
    os.makedirs("data", exist_ok=True)
    
    # åˆ›å»ºVOCdevkitè½¯é“¾æ¥
    voc_source = "/home/kyc/project/nanodet/data/VOCdevkit"
    voc_target = "data/VOCdevkit"
    
    if not os.path.exists(voc_target):
        os.symlink(voc_source, voc_target)
        print(f"âœ… åˆ›å»ºè½¯é“¾æ¥: {voc_target} -> {voc_source}")
    else:
        print(f"âœ… è½¯é“¾æ¥å·²å­˜åœ¨: {voc_target}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹VOCåˆ°COCOæ ¼å¼è½¬æ¢")
    print("=" * 60)
    
    try:
        # 1. åˆ›å»ºæ•°æ®é›†è½¯é“¾æ¥
        create_data_symlinks()
        
        # 2. è®¾ç½®è·¯å¾„
        voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
        
        if not os.path.exists(voc_root):
            print(f"âŒ VOCæ•°æ®é›†ä¸å­˜åœ¨: {voc_root}")
            return
        
        # 3. è½¬æ¢è®­ç»ƒé›†
        print(f"\nè½¬æ¢è®­ç»ƒé›†...")
        train_file = convert_voc_to_coco(voc_root, 'train', 'data/annotations/voc_train.json')
        
        # 4. è½¬æ¢éªŒè¯é›†
        print(f"\nè½¬æ¢éªŒè¯é›†...")
        val_file = convert_voc_to_coco(voc_root, 'val', 'data/annotations/voc_val.json')
        
        # 5. è½¬æ¢æµ‹è¯•é›†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        test_split_file = os.path.join(voc_root, "ImageSets/Main/test.txt")
        if os.path.exists(test_split_file):
            print(f"\nè½¬æ¢æµ‹è¯•é›†...")
            test_file = convert_voc_to_coco(voc_root, 'test', 'data/annotations/voc_test.json')
        else:
            print(f"\nâš ï¸ æµ‹è¯•é›†ä¸å­˜åœ¨ï¼Œä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†")
            # å¤åˆ¶éªŒè¯é›†æ–‡ä»¶ä½œä¸ºæµ‹è¯•é›†
            import shutil
            shutil.copy(val_file, 'data/annotations/voc_test.json')
            print(f"âœ… å¤åˆ¶éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†: data/annotations/voc_test.json")
        
        print(f"\nğŸ¯ è½¬æ¢å®Œæˆï¼")
        print(f"ç°åœ¨å¯ä»¥ä½¿ç”¨PyTorchè¯„ä¼°è„šæœ¬è¿›è¡Œæµ‹è¯•äº†")
        
        # 6. éªŒè¯æ–‡ä»¶
        print(f"\néªŒè¯ç”Ÿæˆçš„æ–‡ä»¶:")
        for file_path in ['data/annotations/voc_train.json', 'data/annotations/voc_val.json', 'data/annotations/voc_test.json']:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path) / 1024 / 1024  # MB
                print(f"  âœ… {file_path} ({file_size:.1f} MB)")
            else:
                print(f"  âŒ {file_path} ä¸å­˜åœ¨")
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
