#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‡æ–°åˆ†é…VOCæ•°æ®é›†
æŒ‰ç…§æ ‡å‡†çš„70%-15%-15%æ¯”ä¾‹é‡æ–°åˆ†é…è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
"""

import os
import random
import shutil
from pathlib import Path


def analyze_current_distribution():
    """åˆ†æå½“å‰æ•°æ®é›†åˆ†å¸ƒ"""
    print("ğŸ” åˆ†æå½“å‰VOCæ•°æ®é›†åˆ†å¸ƒ...")
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    
    splits = ['train', 'val', 'test']
    current_distribution = {}
    
    for split in splits:
        split_file = os.path.join(voc_root, f"ImageSets/Main/{split}.txt")
        if os.path.exists(split_file):
            with open(split_file, 'r') as f:
                image_ids = [line.strip() for line in f.readlines()]
            current_distribution[split] = len(image_ids)
            print(f"  {split}: {len(image_ids)} å¼ å›¾åƒ")
        else:
            current_distribution[split] = 0
            print(f"  {split}: æ–‡ä»¶ä¸å­˜åœ¨")
    
    total = sum(current_distribution.values())
    print(f"  æ€»è®¡: {total} å¼ å›¾åƒ")
    
    if total > 0:
        print(f"\nå½“å‰åˆ†é…æ¯”ä¾‹:")
        for split, count in current_distribution.items():
            percentage = count / total * 100
            print(f"  {split}: {percentage:.1f}%")
    
    return current_distribution, total


def get_all_available_images():
    """è·å–æ‰€æœ‰å¯ç”¨çš„å›¾åƒ"""
    print("\nğŸ” æ”¶é›†æ‰€æœ‰å¯ç”¨å›¾åƒ...")
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    images_dir = os.path.join(voc_root, "JPEGImages")
    annotations_dir = os.path.join(voc_root, "Annotations")
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = list(Path(images_dir).glob("*.jpg"))
    
    # æ£€æŸ¥å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    valid_images = []
    
    for image_file in image_files:
        image_id = image_file.stem
        annotation_file = os.path.join(annotations_dir, f"{image_id}.xml")
        
        if os.path.exists(annotation_file):
            valid_images.append(image_id)
    
    print(f"  æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒæ–‡ä»¶")
    print(f"  å…¶ä¸­ {len(valid_images)} å¼ æœ‰å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶")
    
    return valid_images


def redistribute_dataset(all_images, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """é‡æ–°åˆ†é…æ•°æ®é›†"""
    print(f"\nğŸ”§ é‡æ–°åˆ†é…æ•°æ®é›†...")
    print(f"  ç›®æ ‡æ¯”ä¾‹: è®­ç»ƒé›†{train_ratio*100:.0f}%, éªŒè¯é›†{val_ratio*100:.0f}%, æµ‹è¯•é›†{test_ratio*100:.0f}%")
    
    # ç¡®ä¿æ¯”ä¾‹åŠ èµ·æ¥ç­‰äº1
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ç­‰äº1"
    
    # éšæœºæ‰“ä¹±
    random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿å¯é‡å¤
    shuffled_images = all_images.copy()
    random.shuffle(shuffled_images)
    
    total_count = len(shuffled_images)
    
    # è®¡ç®—å„é›†åˆçš„å¤§å°
    train_count = int(total_count * train_ratio)
    val_count = int(total_count * val_ratio)
    test_count = total_count - train_count - val_count  # å‰©ä½™çš„éƒ½ç»™æµ‹è¯•é›†
    
    # åˆ†é…å›¾åƒ
    train_images = shuffled_images[:train_count]
    val_images = shuffled_images[train_count:train_count + val_count]
    test_images = shuffled_images[train_count + val_count:]
    
    print(f"\næ–°çš„åˆ†é…ç»“æœ:")
    print(f"  è®­ç»ƒé›†: {len(train_images)} å¼  ({len(train_images)/total_count*100:.1f}%)")
    print(f"  éªŒè¯é›†: {len(val_images)} å¼  ({len(val_images)/total_count*100:.1f}%)")
    print(f"  æµ‹è¯•é›†: {len(test_images)} å¼  ({len(test_images)/total_count*100:.1f}%)")
    print(f"  æ€»è®¡: {total_count} å¼ ")
    
    return {
        'train': train_images,
        'val': val_images,
        'test': test_images
    }


def backup_original_splits():
    """å¤‡ä»½åŸå§‹çš„æ•°æ®é›†åˆ†å‰²"""
    print(f"\nğŸ’¾ å¤‡ä»½åŸå§‹æ•°æ®é›†åˆ†å‰²...")
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    imagesets_dir = os.path.join(voc_root, "ImageSets/Main")
    backup_dir = os.path.join(voc_root, "ImageSets/Main_backup")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    os.makedirs(backup_dir, exist_ok=True)
    
    # å¤‡ä»½ç°æœ‰çš„åˆ†å‰²æ–‡ä»¶
    splits = ['train.txt', 'val.txt', 'test.txt']
    
    for split_file in splits:
        original_path = os.path.join(imagesets_dir, split_file)
        backup_path = os.path.join(backup_dir, split_file)
        
        if os.path.exists(original_path):
            shutil.copy2(original_path, backup_path)
            print(f"  å¤‡ä»½: {split_file}")
        else:
            print(f"  è·³è¿‡: {split_file} (ä¸å­˜åœ¨)")
    
    print(f"  å¤‡ä»½å®Œæˆ: {backup_dir}")


def save_new_splits(new_distribution):
    """ä¿å­˜æ–°çš„æ•°æ®é›†åˆ†å‰²"""
    print(f"\nğŸ’¾ ä¿å­˜æ–°çš„æ•°æ®é›†åˆ†å‰²...")
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    imagesets_dir = os.path.join(voc_root, "ImageSets/Main")
    
    for split_name, image_ids in new_distribution.items():
        split_file = os.path.join(imagesets_dir, f"{split_name}.txt")
        
        with open(split_file, 'w') as f:
            for image_id in sorted(image_ids):  # æ’åºä»¥ä¿è¯ä¸€è‡´æ€§
                f.write(f"{image_id}\n")
        
        print(f"  ä¿å­˜: {split_name}.txt ({len(image_ids)} å¼ å›¾åƒ)")
    
    print(f"  ä¿å­˜å®Œæˆ: {imagesets_dir}")


def verify_new_distribution():
    """éªŒè¯æ–°çš„æ•°æ®é›†åˆ†å¸ƒ"""
    print(f"\nâœ… éªŒè¯æ–°çš„æ•°æ®é›†åˆ†å¸ƒ...")
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    
    splits = ['train', 'val', 'test']
    new_distribution = {}
    all_images_check = set()
    
    for split in splits:
        split_file = os.path.join(voc_root, f"ImageSets/Main/{split}.txt")
        with open(split_file, 'r') as f:
            image_ids = [line.strip() for line in f.readlines()]
        
        new_distribution[split] = len(image_ids)
        all_images_check.update(image_ids)
        
        print(f"  {split}: {len(image_ids)} å¼ å›¾åƒ")
    
    total = sum(new_distribution.values())
    print(f"  æ€»è®¡: {total} å¼ å›¾åƒ")
    print(f"  å»é‡å: {len(all_images_check)} å¼ å›¾åƒ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
    if total == len(all_images_check):
        print(f"  âœ… æ— é‡å¤å›¾åƒ")
    else:
        print(f"  âŒ å­˜åœ¨é‡å¤å›¾åƒ")
    
    # æ˜¾ç¤ºæ–°çš„æ¯”ä¾‹
    print(f"\næ–°çš„åˆ†é…æ¯”ä¾‹:")
    for split, count in new_distribution.items():
        percentage = count / total * 100
        print(f"  {split}: {percentage:.1f}%")
    
    return new_distribution


def create_class_specific_splits():
    """åˆ›å»ºç±»åˆ«ç‰¹å®šçš„åˆ†å‰²æ–‡ä»¶ï¼ˆVOCæ ¼å¼éœ€è¦ï¼‰"""
    print(f"\nğŸ”§ åˆ›å»ºç±»åˆ«ç‰¹å®šçš„åˆ†å‰²æ–‡ä»¶...")
    
    # VOC 20ä¸ªç±»åˆ«
    voc_classes = [
        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
        'bus', 'car', 'cat', 'chair', 'cow',
        'diningtable', 'dog', 'horse', 'motorbike', 'person',
        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
    ]
    
    voc_root = "/home/kyc/project/nanodet/data/VOCdevkit/VOC2007"
    imagesets_dir = os.path.join(voc_root, "ImageSets/Main")
    
    # è¯»å–ä¸»è¦çš„åˆ†å‰²
    splits = ['train', 'val', 'test']
    main_splits = {}
    
    for split in splits:
        split_file = os.path.join(imagesets_dir, f"{split}.txt")
        with open(split_file, 'r') as f:
            main_splits[split] = [line.strip() for line in f.readlines()]
    
    # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºåˆ†å‰²æ–‡ä»¶
    for class_name in voc_classes:
        for split in splits:
            class_split_file = os.path.join(imagesets_dir, f"{class_name}_{split}.txt")
            
            # ç®€åŒ–å¤„ç†ï¼šæ‰€æœ‰å›¾åƒéƒ½æ ‡è®°ä¸ºå¯èƒ½åŒ…å«è¯¥ç±»åˆ«
            with open(class_split_file, 'w') as f:
                for image_id in main_splits[split]:
                    f.write(f"{image_id}  1\n")  # 1è¡¨ç¤ºå¯èƒ½åŒ…å«è¯¥ç±»åˆ«
    
    print(f"  ä¸º {len(voc_classes)} ä¸ªç±»åˆ«åˆ›å»ºäº†åˆ†å‰²æ–‡ä»¶")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é‡æ–°åˆ†é…VOCæ•°æ®é›†")
    print("=" * 60)
    
    try:
        # 1. åˆ†æå½“å‰åˆ†å¸ƒ
        current_dist, total = analyze_current_distribution()
        
        if total == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®é›†")
            return
        
        # 2. è·å–æ‰€æœ‰å¯ç”¨å›¾åƒ
        all_images = get_all_available_images()
        
        if len(all_images) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒ")
            return
        
        # 3. è¯¢é—®ç”¨æˆ·ç¡®è®¤
        print(f"\nğŸ“‹ é‡æ–°åˆ†é…è®¡åˆ’:")
        print(f"  å½“å‰åˆ†å¸ƒ: è®­ç»ƒ{current_dist.get('train', 0)}å¼ , éªŒè¯{current_dist.get('val', 0)}å¼ , æµ‹è¯•{current_dist.get('test', 0)}å¼ ")
        print(f"  ç›®æ ‡åˆ†å¸ƒ: è®­ç»ƒ70%, éªŒè¯15%, æµ‹è¯•15%")
        print(f"  æ€»å›¾åƒæ•°: {len(all_images)}å¼ ")
        
        confirm = input(f"\næ˜¯å¦ç»§ç»­é‡æ–°åˆ†é…ï¼Ÿ(y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        # 4. å¤‡ä»½åŸå§‹åˆ†å‰²
        backup_original_splits()
        
        # 5. é‡æ–°åˆ†é…
        new_distribution = redistribute_dataset(all_images)
        
        # 6. ä¿å­˜æ–°åˆ†å‰²
        save_new_splits(new_distribution)
        
        # 7. åˆ›å»ºç±»åˆ«ç‰¹å®šåˆ†å‰²
        create_class_specific_splits()
        
        # 8. éªŒè¯ç»“æœ
        verify_new_distribution()
        
        print(f"\nğŸ¯ æ•°æ®é›†é‡æ–°åˆ†é…å®Œæˆï¼")
        print(f"  åŸå§‹åˆ†å‰²å·²å¤‡ä»½åˆ°: ImageSets/Main_backup/")
        print(f"  æ–°çš„åˆ†å‰²å·²ä¿å­˜åˆ°: ImageSets/Main/")
        print(f"  ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
        
    except Exception as e:
        print(f"âŒ é‡æ–°åˆ†é…å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
