#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
PyTorchç‰ˆæœ¬è®­ç»ƒå‡†å¤‡è„šæœ¬
æ£€æŸ¥ç¯å¢ƒã€æ•°æ®é›†ï¼Œå¹¶æä¾›è®­ç»ƒæŒ‡å¯¼
"""

import os
import sys
import subprocess
import json
from pathlib import Path


def check_pytorch_environment():
    """æ£€æŸ¥PyTorchç¯å¢ƒ"""
    print("=" * 60)
    print("PyTorch Environment Check")
    print("=" * 60)
    
    try:
        import warnings
        warnings.filterwarnings("ignore", message=".*NumPy.*")

        import torch
        print(f"âœ“ PyTorch version: {torch.__version__}")

        try:
            import torchvision
            print(f"âœ“ TorchVision version: {torchvision.__version__}")
        except Exception as e:
            print(f"âš  TorchVision warning (but available): {str(e)[:50]}...")

        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            print(f"âœ“ CUDA available: {torch.cuda.get_device_name(0)}")
            print(f"âœ“ CUDA version: {torch.version.cuda}")
            print(f"âœ“ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
        else:
            print("âš  CUDA not available, will use CPU training")

        return True
    except ImportError as e:
        print(f"âœ— PyTorch not installed: {e}")
        return False


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…ï¼ˆä¿®å¤äº†åŒ…åä¸æ¨¡å—åæ˜ å°„é—®é¢˜ï¼‰"""
    print("\n" + "=" * 60)
    print("Dependencies Check")
    print("=" * 60)
    
    # å…³é”®ä¿®å¤ï¼šå»ºç«‹ã€Œå®‰è£…åŒ…åâ†’å¯¼å…¥æ¨¡å—åã€çš„æ˜ å°„å…³ç³»
    required_packages = {
        'pytorch_lightning': 'pytorch_lightning',
        'opencv-python': 'cv2',          # å®‰è£…åâ‰ å¯¼å…¥å
        'pycocotools': 'pycocotools',
        'matplotlib': 'matplotlib',
        'numpy': 'numpy',
        'Pillow': 'PIL',                 # å®‰è£…åâ‰ å¯¼å…¥å
        'tqdm': 'tqdm',
        'tensorboard': 'tensorboard'
    }
    
    missing_packages = []
    
    for install_name, import_name in required_packages.items():
        try:
            import warnings
            warnings.filterwarnings("ignore")
            __import__(import_name)  # ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥å
            print(f"âœ“ {install_name}")
        except ImportError:
            print(f"âœ— {install_name} - Missing")
            missing_packages.append(install_name)  # æç¤ºæ—¶ç”¨å®‰è£…å
        except Exception as e:
            print(f"âš  {install_name} - Available but with warnings")
    
    if missing_packages:
        print(f"\nâš  Missing packages: {', '.join(missing_packages)}")
        print("Install with: pip install " + " ".join(missing_packages))
        return False
    
    return True


def check_voc_dataset():
    """æ£€æŸ¥VOCæ•°æ®é›†"""
    print("\n" + "=" * 60)
    print("VOC Dataset Check")
    print("=" * 60)
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    data_paths = [
        'data/VOC_mini',
        '../nanodet-jittor/data/VOC_mini',
        'data/VOCdevkit'
    ]
    
    dataset_path = None
    for path in data_paths:
        if os.path.exists(path):
            dataset_path = path
            break
    
    if dataset_path is None:
        print("âœ— VOC dataset not found")
        print("Please prepare VOC dataset using one of these methods:")
        print("1. cd ../nanodet-jittor && python tools/create_mini_voc_dataset.py")
        print("2. cd ../nanodet-jittor && python tools/download_voc_dataset.py --download")
        return False
    
    print(f"âœ“ Dataset found at: {dataset_path}")
    
    # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
    ann_files = [
        os.path.join(dataset_path, 'annotations/voc_train.json'),
        os.path.join(dataset_path, 'annotations/voc_val.json')
    ]
    
    for ann_file in ann_files:
        if os.path.exists(ann_file):
            with open(ann_file, 'r') as f:
                data = json.load(f)
            print(f"âœ“ {os.path.basename(ann_file)}: {len(data['images'])} images, {len(data['annotations'])} annotations")
        else:
            print(f"âœ— {ann_file} not found")
            return False
    
    # æ£€æŸ¥å›¾ç‰‡ç›®å½•
    img_dir = os.path.join(dataset_path, 'images')
    if os.path.exists(img_dir):
        img_count = len([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])
        print(f"âœ“ Images directory: {img_count} images")
    else:
        print(f"âœ— Images directory not found: {img_dir}")
        return False
    
    return True, dataset_path


def update_config_paths(dataset_path):
    """æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®é›†è·¯å¾„"""
    print("\n" + "=" * 60)
    print("Config Update")
    print("=" * 60)
    
    config_file = 'config/nanodet-plus-m_320_voc.yml'
    
    if not os.path.exists(config_file):
        print(f"âœ— Config file not found: {config_file}")
        return False
    
    # è¯»å–é…ç½®æ–‡ä»¶
    with open(config_file, 'r') as f:
        content = f.read()
    
    # æ›´æ–°è·¯å¾„
    abs_dataset_path = os.path.abspath(dataset_path)
    img_path = os.path.join(abs_dataset_path, 'images')
    train_ann_path = os.path.join(abs_dataset_path, 'annotations/voc_train.json')
    val_ann_path = os.path.join(abs_dataset_path, 'annotations/voc_val.json')
    
    # æ›¿æ¢è·¯å¾„
    content = content.replace('data/VOC_mini/images', img_path)
    content = content.replace('data/VOC_mini/annotations/voc_train.json', train_ann_path)
    content = content.replace('data/VOC_mini/annotations/voc_val.json', val_ann_path)
    
    # å†™å›é…ç½®æ–‡ä»¶
    with open(config_file, 'w') as f:
        f.write(content)
    
    print(f"âœ“ Updated config file: {config_file}")
    print(f"  Image path: {img_path}")
    print(f"  Train annotations: {train_ann_path}")
    print(f"  Val annotations: {val_ann_path}")
    
    return True


def install_nanodet():
    """å®‰è£…NanoDetåŒ…"""
    print("\n" + "=" * 60)
    print("NanoDet Installation")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
        import nanodet
        print("âœ“ NanoDet already installed")
        return True
    except ImportError:
        print("Installing NanoDet...")
        try:
            subprocess.run([sys.executable, 'setup.py', 'develop'], check=True)
            print("âœ“ NanoDet installed successfully")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âœ— Failed to install NanoDet: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("NanoDet PyTorch Training Preparation")
    print("Preparing PyTorch version training for baseline results...")
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_pytorch_environment():
        print("\nâŒ PyTorch environment check failed!")
        return False
    
    if not check_dependencies():
        print("\nâŒ Dependencies check failed!")
        return False
    
    # æ£€æŸ¥æ•°æ®é›†
    dataset_check = check_voc_dataset()
    if isinstance(dataset_check, tuple):
        success, dataset_path = dataset_check
        if not success:
            print("\nâŒ VOC dataset check failed!")
            return False
    else:
        print("\nâŒ VOC dataset check failed!")
        return False
    
    # æ›´æ–°é…ç½®
    if not update_config_paths(dataset_path):
        print("\nâŒ Config update failed!")
        return False
    
    # å®‰è£…NanoDet
    if not install_nanodet():
        print("\nâŒ NanoDet installation failed!")
        return False
    
    # æ˜¾ç¤ºè®­ç»ƒå‘½ä»¤
    print("\n" + "=" * 60)
    print("Ready to Train!")
    print("=" * 60)
    print("\nğŸ‰ All checks passed! Ready to start PyTorch training.")
    print("\nTraining commands:")
    print("1. Quick test (few epochs):")
    print("   python tools/train.py config/nanodet-plus-m_320_voc.yml")
    print("\n2. Full training:")
    print("   python tools/train.py config/nanodet-plus-m_320_voc.yml")
    print("\n3. Resume training:")
    print("   python tools/train.py config/nanodet-plus-m_320_voc.yml --resume")
    print("\n4. Test model:")
    print("   python tools/test.py config/nanodet-plus-m_320_voc.yml --checkpoint workspace/nanodet-plus-m_320_voc/model_best.ckpt")
    
    print("\nğŸ“Š Expected results:")
    print("- Training time: ~2-4 hours for 100 epochs")
    print("- Memory usage: ~6-7GB on RTX4060")
    print("- mAP target: 40-50% on VOC dataset")
    print("- Model size: ~1.2MB")
    
    print("\nğŸ“ Training logs will be saved to:")
    print("- Checkpoints: workspace/nanodet-plus-m_320_voc/")
    print("- TensorBoard: workspace/nanodet-plus-m_320_voc/tb_logs/")
    
    return True


if __name__ == '__main__':
    success = main()
    if not success:
        print("\nâŒ Preparation failed! Please fix the issues above.")
        sys.exit(1)
    else:
        print("\nâœ… Preparation completed successfully!")
        sys.exit(0)
