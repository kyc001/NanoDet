#!/usr/bin/env python3
"""
ç®€å•çš„PyTorch vs Jittoræ£€æµ‹ç»“æœå¯¹æ¯”
ä½¿ç”¨sample_detsä¸­çš„åŸå›¾ï¼Œç”¨PyTorchæ¨ç†ï¼Œç„¶åä¸Jittorç»“æœå¯¹æ¯”
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import subprocess
import sys

def get_original_images():
    """è·å–sample_detså¯¹åº”çš„åŸå›¾"""
    sample_dets_dir = "DELIVERABLES/images/sample_dets"
    original_images = []
    
    if os.path.exists(sample_dets_dir):
        det_files = sorted([f for f in os.listdir(sample_dets_dir) if f.endswith('_det.jpg')])
        
        for det_file in det_files:
            img_name = det_file.replace('_det.jpg', '.jpg')
            original_path = f"data/VOCdevkit/VOC2007/JPEGImages/{img_name}"
            jittor_result_path = os.path.join(sample_dets_dir, det_file)
            
            if os.path.exists(original_path):
                original_images.append({
                    'name': img_name.replace('.jpg', ''),
                    'original': original_path,
                    'jittor_result': jittor_result_path
                })
    
    return original_images

def run_pytorch_inference_simple(image_path, output_path):
    """ä½¿ç”¨PyTorchè¿›è¡Œç®€å•æ¨ç†"""
    try:
        print(f"ğŸ” PyTorchæ¨ç†: {os.path.basename(image_path)}")
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        config_path = "nanodet-pytorch/config/nanodet-plus-m_320_voc_bs64_50epochs.yml"
        model_path = "nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64_50epochs/model_best/model_best.ckpt"
        demo_script = "tools/simple_pytorch_demo.py"

        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False

        if not os.path.exists(demo_script):
            print(f"âŒ æ¨ç†è„šæœ¬ä¸å­˜åœ¨: {demo_script}")
            return False

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # æ„å»ºæ¨ç†å‘½ä»¤
        cmd = [
            "python", demo_script,
            "--config", config_path,
            "--model", model_path,
            "--img", image_path,
            "--output", output_path,
            "--device", "cuda:0"
        ]
        
        print(f"   æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # æ‰§è¡Œæ¨ç†å‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            print(f"âœ… PyTorchæ¨ç†æˆåŠŸ")
            if os.path.exists(output_path):
                print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
                return True
            else:
                print(f"   è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ: {output_path}")
                return False
        else:
            print(f"âŒ PyTorchæ¨ç†å¤±è´¥:")
            print(f"   stderr: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"âŒ PyTorchæ¨ç†è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ PyTorchæ¨ç†å¼‚å¸¸: {e}")
        return False

def create_three_way_comparison(original_path, pytorch_result_path, jittor_result_path, output_path, img_name):
    """åˆ›å»ºä¸‰å›¾å¯¹æ¯”"""
    
    fig, axes = plt.subplots(1, 3, figsize=(24, 8))
    
    # åŸå›¾
    if os.path.exists(original_path):
        original_img = cv2.imread(original_path)
        original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        axes[0].imshow(original_img_rgb)
        axes[0].set_title('Original Image', fontsize=16, fontweight='bold')
    else:
        axes[0].text(0.5, 0.5, 'Original\nNot Found', ha='center', va='center', fontsize=16)
        axes[0].set_title('Original Image', fontsize=16, fontweight='bold')
    axes[0].axis('off')
    
    # PyTorchç»“æœ
    if pytorch_result_path and os.path.exists(pytorch_result_path):
        pytorch_img = cv2.imread(pytorch_result_path)
        pytorch_img_rgb = cv2.cvtColor(pytorch_img, cv2.COLOR_BGR2RGB)
        axes[1].imshow(pytorch_img_rgb)
        axes[1].set_title('PyTorch Detection\n(Real Result)', fontsize=16, fontweight='bold', color='red')
    else:
        axes[1].text(0.5, 0.5, 'PyTorch\nInference Failed', ha='center', va='center', fontsize=16, color='red')
        axes[1].set_title('PyTorch Detection\n(Failed)', fontsize=16, fontweight='bold', color='red')
    axes[1].axis('off')
    
    # Jittorç»“æœ
    if os.path.exists(jittor_result_path):
        jittor_img = cv2.imread(jittor_result_path)
        jittor_img_rgb = cv2.cvtColor(jittor_img, cv2.COLOR_BGR2RGB)
        axes[2].imshow(jittor_img_rgb)
        axes[2].set_title('Jittor Detection\n(Real Result)', fontsize=16, fontweight='bold', color='blue')
    else:
        axes[2].text(0.5, 0.5, 'Jittor\nResult Not Found', ha='center', va='center', fontsize=16, color='blue')
        axes[2].set_title('Jittor Detection\n(Not Found)', fontsize=16, fontweight='bold', color='blue')
    axes[2].axis('off')
    
    # è®¾ç½®æ€»æ ‡é¢˜
    fig.suptitle(f'Real Detection Comparison: {img_name}', fontsize=20, fontweight='bold')
    
    # ä¿å­˜å¯¹æ¯”å›¾
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ä¸‰å›¾å¯¹æ¯”å·²ä¿å­˜: {output_path}")

def create_comparison_grid():
    """åˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾"""
    
    # è·å–åŸå›¾åˆ—è¡¨
    images = get_original_images()
    
    if len(images) < 4:
        print("âŒ å›¾ç‰‡æ•°é‡ä¸è¶³")
        return
    
    # é€‰æ‹©å‰8å¼ å›¾ç‰‡
    selected_images = images[:8]
    
    fig, axes = plt.subplots(2, 4, figsize=(24, 12))
    fig.suptitle('PyTorch vs Jittor Detection Results Comparison', fontsize=20, fontweight='bold')
    
    for i, img_info in enumerate(selected_images):
        row = i // 4
        col = i % 4
        
        # å°è¯•åŠ è½½PyTorchç»“æœ
        pytorch_result_path = f"temp_pytorch_results/{img_info['name']}_det.jpg"
        
        if os.path.exists(pytorch_result_path):
            # å¦‚æœæœ‰PyTorchç»“æœï¼Œæ˜¾ç¤ºå¯¹æ¯”
            pytorch_img = cv2.imread(pytorch_result_path)
            pytorch_img_rgb = cv2.cvtColor(pytorch_img, cv2.COLOR_BGR2RGB)
            
            # ä¸ŠåŠéƒ¨åˆ†æ˜¾ç¤ºPyTorchç»“æœ
            if row == 0:
                axes[row, col].imshow(pytorch_img_rgb)
                axes[row, col].set_title(f'PyTorch: {img_info["name"]}', fontweight='bold', color='red')
            else:
                # ä¸‹åŠéƒ¨åˆ†æ˜¾ç¤ºJittorç»“æœ
                jittor_img = cv2.imread(img_info['jittor_result'])
                jittor_img_rgb = cv2.cvtColor(jittor_img, cv2.COLOR_BGR2RGB)
                axes[row, col].imshow(jittor_img_rgb)
                axes[row, col].set_title(f'Jittor: {img_info["name"]}', fontweight='bold', color='blue')
        else:
            # å¦‚æœæ²¡æœ‰PyTorchç»“æœï¼Œæ˜¾ç¤ºJittorç»“æœ
            jittor_img = cv2.imread(img_info['jittor_result'])
            jittor_img_rgb = cv2.cvtColor(jittor_img, cv2.COLOR_BGR2RGB)
            axes[row, col].imshow(jittor_img_rgb)
            axes[row, col].set_title(f'Jittor: {img_info["name"]}', fontweight='bold', color='blue')
        
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.savefig('DELIVERABLES/images/real_comparisons/pytorch_jittor_comparison_grid.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… å¯¹æ¯”ç½‘æ ¼å›¾å·²ç”Ÿæˆ: pytorch_jittor_comparison_grid.png")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹ç®€å•çš„PyTorch vs Jittoræ£€æµ‹ç»“æœå¯¹æ¯”...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("DELIVERABLES/images/real_comparisons", exist_ok=True)
    os.makedirs("temp_pytorch_results", exist_ok=True)
    
    # è·å–åŸå›¾åˆ—è¡¨
    images = get_original_images()
    
    if not images:
        print("âŒ æœªæ‰¾åˆ°åŸå›¾")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
    
    successful_pytorch = 0
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for i, img_info in enumerate(images[:4]):  # åªå¤„ç†å‰4å¼ 
        print(f"\nğŸ–¼ï¸ å¤„ç†å›¾ç‰‡ {i+1}/{min(4, len(images))}: {img_info['name']}")
        
        # PyTorchæ¨ç†
        pytorch_output = f"temp_pytorch_results/{img_info['name']}_det.jpg"
        pytorch_success = run_pytorch_inference_simple(img_info['original'], pytorch_output)
        
        if pytorch_success:
            successful_pytorch += 1
        
        # åˆ›å»ºä¸‰å›¾å¯¹æ¯”
        comparison_output = f"DELIVERABLES/images/real_comparisons/{img_info['name']}_three_way_comparison.png"
        create_three_way_comparison(
            img_info['original'],
            pytorch_output if pytorch_success else None,
            img_info['jittor_result'],
            comparison_output,
            img_info['name']
        )
    
    # åˆ›å»ºå¯¹æ¯”ç½‘æ ¼
    create_comparison_grid()
    
    print(f"\nğŸ“Š å¤„ç†ç»“æœ:")
    print(f"   æ€»å›¾ç‰‡æ•°: {min(4, len(images))}")
    print(f"   PyTorchæ¨ç†æˆåŠŸ: {successful_pytorch}")
    print(f"   Jittorç»“æœå¯ç”¨: {min(4, len(images))}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists("temp_pytorch_results"):
        import shutil
        # ä¸åˆ é™¤ï¼Œä¿ç•™ç»“æœ
        print(f"   PyTorchç»“æœä¿å­˜åœ¨: temp_pytorch_results/")
    
    print("\nğŸ‰ ç®€å•å¯¹æ¯”å®Œæˆï¼")
    print("ğŸ“ è¾“å‡ºç›®å½•: DELIVERABLES/images/real_comparisons/")

if __name__ == "__main__":
    main()
