#!/usr/bin/env python3
"""
è¿è¡ŒçœŸå®çš„PyTorchæ¨ç†å¹¶ä¸Jittorç»“æœå¯¹æ¯”
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
import subprocess
import json

def run_pytorch_demo(image_path):
    """è¿è¡ŒPyTorch demoè¿›è¡Œæ¨ç†"""
    try:
        print(f"ğŸ” è¿è¡ŒPyTorchæ¨ç†: {os.path.basename(image_path)}")
        
        # æ£€æŸ¥PyTorchæ¨ç†è„šæœ¬
        pytorch_inference = "tools/pytorch_inference_demo.py"
        if not os.path.exists(pytorch_inference):
            print(f"âŒ PyTorchæ¨ç†è„šæœ¬ä¸å­˜åœ¨: {pytorch_inference}")
            return None

        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_path = "nanodet-pytorch/config/nanodet-plus-m_320_voc_bs64_50epochs.yml"
        if not os.path.exists(config_path):
            print(f"âŒ PyTorché…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return None

        # æ£€æŸ¥æ¨¡å‹æƒé‡
        model_path = "nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64_50epochs/model_best/nanodet_model_best.pth"
        if not os.path.exists(model_path):
            print(f"âŒ PyTorchæ¨¡å‹æƒé‡ä¸å­˜åœ¨: {model_path}")
            return None

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "temp_pytorch_results"
        os.makedirs(output_dir, exist_ok=True)

        # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_img = os.path.join(output_dir, os.path.basename(image_path))

        # æ„å»ºæ¨ç†å‘½ä»¤
        cmd = [
            "python", pytorch_inference,
            "--config", config_path,
            "--model", model_path,
            "--img", image_path,
            "--output", output_img,
            "--device", "cuda:0"
        ]
        
        print(f"   æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        # æ‰§è¡Œæ¨ç†å‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

        if result.returncode == 0:
            print(f"âœ… PyTorchæ¨ç†æˆåŠŸ")
            print(f"   è¾“å‡º: {result.stdout}")

            # æ£€æŸ¥è¾“å‡ºå›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if os.path.exists(output_img):
                print(f"   è¾“å‡ºå›¾ç‰‡: {output_img}")
                return output_img
            else:
                print(f"   æœªæ‰¾åˆ°è¾“å‡ºå›¾ç‰‡: {output_img}")
                return None
        else:
            print(f"âŒ PyTorchæ¨ç†å¤±è´¥:")
            print(f"   stdout: {result.stdout}")
            print(f"   stderr: {result.stderr}")
            return None
            
    except subprocess.TimeoutExpired:
        print(f"âŒ PyTorchæ¨ç†è¶…æ—¶")
        return None
    except Exception as e:
        print(f"âŒ PyTorchæ¨ç†å¼‚å¸¸: {e}")
        return None

def create_real_side_by_side_comparison():
    """åˆ›å»ºçœŸå®çš„å¹¶æ’å¯¹æ¯”å›¾"""
    
    # è·å–æµ‹è¯•å›¾ç‰‡
    test_images = []
    sample_dets_dir = "DELIVERABLES/images/sample_dets"
    
    if os.path.exists(sample_dets_dir):
        det_files = [f for f in os.listdir(sample_dets_dir) if f.endswith('_det.jpg')]
        for det_file in det_files[:4]:  # åªå¤„ç†å‰4å¼ 
            img_name = det_file.replace('_det.jpg', '.jpg')
            img_path = f"data/VOCdevkit/VOC2007/JPEGImages/{img_name}"
            if os.path.exists(img_path):
                test_images.append((img_path, det_file))
    
    if not test_images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("DELIVERABLES/images/real_comparisons", exist_ok=True)
    
    comparison_results = []
    
    for i, (image_path, jittor_det_file) in enumerate(test_images):
        img_name = os.path.basename(image_path).split('.')[0]
        print(f"\nğŸ–¼ï¸ å¤„ç†å›¾ç‰‡ {i+1}/{len(test_images)}: {img_name}")
        
        # è¿è¡ŒPyTorchæ¨ç†
        pytorch_result_img = run_pytorch_demo(image_path)
        
        # è·å–Jittorç»“æœ
        jittor_result_img = os.path.join(sample_dets_dir, jittor_det_file)
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        create_comparison_image(image_path, pytorch_result_img, jittor_result_img, img_name)
        
        # è®°å½•ç»“æœ
        comparison_results.append({
            "image": img_name,
            "original": image_path,
            "pytorch_result": pytorch_result_img,
            "jittor_result": jittor_result_img,
            "pytorch_success": pytorch_result_img is not None
        })
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    results_path = "DELIVERABLES/images/real_comparisons/real_comparison_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(comparison_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ å¯¹æ¯”ç»“æœå·²ä¿å­˜: {results_path}")
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    successful_pytorch = sum(1 for r in comparison_results if r["pytorch_success"])
    print(f"\nğŸ“Š ç»Ÿè®¡æŠ¥å‘Š:")
    print(f"   æ€»æµ‹è¯•å›¾ç‰‡: {len(comparison_results)}")
    print(f"   PyTorchæ¨ç†æˆåŠŸ: {successful_pytorch}")
    print(f"   Jittorç»“æœå¯ç”¨: {len(comparison_results)}")

def create_comparison_image(original_path, pytorch_result_path, jittor_result_path, img_name):
    """åˆ›å»ºä¸‰å›¾å¯¹æ¯”"""
    
    fig, axes = plt.subplots(1, 3, figsize=(24, 8))
    
    # åŸå›¾
    if os.path.exists(original_path):
        original_img = cv2.imread(original_path)
        original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        axes[0].imshow(original_img_rgb)
        axes[0].set_title('Original Image', fontsize=14, fontweight='bold')
    else:
        axes[0].text(0.5, 0.5, 'Original\nNot Found', ha='center', va='center', fontsize=16)
        axes[0].set_title('Original Image', fontsize=14, fontweight='bold')
    axes[0].axis('off')
    
    # PyTorchç»“æœ
    if pytorch_result_path and os.path.exists(pytorch_result_path):
        pytorch_img = cv2.imread(pytorch_result_path)
        pytorch_img_rgb = cv2.cvtColor(pytorch_img, cv2.COLOR_BGR2RGB)
        axes[1].imshow(pytorch_img_rgb)
        axes[1].set_title('PyTorch Detection\n(Real Result)', fontsize=14, fontweight='bold', color='red')
    else:
        axes[1].text(0.5, 0.5, 'PyTorch\nInference Failed', ha='center', va='center', fontsize=16, color='red')
        axes[1].set_title('PyTorch Detection\n(Failed)', fontsize=14, fontweight='bold', color='red')
    axes[1].axis('off')
    
    # Jittorç»“æœ
    if os.path.exists(jittor_result_path):
        jittor_img = cv2.imread(jittor_result_path)
        jittor_img_rgb = cv2.cvtColor(jittor_img, cv2.COLOR_BGR2RGB)
        axes[2].imshow(jittor_img_rgb)
        axes[2].set_title('Jittor Detection\n(Real Result)', fontsize=14, fontweight='bold', color='blue')
    else:
        axes[2].text(0.5, 0.5, 'Jittor\nResult Not Found', ha='center', va='center', fontsize=16, color='blue')
        axes[2].set_title('Jittor Detection\n(Not Found)', fontsize=14, fontweight='bold', color='blue')
    axes[2].axis('off')
    
    # è®¾ç½®æ€»æ ‡é¢˜
    fig.suptitle(f'Real Detection Comparison: {img_name}.jpg', fontsize=18, fontweight='bold')
    
    # ä¿å­˜å¯¹æ¯”å›¾
    output_path = f"DELIVERABLES/images/real_comparisons/{img_name}_real_side_by_side.png"
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… çœŸå®å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")

def create_detection_analysis():
    """åˆ›å»ºæ£€æµ‹åˆ†æå›¾"""
    
    # åˆ†æsample_detsä¸­çš„Jittorç»“æœ
    sample_dets_dir = "DELIVERABLES/images/sample_dets"
    if not os.path.exists(sample_dets_dir):
        print("âŒ sample_detsç›®å½•ä¸å­˜åœ¨")
        return
    
    det_files = [f for f in os.listdir(sample_dets_dir) if f.endswith('_det.jpg')]
    
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    fig.suptitle('Jittor Real Detection Results Analysis', fontsize=18, fontweight='bold')
    
    for i, det_file in enumerate(det_files[:8]):
        row = i // 4
        col = i % 4
        
        det_img_path = os.path.join(sample_dets_dir, det_file)
        det_img = cv2.imread(det_img_path)
        det_img_rgb = cv2.cvtColor(det_img, cv2.COLOR_BGR2RGB)
        
        axes[row, col].imshow(det_img_rgb)
        axes[row, col].set_title(det_file.replace('_det.jpg', ''), fontweight='bold')
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.savefig('DELIVERABLES/images/real_comparisons/jittor_real_detection_analysis.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… JittorçœŸå®æ£€æµ‹åˆ†æå›¾å·²ç”Ÿæˆ: jittor_real_detection_analysis.png")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹è¿è¡ŒçœŸå®çš„PyTorchæ¨ç†å¹¶ä¸Jittorå¯¹æ¯”...")
    
    # 1. è¿è¡ŒçœŸå®çš„PyTorch vs Jittorå¯¹æ¯”
    create_real_side_by_side_comparison()
    
    # 2. åˆ›å»ºæ£€æµ‹åˆ†æå›¾
    create_detection_analysis()
    
    print("\nğŸ‰ çœŸå®æ¨ç†å¯¹æ¯”å®Œæˆï¼")
    print("ğŸ“ è¾“å‡ºç›®å½•: DELIVERABLES/images/real_comparisons/")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists("temp_pytorch_results"):
        import shutil
        shutil.rmtree("temp_pytorch_results")
        print("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")

if __name__ == "__main__":
    main()
