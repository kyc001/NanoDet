#!/usr/bin/env python3
"""
ÂàõÂª∫ÁúüÊ≠£ÁöÑPyTorch vs JittorÊ£ÄÊµãÁªìÊûúÂØπÊØî
‰ΩøÁî®JittorÂä†ËΩΩPyTorchÊùÉÈáçÊù•Ê®°ÊãüPyTorchÁªìÊûúÔºå‰∏éJittorÁã¨Á´ãËÆ≠ÁªÉÁªìÊûúÂØπÊØî
"""

import sys
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Ê∑ªÂä†JittorË∑ØÂæÑ
sys.path.append('nanodet-jittor')

import jittor as jt
from nanodet.util.config import load_config, cfg
from nanodet.model.arch import build_model
from nanodet.data.transform import Pipeline
from nanodet.util.check_point import pt_to_jt_checkpoint
import torch

def load_jittor_with_pytorch_weights():
    """‰ΩøÁî®JittorÂä†ËΩΩPyTorchÊùÉÈáç"""
    print("üîß ‰ΩøÁî®JittorÂä†ËΩΩPyTorchÊùÉÈáç...")
    
    # Âä†ËΩΩÈÖçÁΩÆ
    config_path = "nanodet-jittor/config/nanodet-plus-m_320_voc_bs64_50epochs.yml"
    load_config(cfg, config_path)
    
    # ÊûÑÂª∫Ê®°Âûã
    model = build_model(cfg.model)
    
    # Âä†ËΩΩPyTorchÊùÉÈáç
    pt_model_path = "nanodet-pytorch/workspace/nanodet-plus-m_320_voc_bs64_50epochs/model_best/model_best.ckpt"
    
    if not os.path.exists(pt_model_path):
        print(f"‚ùå PyTorchÊùÉÈáçÊñá‰ª∂‰∏çÂ≠òÂú®: {pt_model_path}")
        return None
    
    print(f"üì• Âä†ËΩΩPyTorchÊùÉÈáç: {pt_model_path}")
    
    # Âä†ËΩΩPyTorchÊ£ÄÊü•ÁÇπ
    pt_ckpt = torch.load(pt_model_path, map_location='cpu')
    
    # ÊèêÂèñstate_dict
    if 'state_dict' in pt_ckpt:
        state_dict = pt_ckpt['state_dict']
        # Â§ÑÁêÜavg_modelÂâçÁºÄ
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('avg_model.'):
                new_state_dict[k[10:]] = v
            elif k.startswith('model.'):
                new_state_dict[k[6:]] = v
            else:
                new_state_dict[k] = v
        pt_ckpt['state_dict'] = new_state_dict
    
    print(f"‚úÖ PyTorchÊùÉÈáçÂä†ËΩΩÊàêÂäüÔºåÈîÆÊï∞: {len(pt_ckpt.get('state_dict', pt_ckpt))}")
    
    # ËΩ¨Êç¢‰∏∫JittorÊ†ºÂºè
    print("üîÑ ËΩ¨Êç¢ÊùÉÈáçÊ†ºÂºè...")
    jt_ckpt = pt_to_jt_checkpoint(pt_ckpt, model)
    
    # Âä†ËΩΩÊùÉÈáçÂà∞Ê®°Âûã
    model.load_state_dict(jt_ckpt['state_dict'])
    model.eval()
    
    print("‚úÖ JittorÊ®°ÂûãÂä†ËΩΩPyTorchÊùÉÈáçÊàêÂäü")
    return model

def load_jittor_trained_model():
    """Âä†ËΩΩJittorÁã¨Á´ãËÆ≠ÁªÉÁöÑÊ®°Âûã"""
    print("üîß Âä†ËΩΩJittorÁã¨Á´ãËÆ≠ÁªÉÊ®°Âûã...")
    
    # Âä†ËΩΩÈÖçÁΩÆ
    config_path = "nanodet-jittor/config/nanodet-plus-m_320_voc_bs64_50epochs.yml"
    load_config(cfg, config_path)
    
    # ÊûÑÂª∫Ê®°Âûã
    model = build_model(cfg.model)
    
    # Âä†ËΩΩJittorÊùÉÈáç
    jt_model_path = "workspace/jittor_50epochs_model_best.pkl"
    
    if not os.path.exists(jt_model_path):
        print(f"‚ùå JittorÊùÉÈáçÊñá‰ª∂‰∏çÂ≠òÂú®: {jt_model_path}")
        return None
    
    print(f"üì• Âä†ËΩΩJittorÊùÉÈáç: {jt_model_path}")
    
    checkpoint = jt.load(jt_model_path)
    model.load_state_dict(checkpoint['state_dict'])
    model.eval()
    
    print("‚úÖ JittorÁã¨Á´ãËÆ≠ÁªÉÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
    return model

def inference_with_model(model, image_path):
    """‰ΩøÁî®Ê®°ÂûãËøõË°åÊé®ÁêÜ"""
    try:
        # Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ
        pipeline = Pipeline(cfg.data.val.pipeline, cfg.data.val.keep_ratio)

        # Âä†ËΩΩÂõæÁâá
        img = cv2.imread(image_path)
        if img is None:
            print(f"‚ùå Êó†Ê≥ïÂä†ËΩΩÂõæÁâá: {image_path}")
            return []

        # Ê≠£Á°ÆÊûÑÈÄ† meta Âπ∂Ë∞ÉÁî® Pipeline
        meta = {"img": img}
        meta = pipeline(None, meta, cfg.data.val.input_size)
        proc_img = meta["img"]

        # Êé®ÁêÜ
        with jt.no_grad():
            results = model.inference([proc_img])
        
        # Â§ÑÁêÜÁªìÊûú
        processed_results = []
        if results and len(results) > 0 and len(results[0]) > 0:
            for det in results[0]:
                if len(det) >= 6:  # bbox + score + class
                    bbox = det[:4].tolist()
                    score = float(det[4])
                    class_id = int(det[5])
                    
                    # VOCÁ±ªÂà´Âêç
                    voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
                                 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',
                                 'dog', 'horse', 'motorbike', 'person', 'pottedplant',
                                 'sheep', 'sofa', 'train', 'tvmonitor']
                    
                    if class_id < len(voc_classes):
                        class_name = voc_classes[class_id]
                        
                        processed_results.append({
                            "bbox": bbox,
                            "score": score,
                            "class": class_name,
                            "class_id": class_id
                        })
        
        return processed_results
        
    except Exception as e:
        print(f"‚ùå Êé®ÁêÜÂ§±Ë¥•: {e}")
        return []

def draw_detections(img, detections, title, color=(0, 255, 0)):
    """ÁªòÂà∂Ê£ÄÊµãÁªìÊûú"""
    img_draw = img.copy()
    
    for i, det in enumerate(detections):
        bbox = det["bbox"]
        score = det["score"]
        class_name = det["class"]
        
        # ÁªòÂà∂ËæπÁïåÊ°Ü
        cv2.rectangle(img_draw, 
                     (int(bbox[0]), int(bbox[1])), 
                     (int(bbox[2]), int(bbox[3])), 
                     color, 3)
        
        # ÁªòÂà∂Ê†áÁ≠æËÉåÊôØ
        label = f"{class_name}: {score:.3f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        
        cv2.rectangle(img_draw,
                     (int(bbox[0]), int(bbox[1]) - label_size[1] - 15),
                     (int(bbox[0]) + label_size[0] + 10, int(bbox[1])),
                     color, -1)
        
        # ÁªòÂà∂Ê†áÁ≠æÊñáÂ≠ó
        cv2.putText(img_draw, label,
                   (int(bbox[0]) + 5, int(bbox[1]) - 8),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ÁªòÂà∂Ê£ÄÊµãÂ∫èÂè∑
        cv2.circle(img_draw, (int(bbox[0]) + 15, int(bbox[1]) + 25), 18, color, -1)
        cv2.putText(img_draw, str(i+1),
                   (int(bbox[0]) + 8, int(bbox[1]) + 32),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return img_draw

def create_three_way_comparison(image_path, pytorch_results, jittor_results, output_path, img_name):
    """ÂàõÂª∫‰∏âÂõæÂØπÊØî"""
    
    # Âä†ËΩΩÂéüÂõæ
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # ÁªòÂà∂PyTorchÁªìÊûú (Á∫¢Ëâ≤)
    pytorch_img = draw_detections(img_rgb, pytorch_results, "PyTorch", (255, 0, 0))
    
    # ÁªòÂà∂JittorÁªìÊûú (ËìùËâ≤)
    jittor_img = draw_detections(img_rgb, jittor_results, "Jittor", (0, 0, 255))
    
    # ÂàõÂª∫ÂØπÊØîÂõæ
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))
    
    # ÂéüÂõæ
    ax1.imshow(img_rgb)
    ax1.set_title('Original Image', fontsize=16, fontweight='bold')
    ax1.axis('off')
    
    # PyTorchÁªìÊûú
    ax2.imshow(pytorch_img)
    ax2.set_title(f'PyTorch (via Jittor)\n{len(pytorch_results)} detections', 
                 fontsize=16, fontweight='bold', color='red')
    ax2.axis('off')
    
    # JittorÁªìÊûú
    ax3.imshow(jittor_img)
    ax3.set_title(f'Jittor (Independent)\n{len(jittor_results)} detections', 
                 fontsize=16, fontweight='bold', color='blue')
    ax3.axis('off')
    
    # Ê∑ªÂä†ÂõæÁâáÂêçÁß∞
    fig.suptitle(f'Real Detection Comparison: {img_name}', fontsize=20, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"‚úÖ ÁúüÂÆûÂØπÊØîÂõæÂ∑≤‰øùÂ≠ò: {output_path}")

def main():
    """‰∏ªÂáΩÊï∞"""
    print("üéØ ÂºÄÂßãÂàõÂª∫ÁúüÊ≠£ÁöÑPyTorch vs JittorÊ£ÄÊµãÁªìÊûúÂØπÊØî...")
    
    # ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï
    os.makedirs("DELIVERABLES/images/real_pytorch_jittor_comparison", exist_ok=True)
    
    # 1. Âä†ËΩΩ‰∏§‰∏™Ê®°Âûã
    print("\n" + "="*60)
    print("üì• Âä†ËΩΩÊ®°Âûã...")
    print("="*60)
    
    pytorch_model = load_jittor_with_pytorch_weights()
    jittor_model = load_jittor_trained_model()
    
    if pytorch_model is None or jittor_model is None:
        print("‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•")
        return
    
    # 2. Ëé∑ÂèñÊµãËØïÂõæÁâá
    test_images = [
        "data/VOCdevkit/VOC2007/JPEGImages/000003.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000011.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000014.jpg",
        "data/VOCdevkit/VOC2007/JPEGImages/000015.jpg"
    ]
    
    # ËøáÊª§Â≠òÂú®ÁöÑÂõæÁâá
    valid_images = [img for img in test_images if os.path.exists(img)]
    
    if not valid_images:
        print("‚ùå Êú™ÊâæÂà∞ÊµãËØïÂõæÁâá")
        return
    
    print(f"\nüìã ÊâæÂà∞ {len(valid_images)} Âº†ÊµãËØïÂõæÁâá")
    
    # 3. Â§ÑÁêÜÊØèÂº†ÂõæÁâá
    for i, image_path in enumerate(valid_images):
        img_name = os.path.basename(image_path).split('.')[0]
        print(f"\nüñºÔ∏è Â§ÑÁêÜÂõæÁâá {i+1}/{len(valid_images)}: {img_name}")
        
        # PyTorchÊé®ÁêÜÔºà‰ΩøÁî®JittorÂä†ËΩΩPyTorchÊùÉÈáçÔºâ
        print("   üîç PyTorchÊé®ÁêÜÔºàvia JittorÔºâ...")
        pytorch_results = inference_with_model(pytorch_model, image_path)
        print(f"      Ê£ÄÊµãÂà∞ {len(pytorch_results)} ‰∏™ÁõÆÊ†á")
        
        # JittorÊé®ÁêÜÔºàÁã¨Á´ãËÆ≠ÁªÉÔºâ
        print("   üîç JittorÊé®ÁêÜÔºàÁã¨Á´ãËÆ≠ÁªÉÔºâ...")
        jittor_results = inference_with_model(jittor_model, image_path)
        print(f"      Ê£ÄÊµãÂà∞ {len(jittor_results)} ‰∏™ÁõÆÊ†á")
        
        # ÂàõÂª∫ÂØπÊØîÂõæ
        comparison_path = f"DELIVERABLES/images/real_pytorch_jittor_comparison/{img_name}_real_comparison.png"
        create_three_way_comparison(image_path, pytorch_results, jittor_results, comparison_path, img_name)
        
        # ÊâìÂç∞Ê£ÄÊµãÁªìÊûúÂØπÊØî
        print(f"   üìä ÂØπÊØîÁªìÊûú:")
        print(f"      PyTorch: {len(pytorch_results)} ‰∏™Ê£ÄÊµã")
        print(f"      Jittor:  {len(jittor_results)} ‰∏™Ê£ÄÊµã")
        print(f"      Â∑ÆÂºÇ:    {abs(len(pytorch_results) - len(jittor_results))} ‰∏™Ê£ÄÊµã")
    
    print(f"\nüéâ ÁúüÂÆûPyTorch vs JittorÂØπÊØîÂÆåÊàêÔºÅ")
    print(f"üìÅ ËæìÂá∫ÁõÆÂΩï: DELIVERABLES/images/real_pytorch_jittor_comparison/")
    print(f"üìä ÁîüÊàê‰∫Ü {len(valid_images)} Âº†ÁúüÂÆûÂØπÊØîÂõæ")
    
    print(f"\nüí° ËØ¥Êòé:")
    print(f"   - PyTorchÁªìÊûú: ‰ΩøÁî®JittorÊ°ÜÊû∂Âä†ËΩΩPyTorchÊùÉÈáçËøõË°åÊé®ÁêÜ")
    print(f"   - JittorÁªìÊûú: ‰ΩøÁî®JittorÁã¨Á´ãËÆ≠ÁªÉÁöÑÊùÉÈáçËøõË°åÊé®ÁêÜ")
    print(f"   - ËøôÊ†∑ÂèØ‰ª•ÁúãÂà∞ÊùÉÈáçËΩ¨Êç¢ÁöÑÊïàÊûúÂíå‰∏§ÁßçËÆ≠ÁªÉÊñπÂºèÁöÑÂ∑ÆÂºÇ")

if __name__ == "__main__":
    main()
